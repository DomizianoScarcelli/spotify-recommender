{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DomizianoScarcelli/big-data-project/blob/dev/data_preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KOojFseRjVnN"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here I configure the environment. Since I alternated from Google Colab to Local development, I define a LOCAL variable that allows me to know in which environment I am. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "def is_running_on_colab():\n",
        "    return \"COLAB_GPU\" in os.environ\n",
        "\n",
        "LOCAL = not is_running_on_colab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3wVgRfHYoOs",
        "outputId": "c12d7157-1feb-4672-bc14-4e52c1eb6e4e"
      },
      "outputs": [],
      "source": [
        "#@title Download necessary libraries\n",
        "if not LOCAL:\n",
        "    !pip install pyspark -qq\n",
        "    !pip install -U -q PyDrive -qq\n",
        "    !apt install openjdk-8-jdk-headless -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CGHPv9OqY9MI"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "import requests\n",
        "\n",
        "import pyspark\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql import SparkSession, DataFrame, Row\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType, FloatType, LongType\n",
        "from pyspark import SparkConf\n",
        "from pyspark.ml.linalg import SparseVector, VectorUDT\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.model_selection import train_test_split as sklearn_split\n",
        "import shutil\n",
        "if not LOCAL:\n",
        "    from google.colab import drive\n",
        "\n",
        "from typing import Tuple\n",
        "from functools import reduce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JF8LUBZeYiWP"
      },
      "outputs": [],
      "source": [
        "#@title Set up variables\n",
        "if not LOCAL:\n",
        "    JAVA_HOME = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "    GDRIVE_DIR = \"/content/drive\"\n",
        "    GDRIVE_HOME_DIR = GDRIVE_DIR + \"/MyDrive\"\n",
        "    GDRIVE_DATA_DIR = GDRIVE_HOME_DIR + \"/Big Data/datasets\"\n",
        "    DATASET_FILE = os.path.join(GDRIVE_DATA_DIR, \"pyspark_friendly_spotify_playlist_dataset\")\n",
        "    AUDIO_FEATURES_FILE = os.path.join(GDRIVE_DATA_DIR, \"pyspark_track_features\")\n",
        "    LITTLE_SLICE_FILE = os.path.join(GDRIVE_DATA_DIR, \"little_slice\")\n",
        "    SMALL_SLICE_FLIE = os.path.join(GDRIVE_DATA_DIR, \"small_slice\")\n",
        "    LITTLE_SLICE_AUDIO_FEATURES = os.path.join(GDRIVE_DATA_DIR, \"little_slice_audio_features\")\n",
        "    MICRO_SLICE_AUDIO_FEATURES = os.path.join(GDRIVE_DATA_DIR, \"micro_slice_audio_features\")\n",
        "    SPLITTED_SLICE_AUDIO_FEATURES = os.path.join(GDRIVE_DATA_DIR, \"splitted_pyspark_track_features\")\n",
        "    SAVED_DFS_PATH = os.path.join(GDRIVE_DATA_DIR, \"saved_dfs\")\n",
        "    SAVED_MODELS = os.path.join(GDRIVE_DATA_DIR, \"saved_models\")\n",
        "    PRUNED_DF_PATH = os.path.join(GDRIVE_DATA_DIR, \"pruned_df_100k\")\n",
        "else:\n",
        "    GDRIVE_DATA_DIR = os.path.abspath(\"./data\")\n",
        "    SAVED_DFS_PATH = os.path.join(GDRIVE_DATA_DIR, \"saved_dfs\")\n",
        "    SAVED_MODELS = os.path.join(GDRIVE_DATA_DIR, \"saved_models\")\n",
        "    DATASET_FILE = os.path.join(GDRIVE_DATA_DIR, \"full_dataset\")\n",
        "    SMALL_SLICE_FLIE = os.path.join(GDRIVE_DATA_DIR, \"small_slice\")\n",
        "    PRUNED_DF_PATH = os.path.join(GDRIVE_DATA_DIR, \"pruned_df_100k\")\n",
        "    JAVA_HOME = \"/opt/homebrew/opt/openjdk\"\n",
        "RANDOM_SEED = 42 # for reproducibility\n",
        "os.environ[\"JAVA_HOME\"] = JAVA_HOME\n",
        "os.environ[\"PYSPARK_PYTHON\"]=\"python\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4m7VztzdZgm6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "23/06/29 11:26:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
          ]
        }
      ],
      "source": [
        "#@title Create the session\n",
        "conf = SparkConf().\\\n",
        "                set('spark.ui.port', \"4050\").\\\n",
        "                set('spark.executor.memory', '12G').\\\n",
        "                set('spark.driver.memory', '12G').\\\n",
        "                set('spark.driver.maxResultSize', '100G').\\\n",
        "                set(\"spark.executor.extraJavaOptions\", \"-XX:+UseG1GC\").\\\n",
        "                setAppName(\"PySparkTutorial\").\\\n",
        "                setMaster(\"local[*]\")\n",
        "\n",
        "# Create the context\n",
        "sc = pyspark.SparkContext(conf=conf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsX5d-YXZ2Ul",
        "outputId": "ceb1f82f-fefa-49a2-93d3-52e33fa081a2"
      },
      "outputs": [],
      "source": [
        "if not LOCAL:\n",
        "    drive.mount(GDRIVE_DIR, force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlxfJiBSZ6ju",
        "outputId": "2895ee5f-0dca-4399-9474-eb669896ea71"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<pyspark.sql.session.SparkSession at 0x12f8dfc10>,\n",
              " [('spark.app.id', 'local-1688030804255'),\n",
              "  ('spark.executor.extraJavaOptions',\n",
              "   '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false -XX:+UseG1GC'),\n",
              "  ('spark.app.name', 'PySparkTutorial'),\n",
              "  ('spark.driver.host', '192.168.1.175'),\n",
              "  ('spark.executor.id', 'driver'),\n",
              "  ('spark.driver.extraJavaOptions',\n",
              "   '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false'),\n",
              "  ('spark.ui.port', '4050'),\n",
              "  ('spark.driver.port', '54716'),\n",
              "  ('spark.app.startTime', '1688030803774'),\n",
              "  ('spark.rdd.compress', 'True'),\n",
              "  ('spark.driver.memory', '12G'),\n",
              "  ('spark.serializer.objectStreamReset', '100'),\n",
              "  ('spark.master', 'local[*]'),\n",
              "  ('spark.submit.pyFiles', ''),\n",
              "  ('spark.driver.maxResultSize', '100G'),\n",
              "  ('spark.submit.deployMode', 'client'),\n",
              "  ('spark.app.submitTime', '1688030803644'),\n",
              "  ('spark.executor.memory', '12G'),\n",
              "  ('spark.ui.showConsoleProgress', 'true')])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@title Check if everything is ok\n",
        "spark, sc._conf.getAll()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VJeY9PpvaHUJ"
      },
      "source": [
        "# Load DataFrame"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the `DataFrame` schemas and load the primary `DataFrame` containing the 100K playlists. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "icd2lj-RRvhU"
      },
      "outputs": [],
      "source": [
        "song_schema = StructType([\n",
        "    StructField(\"pos\", IntegerType(), True),\n",
        "    StructField(\"artist_name\", StringType(), True),\n",
        "    StructField(\"track_uri\", StringType(), True),\n",
        "    StructField(\"artist_uri\", StringType(), True),\n",
        "    StructField(\"track_name\", StringType(), True),\n",
        "    StructField(\"album_uri\", StringType(), True),\n",
        "    StructField(\"duration_ms\", LongType(), True),\n",
        "    StructField(\"album_name\", StringType(), True)\n",
        "])\n",
        "\n",
        "playlist_schema = StructType([\n",
        "    StructField(\"name\", StringType(), True),\n",
        "    StructField(\"collaborative\", StringType(), True),\n",
        "    StructField(\"pid\", IntegerType(), True),\n",
        "    StructField(\"modified_at\", IntegerType(), True),\n",
        "    StructField(\"num_tracks\", IntegerType(), True),\n",
        "    StructField(\"num_albums\", IntegerType(), True),\n",
        "    StructField(\"num_followers\", IntegerType(), True),\n",
        "    StructField(\"tracks\", ArrayType(song_schema), True),\n",
        "    StructField(\"num_edits\", IntegerType(), True),\n",
        "    StructField(\"duration_ms\", IntegerType(), True),\n",
        "    StructField(\"num_artists\", IntegerType(), True),\n",
        "])\n",
        "\n",
        "playlist_schema_mapped = StructType([\n",
        "    StructField(\"name\", StringType(), True),\n",
        "    StructField(\"collaborative\", StringType(), True),\n",
        "    StructField(\"pid\", IntegerType(), True),\n",
        "    StructField(\"modified_at\", IntegerType(), True),\n",
        "    StructField(\"num_tracks\", IntegerType(), True),\n",
        "    StructField(\"num_albums\", IntegerType(), True),\n",
        "    StructField(\"num_followers\", IntegerType(), True),\n",
        "    StructField(\"tracks\", VectorUDT(), True),\n",
        "    StructField(\"num_edits\", IntegerType(), True),\n",
        "    StructField(\"duration_ms\", IntegerType(), True),\n",
        "    StructField(\"num_artists\", IntegerType(), True),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BY_szFyLTps4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "slice_df = spark.read.schema(playlist_schema).json(SMALL_SLICE_FLIE, multiLine=True)\n",
        "NUM_PLAYLISTS = slice_df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------+-------------+-----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "|          name|collaborative|  pid|modified_at|num_tracks|num_albums|num_followers|              tracks|num_edits|duration_ms|num_artists|\n",
            "+--------------+-------------+-----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "|         Ratch|        false|45000| 1508976000|        88|        70|            1|[{0, Beyonc√©, spo...|       50|   20047039|         48|\n",
            "|  slow it down|        false|45001| 1505952000|        80|        77|            1|[{0, Twinbed, spo...|       20|   20365984|         65|\n",
            "|    Phat Beats|        false|45002| 1466640000|        24|        15|            5|[{0, Baths, spoti...|       16|    5127143|         14|\n",
            "|           ‚úåüèΩ|        false|45003| 1509148800|        77|        63|            3|[{0, Owl City, sp...|       50|   17201663|         54|\n",
            "|          üíòüíò|        false|45004| 1479081600|       102|        78|            1|[{0, Rihanna, spo...|       35|   23364932|         56|\n",
            "|   Summer 2015|         true|45005| 1459555200|       126|       114|            7|[{0, Ti√´sto, spot...|       22|   30131677|         99|\n",
            "|Summer Country|        false|45006| 1492560000|       246|       166|            1|[{0, Kenny Chesne...|       13|   52836874|         91|\n",
            "|          Jazz|        false|45007| 1478044800|        15|        14|            1|[{0, Freddie Hubb...|        3|    6792929|         13|\n",
            "|       Hip Hop|        false|45008| 1503619200|       160|       113|            1|[{0, Fugees, spot...|       39|   37111155|         64|\n",
            "|    dance jams|        false|45009| 1469750400|        19|        16|            1|[{0, Justin Biebe...|        5|    4201172|         16|\n",
            "|   Inspiration|        false|45010| 1496188800|        30|        30|            3|[{0, The Staves, ...|        7|    7466099|         27|\n",
            "|           <33|        false|45011| 1504396800|        18|        16|            5|[{0, KYLE, spotif...|       10|    4106160|         15|\n",
            "|    Christmas |        false|45012| 1387756800|        42|        20|            1|[{0, Louis Armstr...|        2|    9704283|         26|\n",
            "|   Summer 2k17|        false|45013| 1500249600|        52|        51|            3|[{0, Drake, spoti...|       30|   11619016|         50|\n",
            "|         sleep|        false|45014| 1487030400|       164|       111|            1|[{0, TK N Cash, s...|       37|   38449124|         84|\n",
            "|           SKA|        false|45015| 1507593600|        50|        44|            1|[{0, The Slackers...|       15|    9435544|         34|\n",
            "|       Groovin|        false|45016| 1505347200|        88|        80|            1|[{0, of Montreal,...|       36|   23097679|         68|\n",
            "|     Play ME!!|        false|45017| 1477353600|        42|        40|            1|[{0, Jessie J, sp...|       15|    9737901|         35|\n",
            "|   Alternative|        false|45018| 1509408000|        47|        43|            1|[{0, All Time Low...|       36|   10622933|         35|\n",
            "|Rap En Espa√±ol|        false|45019| 1503100800|       138|        25|            1|[{0, Cartel De Sa...|        4|   32636526|         11|\n",
            "+--------------+-------------+-----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "slice_df.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WLoSGO9IJrpr"
      },
      "source": [
        "Since we will produce many files, each one optimized for each technique, let's define here all the different paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jKtjs_wAJzBS"
      },
      "outputs": [],
      "source": [
        "# The DF used for train (80% of the original) (playlist are different)\n",
        "TRAIN_DF_PATH = os.path.join(SAVED_DFS_PATH, f\"train_df-{NUM_PLAYLISTS}.json\")\n",
        "# The DF used for testing (20% of the original) (playlist are different)\n",
        "TEST_DF_PATH = os.path.join(SAVED_DFS_PATH, f\"test_df-{NUM_PLAYLISTS}.json\")\n",
        "\n",
        "# The DF used for train in the NN model (can be filtered or not)\n",
        "NN_TRAIN_DF_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_train_df-{NUM_PLAYLISTS}.json\")\n",
        "# The DF used for testing in the NN model (can be filtered or not)\n",
        "NN_TEST_DF_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_test_df-{NUM_PLAYLISTS}.json\")\n",
        "# The partition in train test of the NN test set. (Same playlists, different songs)\n",
        "NN_TEST_DF_TRAIN_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_test_df-train-{NUM_PLAYLISTS}.json\")\n",
        "NN_TEST_DF_TEST_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_test_df-test-{NUM_PLAYLISTS}.json\")\n",
        "\n",
        "NN_EVAL_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_eval_df-{NUM_PLAYLISTS}.json\")\n",
        "NN_EVAL_TRAIN_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_eval_df-train-{NUM_PLAYLISTS}.json\")\n",
        "NN_EVAL_TEST_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_eval_df-test-{NUM_PLAYLISTS}.json\")\n",
        "# New one:\n",
        "ARTISTS_EMBEDDINGS_TRAIN = os.path.join(SAVED_DFS_PATH, f\"nn_artists_embeddings-train-{NUM_PLAYLISTS}.json\")\n",
        "ARTISTS_EMBEDDINGS_TEST_TRAIN = os.path.join(SAVED_DFS_PATH, f\"nn_artists_embeddings-test-train-{NUM_PLAYLISTS}.json\")\n",
        "ARTISTS_EMBEDDINGS_TEST_TEST = os.path.join(SAVED_DFS_PATH, f\"nn_artists_embeddings-test-test{NUM_PLAYLISTS}.json\")\n",
        "\n",
        "ARTISTS_EMBEDDINGS_EVAL = os.path.join(SAVED_DFS_PATH, f\"nn_artists_embeddings-eval-{NUM_PLAYLISTS}.json\")\n",
        "ARTISTS_EMBEDDINGS_EVAL_TRAIN = os.path.join(SAVED_DFS_PATH, f\"nn_artists_embeddings-eval-train-{NUM_PLAYLISTS}.json\")\n",
        "ARTISTS_EMBEDDINGS_EVAL_TEST = os.path.join(SAVED_DFS_PATH, f\"nn_artists_embeddings-eval-test{NUM_PLAYLISTS}.json\")\n",
        "\n",
        "# The length of the artist vector length (Artist vectors are only used in the NN model)\n",
        "ARTIST_VECTOR_LENGTH_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_artist_vector_length-{NUM_PLAYLISTS}.txt\")\n",
        "\n",
        "SONGS_VECTOR_LENGTH_PATH = os.path.join(SAVED_DFS_PATH, f\"songs_vector_length-{NUM_PLAYLISTS}.txt\")\n",
        "# This may be filtered or not\n",
        "FILTERED_SONGS_VECTOR_LENGTH_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_songs_vector_length-{NUM_PLAYLISTS}.txt\")\n",
        "\n",
        "SONGS_EMBEDDINGS_PATH = os.path.join(SAVED_DFS_PATH, f\"songs_embeddings-{NUM_PLAYLISTS}.json\")\n",
        "SONGS_EMBEDDINGS_TRAIN = os.path.join(SAVED_DFS_PATH, f\"songs_embeddings-train-{NUM_PLAYLISTS}.json\")\n",
        "SONGS_EMBEDDINGS_TEST = os.path.join(SAVED_DFS_PATH, f\"songs_embeddings-test-{NUM_PLAYLISTS}.json\")\n",
        "\n",
        "NN_SONGS_EMBEDDINGS_TRAIN = os.path.join(SAVED_DFS_PATH, f\"nn_songs_embeddings-train-{NUM_PLAYLISTS}.json\")\n",
        "NN_SONGS_EMBEDDINGS_TEST_TRAIN = os.path.join(SAVED_DFS_PATH, f\"nn_songs_embeddings-test-train-{NUM_PLAYLISTS}.json\")\n",
        "NN_SONGS_EMBEDDINGS_TEST_TEST = os.path.join(SAVED_DFS_PATH, f\"nn_songs_embeddings-test-test-{NUM_PLAYLISTS}.json\")\n",
        "\n",
        "NN_SONGS_EMBEDDINGS_EVAL = os.path.join(SAVED_DFS_PATH, f\"nn_songs_embeddings-eval-{NUM_PLAYLISTS}.json\") #TODO: The logic to produce this still has to be coded.\n",
        "NN_SONGS_EMBEDDINGS_EVAL_TRAIN = os.path.join(SAVED_DFS_PATH, f\"nn_songs_embeddings-eval-train-{NUM_PLAYLISTS}.json\")\n",
        "NN_SONGS_EMBEDDINGS_EVAL_TEST = os.path.join(SAVED_DFS_PATH, f\"nn_songs_embeddings-eval-test-{NUM_PLAYLISTS}.json\")\n",
        "\n",
        "SONGS_INFO_DF = os.path.join(SAVED_DFS_PATH, f\"songs_info_df-{NUM_PLAYLISTS}.json\")\n",
        "FILTERED_SONGS_INFO_DF = os.path.join(SAVED_DFS_PATH, f\"nn_songs_info_df-{NUM_PLAYLISTS}.json\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "h5zOoDDXEIBn"
      },
      "source": [
        "# Dataset Train-Test split"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eAhzcKNIQIR9"
      },
      "source": [
        "## Simple Train-Test split\n",
        "For the user-based and item-based collaborative filtering, the train-test split is done by splitting the songs inside each playlist with a ration of 80% train and 20% test. This means that the playlists are the same for the train and test, but the songs inside are different. In this way we can use the train test to recommend the songs, and use the test set to evaluate the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Qek8mLL4EK0M"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def train_test_split(playlist: Row) -> Tuple[Row, Row]:\n",
        "    train_rows, test_rows = sklearn_split(playlist.tracks, random_state=42)\n",
        "\n",
        "    playlist_train =  Row(\n",
        "            name=playlist.name,\n",
        "            collaborative=playlist.collaborative,\n",
        "            pid=playlist.pid,\n",
        "            modified_at=playlist.modified_at,\n",
        "            num_tracks=playlist.num_tracks,\n",
        "            num_albums=playlist.num_albums,\n",
        "            num_followers=playlist.num_followers,\n",
        "            tracks=train_rows,\n",
        "            num_edits=playlist.num_edits,\n",
        "            duration_ms=playlist.duration_ms,\n",
        "            num_artists=playlist.num_artists,\n",
        "        )\n",
        "\n",
        "    playlist_test = Row(\n",
        "            name=playlist.name,\n",
        "            collaborative=playlist.collaborative,\n",
        "            pid=playlist.pid,\n",
        "            modified_at=playlist.modified_at,\n",
        "            num_tracks=playlist.num_tracks,\n",
        "            num_albums=playlist.num_albums,\n",
        "            num_followers=playlist.num_followers,\n",
        "            tracks=test_rows,\n",
        "            num_edits=playlist.num_edits,\n",
        "            duration_ms=playlist.duration_ms,\n",
        "            num_artists=playlist.num_artists,\n",
        "        )\n",
        "    \n",
        "    return playlist_train, playlist_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3p9m_Jl6FDoA"
      },
      "outputs": [],
      "source": [
        "def divide_whole_dataset(playlist_df: DataFrame) -> Tuple[DataFrame, DataFrame]:\n",
        "  train_test_split_udf = F.udf(train_test_split, returnType=ArrayType(StructType(playlist_df.schema.fields)))\n",
        "  divided_df = playlist_df.withColumn(\"divided\", train_test_split_udf(F.struct(*playlist_df.columns)))\n",
        "  train_test_df = divided_df.select(F.col('divided').getItem(0).alias('train'), F.col('divided').getItem(1).alias('test'))\n",
        "\n",
        "  train_df = train_test_df.select(\"train.*\")\n",
        "  test_df = train_test_df.select(\"test.*\")\n",
        "  return train_df, test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "OVERRIDE = False\n",
        "#If True, it computes the dataframe and save them on the disk, overwriting the old ones\n",
        "#Otherwise, it loads the dataframes from the disk, if they exist, otherwise it computes it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "YgXY1Gq1s7j4"
      },
      "outputs": [],
      "source": [
        "if os.path.exists(TRAIN_DF_PATH) and os.path.exists(TEST_DF_PATH) and not OVERRIDE:\n",
        "  train_df = spark.read.schema(playlist_schema).json(TRAIN_DF_PATH)\n",
        "  test_df = spark.read.schema(playlist_schema).json(TEST_DF_PATH)\n",
        "else:\n",
        "  # In order to avoid [PATH_ALREADY_EXISTS] errors. \n",
        "  if os.path.exists(TRAIN_DF_PATH):\n",
        "    shutil.rmtree(TRAIN_DF_PATH)\n",
        "  if os.path.exists(TEST_DF_PATH):\n",
        "    shutil.rmtree(TEST_DF_PATH)\n",
        "\n",
        "  train_df, test_df = divide_whole_dataset(slice_df)\n",
        "  train_df, test_df = train_df.cache(), test_df.cache()\n",
        "  train_df.write.mode(\"overwrite\").json(TRAIN_DF_PATH)\n",
        "  test_df.write.mode(\"overwrite\").json(TEST_DF_PATH)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9Pqje_w0Qk0C"
      },
      "source": [
        "## Neural Network Train-Test split\n",
        "Regarding the Neural Network approach, we cannot use the same train-test split. This because we need a training test that contains some playlists in order to train the model, and then we need a test set with different playlists in order to make the performance evaluation. The test set will also be split with the approach above, meaning some songs will be removes in order to evaluate the recommendations. This approach is needed in order to not evaluate the model with playlists that were in the training set."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Remove playlist with unpopular songs"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before going into the train and test split, let's take the whole 1M playlist dataset, and remove all the playlists that contain a song that appears less than 10 times in the whole dataset, in order for the Neural Network to better learn the patters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "PRUNE = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "PRUNED_DF_PATH_100K = os.path.join(GDRIVE_DATA_DIR, \"pruned_df_100k\")\n",
        "if PRUNE:\n",
        "    FULL_DATASET_PATH = os.path.join(GDRIVE_DATA_DIR, \"full_dataset\")\n",
        "    full_df = spark.read.schema(playlist_schema).json(FULL_DATASET_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prune_dataset(df: DataFrame, min_song_count: int) -> DataFrame:\n",
        "    track_counts = full_df.withColumn(\"track_uri\", F.explode(\"tracks.track_uri\")) \\\n",
        "        .groupBy(\"track_uri\") \\\n",
        "        .agg(F.count(\"*\").alias(\"count\"))\n",
        "\n",
        "    unpopular_songs = full_df.withColumn(\"track_uri\", F.explode(\"tracks.track_uri\")) \\\n",
        "        .join(track_counts, \"track_uri\") \\\n",
        "        .filter(f\"count <= {min_song_count}\") \\\n",
        "        .groupBy(\"pid\") \\\n",
        "        .agg(F.count(\"*\").alias(\"num_unpopular_songs\"))\n",
        "\n",
        "    result_df = full_df.join(unpopular_songs, \"pid\", \"left\")\n",
        "    result_df = result_df.fillna(0)\n",
        "    result_df = result_df.filter(\"num_unpopular_songs == 0\")\n",
        "    return result_df\n",
        "\n",
        "if PRUNE:\n",
        "    pruned_df = prune_dataset(full_df, 10)\n",
        "    tot = pruned_df.count()\n",
        "    frac = 100_000 / tot\n",
        "    pruned_df.sample(False,frac, 42).limit(100_000).write.mode(\"overwrite\").json(PRUNED_DF_PATH_100K)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "aK4IK7EyRD-k"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "def nn_train_test_split(playlists: DataFrame, split: List[float], seed: int = 42,) -> Tuple[DataFrame, DataFrame]:\n",
        "    train_playlists, test_playlists = playlists.randomSplit(split, seed)\n",
        "    return train_playlists, test_playlists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "A50E9GgjRtF8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/29 11:26:57 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
          ]
        }
      ],
      "source": [
        "if not OVERRIDE and os.path.exists(NN_TRAIN_DF_PATH) and os.path.exists(NN_TEST_DF_TRAIN_PATH) and os.path.exists(NN_TEST_DF_TEST_PATH) and os.path.exists(NN_TEST_DF_PATH):\n",
        "  nn_train_df = spark.read.schema(playlist_schema).json(NN_TRAIN_DF_PATH)\n",
        "  nn_test_df = spark.read.schema(playlist_schema).json(NN_TEST_DF_PATH)\n",
        "  nn_test_train_df = spark.read.schema(playlist_schema).json(NN_TEST_DF_TRAIN_PATH)\n",
        "  nn_test_test_df = spark.read.schema(playlist_schema).json(NN_TEST_DF_TEST_PATH)\n",
        "\n",
        "  nn_eval_df = spark.read.schema(playlist_schema).json(NN_SONGS_EMBEDDINGS_EVAL)\n",
        "  nn_eval_train_df = spark.read.schema(playlist_schema).json(NN_SONGS_EMBEDDINGS_EVAL_TRAIN)\n",
        "  nn_eval_test_df = spark.read.schema(playlist_schema).json(NN_SONGS_EMBEDDINGS_EVAL_TEST)\n",
        "else:\n",
        "  # In order to avoid [PATH_ALREADY_EXISTS] errors. \n",
        "  if os.path.exists(NN_TRAIN_DF_PATH):\n",
        "    shutil.rmtree(NN_TRAIN_DF_PATH)\n",
        "  if os.path.exists(NN_TEST_DF_PATH):\n",
        "    shutil.rmtree(NN_TEST_DF_PATH)\n",
        "  if os.path.exists(NN_TEST_DF_TRAIN_PATH):\n",
        "    shutil.rmtree(NN_TEST_DF_TRAIN_PATH)\n",
        "  if os.path.exists(NN_TEST_DF_TEST_PATH):\n",
        "    shutil.rmtree(NN_TEST_DF_TEST_PATH)\n",
        "\n",
        "  nn_train_no_eval_df, nn_test_df = nn_train_test_split(slice_df, split=[0.99, 0.01], seed=0)\n",
        "  nn_test_train_df, nn_test_test_df = divide_whole_dataset(nn_test_df)\n",
        "  nn_train_df, nn_eval_df = nn_train_test_split(nn_train_no_eval_df, split=[0.995, 0.005], seed=0)\n",
        "  nn_eval_train_df, nn_eval_test_df = divide_whole_dataset(nn_eval_df)\n",
        "  test_train_df, test_test_df = nn_test_train_df.cache(), nn_test_test_df.cache()\n",
        "  \n",
        "\n",
        "  nn_eval_df.write.mode(\"overwrite\").json(NN_EVAL_PATH)\n",
        "  nn_eval_train_df.write.mode(\"overwrite\").json(NN_EVAL_TRAIN_PATH)\n",
        "  nn_eval_test_df.write.mode(\"overwrite\").json(NN_EVAL_TEST_PATH)\n",
        "\n",
        "  nn_train_df.write.mode(\"overwrite\").json(NN_TRAIN_DF_PATH)\n",
        "  nn_test_df.write.mode(\"overwrite\").json(NN_TEST_DF_PATH)\n",
        "  nn_test_train_df.write.mode(\"overwrite\").json(NN_TEST_DF_TRAIN_PATH)\n",
        "  nn_test_test_df.write.mode(\"overwrite\").json(NN_TEST_DF_TEST_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+-------------+----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "|         name|collaborative| pid|modified_at|num_tracks|num_albums|num_followers|              tracks|num_edits|duration_ms|num_artists|\n",
            "+-------------+-------------+----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "|       disney|        false|1000| 1457827200|       189|        16|            1|[{31, Daughters o...|        4|   31428282|         65|\n",
            "|Indie Electro|        false|1001| 1417824000|       165|        18|            2|[{117, Boards of ...|        2|   38241566|          8|\n",
            "|  jack & jack|        false|1002| 1465430400|        17|        14|            1|[{14, Jack & Jack...|        3|    3549358|          3|\n",
            "|        vibes|        false|1003| 1498435200|       225|       195|            2|[{119, PREP, spot...|       91|   51242585|        157|\n",
            "|        Indie|        false|1004| 1498608000|       165|       118|            1|[{117, LCD Sounds...|       74|   42601098|         92|\n",
            "|      college|        false|1005| 1504310400|        28|        26|            1|[{22, Kid Ink, sp...|        2|    5870710|         25|\n",
            "|    Summer 15|        false|1006| 1471996800|        80|        74|            2|[{9, Kygo, spotif...|       40|   19652753|         67|\n",
            "|    New music|        false|1007| 1509148800|        58|        48|            1|[{17, Kodak Black...|       20|   13158862|         38|\n",
            "|          Now|        false|1008| 1505692800|        84|        82|            3|[{30, Mullally, s...|       36|   18432208|         79|\n",
            "|         Jams|        false|1009| 1507680000|        41|        36|            1|[{12, Alabama Sha...|       25|    9413467|         31|\n",
            "|    Party Mix|        false|1010| 1464393600|        74|        72|            2|[{39, Stevie Wond...|       11|   17853470|         63|\n",
            "|         LOCO|        false|1011| 1491868800|        97|        90|           18|[{33, Fat Joe, sp...|       27|   20635206|         82|\n",
            "|   Bruno Mars|        false|1012| 1506211200|        18|         7|            1|[{13, Bruno Mars,...|        3|    3974946|          3|\n",
            "|       Breezy|        false|1013| 1490140800|        67|        55|            1|[{7, Jon Bellion,...|       42|   14724585|         45|\n",
            "|      Fall 16|        false|1014| 1496793600|        83|        64|            3|[{61, Kings of Le...|       27|   21004989|         49|\n",
            "|          SLO|        false|1015| 1498262400|        53|        32|            1|[{34, Todd Snider...|        3|   12136870|         19|\n",
            "|       BANGAZ|        false|1016| 1508716800|       198|       141|            1|[{185, Russ, spot...|      104|   43843897|         89|\n",
            "|  Piano Music|        false|1017| 1401148800|        29|        21|            1|[{26, Jennifer Th...|        5|    6992643|         12|\n",
            "|  Beach Music|        false|1018| 1492387200|       130|       106|           14|[{24, Zion & Lenn...|       27|   30811124|         70|\n",
            "|    Slow jamz|        false|1019| 1505779200|        43|        42|            1|[{27, Bone Thugs-...|       15|   11198025|         32|\n",
            "+-------------+-------------+----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-------------+-------------+----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "|         name|collaborative| pid|modified_at|num_tracks|num_albums|num_followers|              tracks|num_edits|duration_ms|num_artists|\n",
            "+-------------+-------------+----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "|       disney|        false|1000| 1457827200|       189|        16|            1|[{184, Various Ar...|        4|   31428282|         65|\n",
            "|Indie Electro|        false|1001| 1417824000|       165|        18|            2|[{135, Boards of ...|        2|   38241566|          8|\n",
            "|  jack & jack|        false|1002| 1465430400|        17|        14|            1|[{0, Jack & Jack,...|        3|    3549358|          3|\n",
            "|        vibes|        false|1003| 1498435200|       225|       195|            2|[{9, Marc E. Bass...|       91|   51242585|        157|\n",
            "|        Indie|        false|1004| 1498608000|       165|       118|            1|[{135, Fleet Foxe...|       74|   42601098|         92|\n",
            "|      college|        false|1005| 1504310400|        28|        26|            1|[{9, Kesha, spoti...|        2|    5870710|         25|\n",
            "|    Summer 15|        false|1006| 1471996800|        80|        74|            2|[{30, Jeremih, sp...|       40|   19652753|         67|\n",
            "|    New music|        false|1007| 1509148800|        58|        48|            1|[{0, Post Malone,...|       20|   13158862|         38|\n",
            "|          Now|        false|1008| 1505692800|        84|        82|            3|[{73, PredZ, spot...|       36|   18432208|         79|\n",
            "|         Jams|        false|1009| 1507680000|        41|        36|            1|[{24, Foster The ...|       25|    9413467|         31|\n",
            "|    Party Mix|        false|1010| 1464393600|        74|        72|            2|[{4, The Killers,...|       11|   17853470|         63|\n",
            "|         LOCO|        false|1011| 1491868800|        97|        90|           18|[{62, Boostee, sp...|       27|   20635206|         82|\n",
            "|   Bruno Mars|        false|1012| 1506211200|        18|         7|            1|[{0, Bruno Mars, ...|        3|    3974946|          3|\n",
            "|       Breezy|        false|1013| 1490140800|        67|        55|            1|[{36, Troye Sivan...|       42|   14724585|         45|\n",
            "|      Fall 16|        false|1014| 1496793600|        83|        64|            3|[{30, The Arcs, s...|       27|   21004989|         49|\n",
            "|          SLO|        false|1015| 1498262400|        53|        32|            1|[{19, Bruce Sprin...|        3|   12136870|         19|\n",
            "|       BANGAZ|        false|1016| 1508716800|       198|       141|            1|[{65, Young Thug,...|      104|   43843897|         89|\n",
            "|  Piano Music|        false|1017| 1401148800|        29|        21|            1|[{27, Jennifer Th...|        5|    6992643|         12|\n",
            "|  Beach Music|        false|1018| 1492387200|       130|       106|           14|[{55, H√©ctor \"El ...|       27|   30811124|         70|\n",
            "|    Slow jamz|        false|1019| 1505779200|        43|        42|            1|[{37, R. Kelly, s...|       15|   11198025|         32|\n",
            "+-------------+-------------+----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.show(), test_df.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7N55cIvSCjlY"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KW-f-pu6DYvh"
      },
      "source": [
        "## Get the artists vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "BMQE8T4XCng8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:KeyboardInterrupt while sending command.                (0 + 8) / 30]\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/dov/miniconda3/envs/dl/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/Users/dov/miniconda3/envs/dl/lib/python3.10/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
            "    answer = smart_decode(self.stream.readline()[:-1])\n",
            "  File \"/Users/dov/miniconda3/envs/dl/lib/python3.10/socket.py\", line 705, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "KeyboardInterrupt\n",
            "[Stage 6:===============>                                          (8 + 8) / 30]\r"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[24], line 80\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[39mreturn\u001b[39;00m artists_slice_df\n\u001b[1;32m     79\u001b[0m \u001b[39m#I've not implemented the code to not \"filter rare\" the artist because I don't need it.\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m filtered_artist_mapping, FILTERED_ARTIST_VECTOR_LENGTH \u001b[39m=\u001b[39m create_artists_pos_mapping(slice_df, filter_rare\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m) \u001b[39m#Should be True, but false for now\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(ARTIST_VECTOR_LENGTH_PATH, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     82\u001b[0m   f\u001b[39m.\u001b[39mwrite(\u001b[39m'\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m FILTERED_ARTIST_VECTOR_LENGTH)\n",
            "Cell \u001b[0;32mIn[24], line 38\u001b[0m, in \u001b[0;36mcreate_artists_pos_mapping\u001b[0;34m(playlist_df, filter_rare)\u001b[0m\n\u001b[1;32m     35\u001b[0m artists_df \u001b[39m=\u001b[39m artists_df\u001b[39m.\u001b[39mwithColumnRenamed(\u001b[39m\"\u001b[39m\u001b[39mpos\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mold_pos\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mwithColumn(\u001b[39m\"\u001b[39m\u001b[39mpos\u001b[39m\u001b[39m\"\u001b[39m, sub_udf(F\u001b[39m.\u001b[39mcol(\u001b[39m\"\u001b[39m\u001b[39mold_pos\u001b[39m\u001b[39m\"\u001b[39m)))\u001b[39m.\u001b[39mdrop(\u001b[39m\"\u001b[39m\u001b[39mold_pos\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m artists_df \u001b[39m=\u001b[39m artists_df\u001b[39m.\u001b[39msort(\u001b[39m\"\u001b[39m\u001b[39martist_uri\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m ARTIST_VECTOR_LENGTH \u001b[39m=\u001b[39m artists_df\u001b[39m.\u001b[39;49mcount()\n\u001b[1;32m     40\u001b[0m \u001b[39mreturn\u001b[39;00m artists_df, ARTIST_VECTOR_LENGTH\n",
            "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.10/site-packages/pyspark/sql/dataframe.py:1193\u001b[0m, in \u001b[0;36mDataFrame.count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1170\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcount\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[1;32m   1171\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns the number of rows in this :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   1172\u001b[0m \n\u001b[1;32m   1173\u001b[0m \u001b[39m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[39m    3\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1193\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mint\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mcount())\n",
            "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.10/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_args(\u001b[39m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n",
            "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.10/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1039\u001b[0m     \u001b[39mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[39mreturn\u001b[39;00m response, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_connection_guard(connection)\n",
            "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.10/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[39m=\u001b[39m smart_decode(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mreadline()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mAnswer received: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[39m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[39m# answer before the socket raises an error.\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "#Filter rare should filter songs before the split, this implementation is wrong.\n",
        "def get_all_artists(playlist_df: DataFrame, filter_rare: bool = False) -> DataFrame:\n",
        "  \"\"\"\n",
        "  Given a playlist dataframe, returns the dataframe containing the unique list of artist_uri that are present in all the playlists.\n",
        "  \"\"\"\n",
        "  if filter_rare:\n",
        "    all_songs = playlist_df.select(F.explode(\"tracks.artist_uri\").alias(\"artist_uri\")) \\\n",
        "            .groupBy(\"artist_uri\") \\\n",
        "            .agg(F.count(\"*\").alias(\"count\")) \\\n",
        "            .filter(F.col(\"count\") >= 3)\n",
        "  else:\n",
        "    all_songs = playlist_df.select(F.explode(\"tracks.artist_uri\").alias(\"artist_uri\")).distinct()\n",
        "  return all_songs\n",
        "\n",
        "def create_artists_pos_mapping(playlist_df: DataFrame, filter_rare: bool = False) -> Tuple[DataFrame, int]:\n",
        "  \"\"\"\n",
        "  Given the dataframe of artists_uri, it returns a mapping pos -> artist_uri in order to map each artist_uri to a position inside the embedding vector\n",
        "  \"\"\"\n",
        "  artists_df = get_all_artists(playlist_df, filter_rare)\n",
        "  artists_df.createOrReplaceTempView(\"ARTISTS\")\n",
        "  # Creates a POS column that maps each row to a integer from 0 to n, where n is the number of rows.\n",
        "  artists_df: DataFrame = spark.sql(\"\"\"\n",
        "  SELECT \n",
        "      row_number() OVER (\n",
        "          PARTITION BY '' \n",
        "          ORDER BY '' \n",
        "      ) as pos,\n",
        "      *\n",
        "  FROM \n",
        "      ARTISTS\n",
        "  \"\"\")\n",
        "  \n",
        "  # UDF function fo subtract 1, since the pos starts from 1, but I want it to start from 0\n",
        "  sub_udf = F.udf(lambda x: x-1, returnType=IntegerType())\n",
        "\n",
        "  artists_df = artists_df.withColumnRenamed(\"pos\", \"old_pos\").withColumn(\"pos\", sub_udf(F.col(\"old_pos\"))).drop(\"old_pos\")\n",
        "  artists_df = artists_df.sort(\"artist_uri\")\n",
        "\n",
        "  ARTIST_VECTOR_LENGTH = artists_df.count()\n",
        "\n",
        "  return artists_df, ARTIST_VECTOR_LENGTH\n",
        "\n",
        "\n",
        "def create_artists_vector(playlist_df: DataFrame, artist_uri_to_id: dict, vector_length) -> DataFrame:\n",
        "    \"\"\"\n",
        "    Returns a DataFrames containing the playlists, but the tracks are represented as a binary sparse vector.\n",
        "    \"\"\"\n",
        "\n",
        "    @F.udf(returnType=VectorUDT())\n",
        "    def extract_vector(tracks):\n",
        "      pos_list = set()\n",
        "\n",
        "      def reduce_fn(pos_list, row):\n",
        "        if row.artist_uri in artist_uri_to_id:\n",
        "          pos_list.add(artist_uri_to_id.get(row.artist_uri))\n",
        "        return pos_list\n",
        "      \n",
        "      pos_list = reduce(reduce_fn, tracks, pos_list)\n",
        "      \n",
        "      return SparseVector(vector_length, sorted(list(pos_list)), [1 for _ in pos_list])\n",
        "\n",
        "    # Apply the mapping UDF on the \"tracks\" column of the slice_df dataframe\n",
        "    mapped_df = playlist_df.withColumn('tracks', extract_vector(F.col('tracks')))\n",
        "\n",
        "    return mapped_df\n",
        "\n",
        "def artist_pipeline(playlist_df: DataFrame, save_name: str) -> DataFrame:\n",
        "  if os.path.exists(save_name) and not OVERRIDE:\n",
        "    artists_slice_df = spark.read.schema(playlist_schema_mapped).json(save_name)\n",
        "    return artists_slice_df\n",
        "  \n",
        "  artists_slice_df = create_artists_vector(playlist_df,\n",
        "                                           artist_uri_to_id, \n",
        "                                           FILTERED_ARTIST_VECTOR_LENGTH).cache()\n",
        "  \n",
        "  artists_slice_df.write.mode(\"overwrite\").json(save_name)\n",
        "  \n",
        "  return artists_slice_df\n",
        "\n",
        "#I've not implemented the code to not \"filter rare\" the artist because I don't need it.\n",
        "filtered_artist_mapping, FILTERED_ARTIST_VECTOR_LENGTH = create_artists_pos_mapping(slice_df, filter_rare=False) #Should be True, but false for now\n",
        "with open(ARTIST_VECTOR_LENGTH_PATH, \"w\") as f:\n",
        "  f.write('%d' % FILTERED_ARTIST_VECTOR_LENGTH)\n",
        "\n",
        "artist_uri_to_id = filtered_artist_mapping.select('artist_uri', 'pos').rdd.collectAsMap()\n",
        "\n",
        "artist_slice_df_train = artist_pipeline(nn_train_df, save_name=ARTISTS_EMBEDDINGS_TRAIN)\n",
        "artist_slice_df_test_train = artist_pipeline(nn_test_train_df, save_name=ARTISTS_EMBEDDINGS_TEST_TRAIN)\n",
        "artist_slice_df_test_test = artist_pipeline(nn_test_test_df, save_name=ARTISTS_EMBEDDINGS_TEST_TEST)\n",
        "\n",
        "artist_slice_df_eval = artist_pipeline(nn_eval_df, save_name=ARTISTS_EMBEDDINGS_EVAL)\n",
        "artist_slice_df_eval_train = artist_pipeline(nn_eval_train_df, save_name=ARTISTS_EMBEDDINGS_EVAL_TRAIN)\n",
        "artist_slice_df_eval_test = artist_pipeline(nn_eval_test_df, save_name=ARTISTS_EMBEDDINGS_EVAL_TEST)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 49:>                                                         (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+---+\n",
            "|          artist_uri|pos|\n",
            "+--------------------+---+\n",
            "|spotify:artist:1v...|  0|\n",
            "|spotify:artist:6i...|  1|\n",
            "|spotify:artist:1X...|  2|\n",
            "|spotify:artist:73...|  3|\n",
            "|spotify:artist:1H...|  4|\n",
            "|spotify:artist:6P...|  5|\n",
            "|spotify:artist:2q...|  6|\n",
            "|spotify:artist:2o...|  7|\n",
            "|spotify:artist:5l...|  8|\n",
            "|spotify:artist:6t...|  9|\n",
            "|spotify:artist:0A...| 10|\n",
            "|spotify:artist:7c...| 11|\n",
            "|spotify:artist:0c...| 12|\n",
            "|spotify:artist:7i...| 13|\n",
            "|spotify:artist:6L...| 14|\n",
            "|spotify:artist:5I...| 15|\n",
            "|spotify:artist:34...| 16|\n",
            "|spotify:artist:47...| 17|\n",
            "|spotify:artist:1l...| 18|\n",
            "|spotify:artist:0k...| 19|\n",
            "+--------------------+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "filtered_artist_mapping.orderBy(\"pos\").show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5EsUj1vODdXy"
      },
      "source": [
        "## Get the tracks vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ztcTMr3wDf2J"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "def get_all_songs(playlist_df: DataFrame, filter_rare: bool = False) -> DataFrame:\n",
        "  \"\"\"\n",
        "  Given a playlist dataframe, returns the dataframe containing the unique list of track_uri that are present in all the playlists.\n",
        "  \"\"\"\n",
        "  if filter_rare:\n",
        "    all_songs = playlist_df.select(F.explode(\"tracks.track_uri\").alias(\"track_uri\")) \\\n",
        "            .groupBy(\"track_uri\") \\\n",
        "            .agg(F.count(\"*\").alias(\"count\")) \\\n",
        "            .filter(F.col(\"count\") >= 5)\n",
        "  else:\n",
        "    all_songs = playlist_df.select(F.explode(\"tracks.track_uri\").alias(\"track_uri\")).distinct()\n",
        "  return all_songs\n",
        "\n",
        "def create_songs_pos_mapping(playlist_df: DataFrame, filter_rare: bool = False) -> Tuple[DataFrame, int]:\n",
        "  \"\"\"\n",
        "  Given the dataframe of tracks_uris, it returns a mapping pos -> track_uri in order to map each track_uri to a position inside the embedding vector\n",
        "  \"\"\"\n",
        "  songs_df = get_all_songs(playlist_df, filter_rare)\n",
        "  songs_df.createOrReplaceTempView(\"SONGS_INFO\")\n",
        "\n",
        "  songs_df = spark.sql(\"\"\"\n",
        "  SELECT \n",
        "      row_number() OVER (\n",
        "          PARTITION BY '' \n",
        "          ORDER BY '' \n",
        "      ) as pos,\n",
        "      *\n",
        "  FROM \n",
        "      SONGS_INFO\n",
        "  \"\"\")\n",
        "  \n",
        "  sub_udf = F.udf(lambda x: x-1, returnType=IntegerType())\n",
        "  songs_df = songs_df.withColumnRenamed(\"pos\", \"old_pos\").withColumn(\"pos\", sub_udf(F.col(\"old_pos\"))).drop(\"old_pos\")\n",
        "\n",
        "  RATING_VECTOR_LENGTH = songs_df.count()\n",
        "\n",
        "  return songs_df, RATING_VECTOR_LENGTH\n",
        "\n",
        "\n",
        "def map_track_df_to_pos(playlist_df: DataFrame, track_uri_to_id: dict, vector_length: int) -> DataFrame:\n",
        "    \"\"\"\n",
        "    Returns a DataFrames containing the playlists, but the tracks are represented as a binary sparse vector.\n",
        "    \"\"\"\n",
        "\n",
        "    @F.udf(returnType=VectorUDT())\n",
        "    def extract_vector(tracks):\n",
        "      pos_list = set()\n",
        "\n",
        "      def reduce_fn(pos_list, row):\n",
        "        if row.track_uri in track_uri_to_id:\n",
        "          pos_list.add(track_uri_to_id.get(row.track_uri))\n",
        "        return pos_list\n",
        "      \n",
        "      pos_list = reduce(reduce_fn, tracks, pos_list)\n",
        "      \n",
        "      return SparseVector(vector_length, sorted(list(pos_list)), [1 for _ in pos_list])\n",
        "\n",
        "    # Apply the mapping UDF on the \"tracks\" column of the slice_df dataframe\n",
        "    mapped_df = playlist_df.withColumn('tracks', extract_vector(F.col('tracks')))\n",
        "\n",
        "    return mapped_df\n",
        "\n",
        "def track_pipeline(playlist_df: DataFrame, save_name: str, filter_rare: bool = False) -> DataFrame:\n",
        "  if os.path.exists(save_name) and not OVERRIDE:\n",
        "    song_embeddings_df = spark.read.schema(playlist_schema_mapped).json(save_name)\n",
        "    return song_embeddings_df\n",
        "\n",
        "  track_mapping = track_uri_to_id if not filter_rare else filtered_track_uri_to_id\n",
        "  vector_length = SONG_VECTOR_LENGTH if not filter_rare else FILTERED_SONG_VECTOR_LENGTH\n",
        "  song_embeddings_df = map_track_df_to_pos(playlist_df, \n",
        "                                       track_mapping, \n",
        "                                       vector_length).cache()\n",
        "\n",
        "  song_embeddings_df.write.mode(\"overwrite\").json(save_name)\n",
        "  \n",
        "  return song_embeddings_df\n",
        "\n",
        "\n",
        "song_mapping, SONG_VECTOR_LENGTH = create_songs_pos_mapping(slice_df)\n",
        "filtered_song_mapping, FILTERED_SONG_VECTOR_LENGTH = create_songs_pos_mapping(slice_df, filter_rare=False)\n",
        "\n",
        "with open(SONGS_VECTOR_LENGTH_PATH, \"w\") as f:\n",
        "  f.write('%d' % SONG_VECTOR_LENGTH)\n",
        "with open(FILTERED_SONGS_VECTOR_LENGTH_PATH, \"w\") as f:\n",
        "  f.write('%d' % FILTERED_SONG_VECTOR_LENGTH)\n",
        "\n",
        "track_uri_to_id = song_mapping.select('track_uri', 'pos').rdd.collectAsMap()\n",
        "filtered_track_uri_to_id = filtered_song_mapping.select('track_uri', 'pos').rdd.collectAsMap()\n",
        "\n",
        "song_mapping.write.mode(\"overwrite\").json(SONGS_INFO_DF)\n",
        "filtered_song_mapping.write.mode(\"overwrite\").json(FILTERED_SONGS_INFO_DF)\n",
        "\n",
        "songs_embeddings = track_pipeline(slice_df, save_name=SONGS_EMBEDDINGS_PATH)\n",
        "songs_slice_df_train = track_pipeline(train_df, save_name=SONGS_EMBEDDINGS_TRAIN)\n",
        "songs_slice_df_test = track_pipeline(test_df, save_name=SONGS_EMBEDDINGS_TEST)\n",
        "\n",
        "nn_songs_slice_df_train = track_pipeline(nn_train_df, filter_rare=False, save_name=NN_SONGS_EMBEDDINGS_TRAIN)\n",
        "nn_songs_slice_df_test_train = track_pipeline(nn_test_train_df, filter_rare=False, save_name=NN_SONGS_EMBEDDINGS_TEST_TRAIN) #This should be True, but for now is False\n",
        "nn_songs_slice_df_test_test = track_pipeline(nn_test_test_df, filter_rare=False, save_name=NN_SONGS_EMBEDDINGS_TEST_TEST)\n",
        "\n",
        "nn_songs_slice_df_eval = track_pipeline(nn_eval_df, filter_rare=False, save_name=NN_SONGS_EMBEDDINGS_EVAL)\n",
        "nn_songs_slice_df_eval_train = track_pipeline(nn_eval_train_df, filter_rare=False, save_name=NN_SONGS_EMBEDDINGS_EVAL_TRAIN) #This should be True, but for now is False\n",
        "nn_songs_slice_df_eval_test = track_pipeline(nn_eval_test_df, filter_rare=False, save_name=NN_SONGS_EMBEDDINGS_EVAL_TEST)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBY7sY0P-Jtl",
        "outputId": "4bc5cd20-418c-4caf-e690-2dde54bdaf36"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+---+\n",
            "|           track_uri|pos|\n",
            "+--------------------+---+\n",
            "|spotify:track:1mr...|  0|\n",
            "|spotify:track:1Uv...|  1|\n",
            "|spotify:track:4WR...|  2|\n",
            "|spotify:track:7B6...|  3|\n",
            "|spotify:track:2Gy...|  4|\n",
            "|spotify:track:7AO...|  5|\n",
            "|spotify:track:48Z...|  6|\n",
            "|spotify:track:1Um...|  7|\n",
            "|spotify:track:7MO...|  8|\n",
            "|spotify:track:27P...|  9|\n",
            "|spotify:track:6lt...| 10|\n",
            "|spotify:track:1yz...| 11|\n",
            "|spotify:track:5Mz...| 12|\n",
            "|spotify:track:3BU...| 13|\n",
            "|spotify:track:4Cl...| 14|\n",
            "|spotify:track:2dN...| 15|\n",
            "|spotify:track:341...| 16|\n",
            "|spotify:track:7ja...| 17|\n",
            "|spotify:track:4eQ...| 18|\n",
            "|spotify:track:6fy...| 19|\n",
            "+--------------------+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(None, 681805)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "song_mapping.show(), song_mapping.count()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "J1q5NS7aSrEc"
      },
      "source": [
        "## Get the Item-based dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7JxlnY0UJy9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "def create_playlists_pos_mapping(playlist_df: DataFrame) -> Tuple[DataFrame, int]:\n",
        "  \"\"\"\n",
        "  Returns the dataframe that maps each playlist pid to a position, and the total number of playlists in the dataframe.\n",
        "  \"\"\"\n",
        "  playlist_df.createOrReplaceTempView(\"PLAYLISTS_INFO\")\n",
        "\n",
        "  playlist_df = spark.sql(\"\"\"\n",
        "  SELECT \n",
        "      row_number() OVER (\n",
        "          PARTITION BY '' \n",
        "          ORDER BY '' \n",
        "      ) as pos,\n",
        "      *\n",
        "  FROM \n",
        "      PLAYLISTS_INFO\n",
        "  \"\"\")\n",
        "  \n",
        "  sub_udf = F.udf(lambda x: x-1, returnType=IntegerType())\n",
        "  playlist_df = playlist_df.withColumnRenamed(\"pos\", \"old_pos\").withColumn(\"pos\", sub_udf(F.col(\"old_pos\"))).drop(\"old_pos\")\n",
        "  playlist_df = playlist_df.select(\"pid\", \"pos\").sort(\"pid\").cache()\n",
        "  PLAYLIST_VECTOR_LENGTH = playlist_df.count()\n",
        "  return playlist_df, PLAYLIST_VECTOR_LENGTH\n",
        "\n",
        "playlist_map, PLAYLIST_VECTOR_LENGTH = create_playlists_pos_mapping(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybAIbRP6T-uX"
      },
      "outputs": [],
      "source": [
        "playlist_pid_to_id = playlist_map.rdd.collectAsMap()\n",
        "\n",
        "def create_playlist_vector(playlist_df: DataFrame) -> DataFrame:\n",
        "    \"\"\"\n",
        "    Returns a DataFrames containing the track uris mapped to a list of playlist. The list of playlists is represented as a binary sparse vector.\n",
        "    \"\"\"\n",
        "    exploded_df = playlist_df.select(\"tracks\", \"pid\").withColumn(\"track_uri\", F.explode(\"tracks.track_uri\"))\n",
        "    new_df = exploded_df.groupBy(\"track_uri\").agg(F.collect_list(\"pid\").alias(\"pid\"))\n",
        "\n",
        "    @F.udf(returnType=VectorUDT())\n",
        "    def extract_vector(row):\n",
        "      pos_list = set(playlist_pid_to_id.get(pid) for pid in row)\n",
        "      \n",
        "      return SparseVector(NUM_PLAYLISTS, sorted(list(pos_list)), [1 for _ in pos_list])\n",
        "\n",
        "    # Apply the mapping UDF on the \"tracks\" column of the slice_df dataframe\n",
        "    mapped_df = new_df.withColumn('embedding', extract_vector(F.col('pid'))).drop(\"pid\")\n",
        "\n",
        "    return mapped_df\n",
        "\n",
        "playlist_mapped = create_playlist_vector(slice_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-324eStVbv2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "PLAYLIST_MAP_PATH = os.path.join(SAVED_DFS_PATH, f\"playlist_map-{NUM_PLAYLISTS}.json\")\n",
        "PID_TO_ID_PATH = os.path.join(SAVED_DFS_PATH, f\"playlist_pid_to_id-{NUM_PLAYLISTS}.json\")\n",
        "playlist_mapped.write.mode(\"overwrite\").json(PLAYLIST_MAP_PATH)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TBMBeTCsP48X"
      },
      "source": [
        "# Upload the songs into the Database for the Webapp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFlGiyNQQuwU"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/23 03:12:55 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
          ]
        }
      ],
      "source": [
        "def get_all_songs_w_info(playlist_df: DataFrame) -> DataFrame:\n",
        "  \"\"\"\n",
        "  Given a playlist dataframe, returns the dataframe containing the unique list of songs with their relative info withing the entire playlist dataset.\n",
        "  \"\"\"\n",
        "  all_songs = playlist_df.select(F.explode(\"tracks\")).select('col.*').drop(\"pos\").distinct()\n",
        "  return all_songs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byhH1-K_TAs2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "all_songs_w_info = get_all_songs_w_info(slice_df).collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c6fb824db598492d9803af830d179ffe",
            "4e7f65e850c94eff85877012f33414ed",
            "0c31c062006740018c56c6b2df9b1d8b",
            "40a1fef6446a4342b14c81eabb926a3e",
            "9e9887de827c4d19b7eb636c5682928f",
            "bd085677f529464196cc585ad7c8ecc1",
            "d098cf8acbc04b77a9eb1fd0c4dde68b",
            "cfa31440a39c4f3585d6af25f8d49233",
            "13880fb8337445bb94b35c0df22b8707",
            "975c449bf9fc42f2b00b7152b6ec302a",
            "3defa76cd2e6451998c72607237c4f19"
          ]
        },
        "id": "Ma-yqJNhP2RG",
        "outputId": "112cd6ca-efdb-4cd1-8bd8-12195f69f3ce"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c732376b2a14f61a4f919961ba2957a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/137 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "BASE_URL = \"http://localhost:3004\"\n",
        "CREATE_SONG = f\"{BASE_URL}/create-songs-batch\"\n",
        "\n",
        "BATCH_SIZE = 5000\n",
        "for index in tqdm(range(0, len(all_songs_w_info), BATCH_SIZE)):\n",
        "  start_index = index + BATCH_SIZE\n",
        "  end_index = min(len(all_songs_w_info)-1, start_index + BATCH_SIZE)\n",
        "  songs = all_songs_w_info[start_index:end_index]\n",
        "  data = []\n",
        "  for i, row in enumerate(songs):\n",
        "    body = {\n",
        "      \"id\": start_index + i,\n",
        "      \"name\": str(row.track_name),\n",
        "      \"artist\": str(row.artist_name),\n",
        "      \"album\": str(row.album_name),\n",
        "      \"duration\": int(row.duration_ms),\n",
        "      \"song_uri\": row.track_uri,\n",
        "      \"album_uri\": row.album_uri,\n",
        "      \"song_artist_concat\": f\"{row.track_name} {row.artist_name}\"\n",
        "    }\n",
        "    data.append(body)\n",
        "  requests.post(CREATE_SONG, json=data)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPbciytrFnhNPExg4p+vYmT",
      "collapsed_sections": [
        "KOojFseRjVnN",
        "X-s_eNiVaxhn"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c31c062006740018c56c6b2df9b1d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfa31440a39c4f3585d6af25f8d49233",
            "max": 137,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13880fb8337445bb94b35c0df22b8707",
            "value": 137
          }
        },
        "13880fb8337445bb94b35c0df22b8707": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e61087f826b4a818455d838870841b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed832a833b7149e3be7ff208755a3f04",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1fb9cc7bf3145eb9c15a6e71551dc8d",
            "value": 44
          }
        },
        "3defa76cd2e6451998c72607237c4f19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40a1fef6446a4342b14c81eabb926a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_975c449bf9fc42f2b00b7152b6ec302a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3defa76cd2e6451998c72607237c4f19",
            "value": " 137/137 [06:27&lt;00:00,  2.26s/it]"
          }
        },
        "461d96c9e09144c29caff1f9f02a871a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5274823fc7134851835d3875a38f780a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f0a9f828880f49ce83a384881f0d9c64",
            "value": " 44/100 [1:18:50&lt;1:43:22, 110.77s/it]"
          }
        },
        "4e7f65e850c94eff85877012f33414ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd085677f529464196cc585ad7c8ecc1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d098cf8acbc04b77a9eb1fd0c4dde68b",
            "value": "100%"
          }
        },
        "5274823fc7134851835d3875a38f780a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d1d20beeb03402795c47c1f419bc22b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b3f11a17ea04e3b8f4ce9e748e25972": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a475aa00b3c148479b5c80cd873c76a0",
              "IPY_MODEL_2e61087f826b4a818455d838870841b5",
              "IPY_MODEL_461d96c9e09144c29caff1f9f02a871a"
            ],
            "layout": "IPY_MODEL_ff97d41fc76848969a807e0e1d1c0089"
          }
        },
        "7e88f1a3aa804b68ad6cdac59f935ef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "975c449bf9fc42f2b00b7152b6ec302a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e9887de827c4d19b7eb636c5682928f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a475aa00b3c148479b5c80cd873c76a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d1d20beeb03402795c47c1f419bc22b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7e88f1a3aa804b68ad6cdac59f935ef9",
            "value": " 44%"
          }
        },
        "bd085677f529464196cc585ad7c8ecc1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6fb824db598492d9803af830d179ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e7f65e850c94eff85877012f33414ed",
              "IPY_MODEL_0c31c062006740018c56c6b2df9b1d8b",
              "IPY_MODEL_40a1fef6446a4342b14c81eabb926a3e"
            ],
            "layout": "IPY_MODEL_9e9887de827c4d19b7eb636c5682928f"
          }
        },
        "cfa31440a39c4f3585d6af25f8d49233": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d098cf8acbc04b77a9eb1fd0c4dde68b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1fb9cc7bf3145eb9c15a6e71551dc8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed832a833b7149e3be7ff208755a3f04": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0a9f828880f49ce83a384881f0d9c64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff97d41fc76848969a807e0e1d1c0089": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
