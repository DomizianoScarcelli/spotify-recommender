{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "VJeY9PpvaHUJ"
      ],
      "authorship_tag": "ABX9TyPPU8QD4EuaXqVJ/PaUZUvT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DomizianoScarcelli/big-data-project/blob/item-based-cf/item_based_CF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOojFseRjVnN"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N3wVgRfHYoOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51d43437-9d3d-4c8f-fc4f-9301b6875c6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "The following additional packages will be installed:\n",
            "  libxtst6 openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  libxtst6 openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 3 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 36.5 MB of archives.\n",
            "After this operation, 144 MB of additional disk space will be used.\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "(Reading database ... 122542 files and directories currently installed.)\n",
            "Preparing to unpack .../libxtst6_2%3a1.2.3-1_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u372-ga~us1-0ubuntu1~20.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u372-ga~us1-0ubuntu1~20.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u372-ga~us1-0ubuntu1~20.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u372-ga~us1-0ubuntu1~20.04) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u372-ga~us1-0ubuntu1~20.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u372-ga~us1-0ubuntu1~20.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n"
          ]
        }
      ],
      "source": [
        "#@title Download necessary libraries\n",
        "!pip install pyspark -qq\n",
        "!pip install -U -q PyDrive -qq\n",
        "!apt install openjdk-8-jdk-headless -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "CGHPv9OqY9MI",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import plotly\n",
        "\n",
        "import pyspark\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql import SparkSession, DataFrame, Row\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType, FloatType, LongType\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.ml.linalg import SparseVector, DenseVector, VectorUDT\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "import gc\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "from typing import Tuple, Callable, Dict\n",
        "from functools import reduce\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JF8LUBZeYiWP"
      },
      "outputs": [],
      "source": [
        "#@title Set up variables\n",
        "JAVA_HOME = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "GDRIVE_DIR = \"/content/drive\"\n",
        "GDRIVE_HOME_DIR = GDRIVE_DIR + \"/MyDrive\"\n",
        "GDRIVE_DATA_DIR = GDRIVE_HOME_DIR + \"/Big Data/datasets\"\n",
        "DATASET_FILE = os.path.join(GDRIVE_DATA_DIR, \"pyspark_friendly_spotify_playlist_dataset\")\n",
        "AUDIO_FEATURES_FILE = os.path.join(GDRIVE_DATA_DIR, \"pyspark_track_features\")\n",
        "LITTLE_SLICE_FILE = os.path.join(GDRIVE_DATA_DIR, \"little_slice\")\n",
        "SMALL_SLICE_FLIE = os.path.join(GDRIVE_DATA_DIR, \"small_slice\")\n",
        "LITTLE_SLICE_AUDIO_FEATURES = os.path.join(GDRIVE_DATA_DIR, \"little_slice_audio_features\")\n",
        "MICRO_SLICE_AUDIO_FEATURES = os.path.join(GDRIVE_DATA_DIR, \"micro_slice_audio_features\")\n",
        "SPLITTED_SLICE_AUDIO_FEATURES = os.path.join(GDRIVE_DATA_DIR, \"splitted_pyspark_track_features\")\n",
        "SAVED_DFS_PATH = os.path.join(GDRIVE_DATA_DIR, \"saved_dfs\")\n",
        "RANDOM_SEED = 42 # for reproducibility\n",
        "os.environ[\"JAVA_HOME\"] = JAVA_HOME\n",
        "os.environ[\"PYSPARK_PYTHON\"]=\"python\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "4m7VztzdZgm6"
      },
      "outputs": [],
      "source": [
        "#@title Create the session\n",
        "conf = SparkConf().\\\n",
        "                set('spark.ui.port', \"4050\").\\\n",
        "                set('spark.executor.memory', '12G').\\\n",
        "                set('spark.driver.memory', '12G').\\\n",
        "                set('spark.driver.maxResultSize', '100G').\\\n",
        "                set(\"spark.executor.extraJavaOptions\", \"-XX:+UseG1GC\").\\\n",
        "                setAppName(\"PySparkTutorial\").\\\n",
        "                setMaster(\"local[*]\")\n",
        "\n",
        "# Create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vsX5d-YXZ2Ul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "940b8a79-dedb-4797-81dc-6939fea4ef81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount(GDRIVE_DIR, force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-s_eNiVaxhn"
      },
      "source": [
        "## Setup ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LrnLYquoarPa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82fa3569-0486-4f71-8fba-1294eeea31d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-6.0.0.tar.gz (681 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m681.2/681.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-6.0.0-py3-none-any.whl size=19867 sha256=2ea0a405e8556616b824cf5e74e3a0de743138af7c027d85c1854fda75c496e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/42/78/0c3d438d7f5730451a25f7ac6cbf4391759d22a67576ed7c2c\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-6.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "K3IEuiyDawo3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63a8134e-8052-437c-d37e-73fc4a2a8549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken 2NVN8kdoOnMVtlDGGWtwsbT5M3Q_2EJv2HE77FEXkz978Qtnq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0qJN-lfta1ok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32cad61b-7354-412a-ae5a-ac791ea4002f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-06-02T13:49:23+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Open a ngrok tunnel on the port 4050 where Spark is running\n",
        "port = '4050'\n",
        "public_url = ngrok.connect(port).public_url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "x15LhY-5a3Yi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be9cd32f-6675-45d7-bdc9-2c5d00c28d50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To access the Spark Web UI console, please click on the following link to the ngrok tunnel \"https://b291-35-231-110-172.ngrok-free.app\" -> \"http://127.0.0.1:4050\"\n"
          ]
        }
      ],
      "source": [
        "print(\"To access the Spark Web UI console, please click on the following link to the ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:{}\\\"\".format(public_url, port))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "cellView": "form",
        "id": "jlxfJiBSZ6ju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f050c584-c964-49bd-da77-215691cb5fef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<pyspark.sql.session.SparkSession at 0x7fa7225d0250>,\n",
              " [('spark.driver.port', '35661'),\n",
              "  ('spark.executor.extraJavaOptions',\n",
              "   '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false -XX:+UseG1GC'),\n",
              "  ('spark.app.name', 'PySparkTutorial'),\n",
              "  ('spark.app.startTime', '1685713733484'),\n",
              "  ('spark.app.submitTime', '1685713733216'),\n",
              "  ('spark.driver.host', 'b50a9ced431e'),\n",
              "  ('spark.executor.id', 'driver'),\n",
              "  ('spark.app.id', 'local-1685713738197'),\n",
              "  ('spark.driver.extraJavaOptions',\n",
              "   '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false'),\n",
              "  ('spark.ui.port', '4050'),\n",
              "  ('spark.rdd.compress', 'True'),\n",
              "  ('spark.driver.memory', '12G'),\n",
              "  ('spark.serializer.objectStreamReset', '100'),\n",
              "  ('spark.master', 'local[*]'),\n",
              "  ('spark.submit.pyFiles', ''),\n",
              "  ('spark.driver.maxResultSize', '100G'),\n",
              "  ('spark.submit.deployMode', 'client'),\n",
              "  ('spark.executor.memory', '12G'),\n",
              "  ('spark.ui.showConsoleProgress', 'true')])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#@title Check if everything is ok\n",
        "spark, sc._conf.getAll()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJeY9PpvaHUJ"
      },
      "source": [
        "# Data acquisition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "icd2lj-RRvhU"
      },
      "outputs": [],
      "source": [
        "song_schema = StructType([\n",
        "    StructField(\"pos\", IntegerType(), True),\n",
        "    StructField(\"artist_name\", StringType(), True),\n",
        "    StructField(\"track_uri\", StringType(), True),\n",
        "    StructField(\"artist_uri\", StringType(), True),\n",
        "    StructField(\"track_name\", StringType(), True),\n",
        "    StructField(\"album_uri\", StringType(), True),\n",
        "    StructField(\"duration_ms\", LongType(), True),\n",
        "    StructField(\"album_name\", StringType(), True)\n",
        "])\n",
        "\n",
        "playlist_schema = StructType([\n",
        "    StructField(\"name\", StringType(), True),\n",
        "    StructField(\"collaborative\", StringType(), True),\n",
        "    StructField(\"pid\", IntegerType(), True),\n",
        "    StructField(\"modified_at\", IntegerType(), True),\n",
        "    StructField(\"num_tracks\", IntegerType(), True),\n",
        "    StructField(\"num_albums\", IntegerType(), True),\n",
        "    StructField(\"num_followers\", IntegerType(), True),\n",
        "    StructField(\"tracks\", ArrayType(song_schema), True),\n",
        "    StructField(\"num_edits\", IntegerType(), True),\n",
        "    StructField(\"duration_ms\", IntegerType(), True),\n",
        "    StructField(\"num_artists\", IntegerType(), True),\n",
        "])\n",
        "\n",
        "playlist_schema_mapped = StructType([\n",
        "    StructField(\"name\", StringType(), True),\n",
        "    StructField(\"collaborative\", StringType(), True),\n",
        "    StructField(\"pid\", IntegerType(), True),\n",
        "    StructField(\"modified_at\", IntegerType(), True),\n",
        "    StructField(\"num_tracks\", IntegerType(), True),\n",
        "    StructField(\"num_albums\", IntegerType(), True),\n",
        "    StructField(\"num_followers\", IntegerType(), True),\n",
        "    StructField(\"tracks\", VectorUDT(), True),\n",
        "    StructField(\"num_edits\", IntegerType(), True),\n",
        "    StructField(\"duration_ms\", IntegerType(), True),\n",
        "    StructField(\"num_artists\", IntegerType(), True),\n",
        "])\n",
        "\n",
        "audio_features_schema = StructType([\n",
        "    StructField(\"danceability\", FloatType(), True),\n",
        "    StructField(\"energy\", FloatType(), True),\n",
        "    StructField(\"key\", IntegerType(), True),\n",
        "    StructField(\"loudness\", FloatType(), True),\n",
        "    StructField(\"mode\", IntegerType(), True),\n",
        "    StructField(\"speechiness\", FloatType(), True),\n",
        "    StructField(\"acousticness\", FloatType(), True),\n",
        "    StructField(\"instrumentalness\", FloatType(), True),\n",
        "    StructField(\"liveness\", FloatType(), True),\n",
        "    StructField(\"valence\", FloatType(), True),\n",
        "    StructField(\"tempo\", FloatType(), True),\n",
        "    StructField(\"type\", StringType(), True),\n",
        "    StructField(\"id\", StringType(), True),\n",
        "    StructField(\"uri\", StringType(), True),\n",
        "    StructField(\"track_href\", StringType(), True),\n",
        "    StructField(\"analysis_url\", StringType(), True),\n",
        "    StructField(\"duration_ms\", LongType(), True),\n",
        "    StructField(\"time_signature\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BY_szFyLTps4"
      },
      "outputs": [],
      "source": [
        "playlist_df = spark.read.schema(playlist_schema).json(DATASET_FILE, multiLine=True)\n",
        "slice_df = spark.read.schema(playlist_schema).json(SMALL_SLICE_FLIE, multiLine=True)\n",
        "# slice_df = spark.read.schema(playlist_schema).json(LITTLE_SLICE_FILE, multiLine=True)\n",
        "audio_df = spark.read.schema(audio_features_schema).json(SPLITTED_SLICE_AUDIO_FEATURES, multiLine=True) #has less songs than expected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PEI_1vcSPxOG"
      },
      "outputs": [],
      "source": [
        "# slice_df.select(\"tracks\").first()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gnNiOotq3p3f"
      },
      "outputs": [],
      "source": [
        "# slice_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Item-Based Collaborative Filtering"
      ],
      "metadata": {
        "id": "p211b9samoI9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Item-Based Collaboartive Filtering is the \"transpose\" approach to user-based CF. This time we won't consider the users' feature vectors, but the items'.\n",
        "An item's rating vector $\\mathbf{r}_i$ is the vector of ratings given to the item $i$ for all the users.\n",
        "\n",
        "Let $m$ be the number of users, $n$ the number of playlists, then $\\mathbf{r}_i \\in \\mathbb{R}^m$ and $\\mathbf{R} \\in \\mathbb{R}^{m \\times n}$.\n",
        "\n",
        "In order to make a prediction, we take the set of items $I_u$ rated by the user $u$, and we compute the set $I^k_u$ of the top-$k$ most similar items to $i$ rated by $u$, for each item $i \\in I_u$. Once done that, we average the $k$ rating vectors weighting them by their respective similarity."
      ],
      "metadata": {
        "id": "1pR8c5Ro5_DI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# slice_df = slice_df.cache()"
      ],
      "metadata": {
        "id": "8n4nUj_wSJeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEBUG = True"
      ],
      "metadata": {
        "id": "wSg4hiaeewgY"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_PLAYLISTS = 100_000\n",
        "SONGS_EMBEDDINGS_PATH = os.path.join(SAVED_DFS_PATH, f\"songs_embeddings-train-{NUM_PLAYLISTS}.json\")\n",
        "SONGS_INFO_DF = os.path.join(SAVED_DFS_PATH, f\"songs_info_df-train-{NUM_PLAYLISTS}.json\") #TODO: Little bug this is songs_df, meaning it hasn't got any info, but we don't actually care.\n",
        "RATING_VECTOR_LENGTH_PATH = os.path.join(SAVED_DFS_PATH, f\"songs_vector_length-train-{NUM_PLAYLISTS}.txt\")\n",
        "with open(RATING_VECTOR_LENGTH_PATH, \"r\") as f:\n",
        "  RATING_VECTOR_LENGTH = int(f.read()) + 1\n",
        "\n",
        "songs_embeddings = spark.read.schema(playlist_schema_mapped).json(SONGS_EMBEDDINGS_PATH)\n",
        "songs_df = spark.read.json(SONGS_INFO_DF)\n",
        "\n",
        "playlist_map_schema = StructType([\n",
        "    StructField(\"track_uri\", StringType(), True),\n",
        "    StructField(\"embedding\", VectorUDT(), True)\n",
        "])\n",
        "PLAYLIST_MAP_PATH = os.path.join(SAVED_DFS_PATH, f\"playlist_map-{NUM_PLAYLISTS}.json\")\n",
        "playlist_map = spark.read.schema(playlist_map_schema).json(PLAYLIST_MAP_PATH)"
      ],
      "metadata": {
        "id": "dXUCLE9XSKsi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_DF_PATH = os.path.join(SAVED_DFS_PATH, f\"train_df-{NUM_PLAYLISTS}.json\")\n",
        "TEST_DF_PATH = os.path.join(SAVED_DFS_PATH, f\"test_df-{NUM_PLAYLISTS}.json\")\n",
        "\n",
        "train_df = spark.read.schema(playlist_schema).json(TRAIN_DF_PATH)\n",
        "test_df = spark.read.schema(playlist_schema).json(TEST_DF_PATH)"
      ],
      "metadata": {
        "id": "HnchIh93YdaU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard_similarity(vector_1: SparseVector, vector_2: SparseVector) -> float:\n",
        "  \"\"\"\n",
        "  Computes the Jaccard Similarity between two sparse binary vectors\n",
        "  \"\"\"\n",
        "  # Convert SparseVectors to sets\n",
        "  set1 = set(vector_1.indices)\n",
        "  set2 = set(vector_2.indices)\n",
        "\n",
        "  # Calculate the intersection and union of the sets\n",
        "  intersection = len(set1.intersection(set2))\n",
        "  union = len(set1.union(set2))\n",
        "\n",
        "  # Calculate the similarity\n",
        "  similarity = intersection / union\n",
        "\n",
        "  return similarity"
      ],
      "metadata": {
        "id": "eaPyxrxMZClT"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_similarity_df(input_vector: DataFrame, playlist_map: DataFrame, similarityFunction: Callable) -> DataFrame:\n",
        "  \"\"\"\n",
        "  Returns the similarity df for a single song\n",
        "  \"\"\"\n",
        "  \n",
        "  input_vector_cached = input_vector.cache()\n",
        "  input_vector = input_vector.first()[0]\n",
        "  \n",
        "  @F.udf(returnType=FloatType())\n",
        "  def compute_similarity(vector1):\n",
        "    return jaccard_similarity(vector1, input_vector)\n",
        "\n",
        "  result_df = playlist_map.withColumn(\"similarity\", compute_similarity(playlist_map.embedding))\n",
        "\n",
        "  input_vector_cached.unpersist()\n",
        "  \n",
        "  return result_df\n",
        "\n",
        "def get_top_k_results(track_uri: str, similarity_df: DataFrame, k: int = 20) -> DataFrame:\n",
        "  return similarity_df.filter((F.col(\"similarity\") > 0) & (F.col(\"track_uri\") != track_uri)).orderBy(F.col(\"similarity\").desc()).limit(k)\n",
        "\n",
        "if DEBUG:\n",
        "  first_song_vector = playlist_map.select(\"embedding\").limit(1)\n",
        "  first_track_uri = playlist_map.select(\"track_uri\").limit(1).first()[0]\n",
        "  similarity_df = create_similarity_df(first_song_vector, playlist_map, jaccard_similarity)\n",
        "  top_k_results = get_top_k_results(first_track_uri, similarity_df)\n",
        "  top_k_results.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmBLSpdtcylv",
        "outputId": "55b63ee8-3fd1-4f47-fa81-7d08dfdf0b4e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+----------+\n",
            "|           track_uri|           embedding|similarity|\n",
            "+--------------------+--------------------+----------+\n",
            "|spotify:track:3HJ...|(100001,[28824],[...|       0.5|\n",
            "|spotify:track:0aT...|(100001,[28824],[...|       0.5|\n",
            "|spotify:track:3Ra...|(100001,[28824],[...|       0.5|\n",
            "|spotify:track:0lm...|(100001,[28824],[...|       0.5|\n",
            "|spotify:track:0on...|(100001,[28824],[...|       0.5|\n",
            "|spotify:track:2uU...|(100001,[28824],[...|       0.5|\n",
            "|spotify:track:1rg...|(100001,[28824],[...|       0.5|\n",
            "|spotify:track:3eJ...|(100001,[28824],[...|       0.5|\n",
            "|spotify:track:1sn...|(100001,[28824],[...|       0.5|\n",
            "|spotify:track:5YG...|(100001,[28824],[...|       0.5|\n",
            "|spotify:track:2JW...|(100001,[28824],[...|       0.5|\n",
            "|spotify:track:657...|(100001,[60767],[...|       0.5|\n",
            "|spotify:track:2jT...|(100001,[28824],[...|       0.5|\n",
            "|spotify:track:6Jd...|(100001,[28824],[...|       0.5|\n",
            "|spotify:track:47w...|(100001,[28824],[...|       0.5|\n",
            "|spotify:track:7LU...|(100001,[28824],[...|       0.5|\n",
            "|spotify:track:5vD...|(100001,[28824],[...|       0.5|\n",
            "|spotify:track:7rU...|(100001,[28824],[...|       0.5|\n",
            "|spotify:track:5yL...|(100001,[28824],[...|       0.5|\n",
            "|spotify:track:7L6...|(100001,[60767],[...|       0.5|\n",
            "+--------------------+--------------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_similar_songs(playlist: DataFrame, playlist_map: DataFrame):\n",
        "  \"\"\"\n",
        "  For each track in the playlist, it extracts the top-k most similar results.\n",
        "  \"\"\"\n",
        "  return"
      ],
      "metadata": {
        "id": "K9UmYW-9eGuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_similarity_df(playlist: DataFrame, playlist_map: DataFrame, similarityFunction: Callable):\n",
        "  # Get the current playlist's tracks\n",
        "  playlist_tracks = playlist.select(F.explode(\"tracks.track_uri\")).withColumnRenamed(\"col\", \"track_uri\")\n",
        "  playlist_tracks.show()\n",
        "  # Let's extract the rating vector for each single track\n",
        "  playlist_tracks_mapped = playlist_tracks.join(playlist_map, \"track_uri\")\n",
        "  playlist_tracks_mapped.show()\n",
        "\n",
        "\n",
        "  @F.udf(returnType=FloatType())\n",
        "  def compute_similarity(input_vector: SparseVector, other_vector: SparseVector):\n",
        "    return jaccard_similarity(input_vector, other_vector)\n",
        "\n",
        "  # for row in playlist_tracks_mapped.collect():\n",
        "  similarity_df = playlist_map.withColumn(\"similarity\", compute_similarity(playlist_tracks_mapped.limit(2).embedding, playlist_map.embedding))\n",
        "  # break\n",
        "  \n",
        "  similarity_df.show()\n",
        "  return\n",
        "\n",
        "first_playlsit = train_df.limit(1).cache()\n",
        "create_similarity_df(first_playlsit, playlist_map, jaccard_similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hs0TGZxlWnLb",
        "outputId": "da0e6003-9d71-4d38-c41e-58f1337afa22"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|           track_uri|\n",
            "+--------------------+\n",
            "|spotify:track:3nN...|\n",
            "|spotify:track:2JE...|\n",
            "|spotify:track:3EL...|\n",
            "|spotify:track:2k0...|\n",
            "|spotify:track:0jd...|\n",
            "|spotify:track:6mD...|\n",
            "|spotify:track:2G8...|\n",
            "|spotify:track:4HG...|\n",
            "|spotify:track:09H...|\n",
            "|spotify:track:08d...|\n",
            "|spotify:track:4lS...|\n",
            "|spotify:track:6JE...|\n",
            "|spotify:track:2dY...|\n",
            "|spotify:track:51I...|\n",
            "|spotify:track:6Jl...|\n",
            "|spotify:track:5WZ...|\n",
            "|spotify:track:4G9...|\n",
            "|spotify:track:5ok...|\n",
            "|spotify:track:38A...|\n",
            "|spotify:track:4u7...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|           track_uri|           embedding|\n",
            "+--------------------+--------------------+\n",
            "|spotify:track:002...|(100001,[1,5324,1...|\n",
            "|spotify:track:0A7...|  (100001,[1],[1.0])|\n",
            "|spotify:track:0AB...|(100001,[1,1893,5...|\n",
            "|spotify:track:0CK...|(100001,[1,492,11...|\n",
            "|spotify:track:0Q7...|(100001,[1,87067,...|\n",
            "|spotify:track:0Xh...|(100001,[1,6685,3...|\n",
            "|spotify:track:0dQ...|(100001,[1,4811,5...|\n",
            "|spotify:track:0xC...|(100001,[1,56885,...|\n",
            "|spotify:track:0zY...|(100001,[1,57566,...|\n",
            "|spotify:track:0zs...|(100001,[1,302,36...|\n",
            "|spotify:track:1Cd...|(100001,[1,74812,...|\n",
            "|spotify:track:1Gh...|(100001,[1,2376,3...|\n",
            "|spotify:track:1Ok...|(100001,[1,4890,1...|\n",
            "|spotify:track:1SS...|(100001,[1,2376,2...|\n",
            "|spotify:track:1d2...|  (100001,[1],[1.0])|\n",
            "|spotify:track:2JE...|(100001,[1,57566,...|\n",
            "|spotify:track:2Wq...|(100001,[1,9145,2...|\n",
            "|spotify:track:2a9...|(100001,[1,5324,1...|\n",
            "|spotify:track:2dY...|(100001,[1,8360,2...|\n",
            "|spotify:track:2jx...|(100001,[1,1038,3...|\n",
            "+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+--------------------+--------------------+----------+\n",
            "|           track_uri|           embedding|similarity|\n",
            "+--------------------+--------------------+----------+\n",
            "|spotify:track:000...|(100001,[28824,60...|       1.0|\n",
            "|spotify:track:000...|(100001,[60352],[...|       1.0|\n",
            "|spotify:track:000...|(100001,[76926],[...|       1.0|\n",
            "|spotify:track:000...|(100001,[79686],[...|       1.0|\n",
            "|spotify:track:000...|(100001,[14092,21...|       1.0|\n",
            "|spotify:track:000...|(100001,[74372],[...|       1.0|\n",
            "|spotify:track:000...|(100001,[8758],[1...|       1.0|\n",
            "|spotify:track:000...|(100001,[70399],[...|       1.0|\n",
            "|spotify:track:001...|(100001,[9796,169...|       1.0|\n",
            "|spotify:track:001...|(100001,[3698,702...|       1.0|\n",
            "|spotify:track:001...|(100001,[92210],[...|       1.0|\n",
            "|spotify:track:001...|(100001,[7110,250...|       1.0|\n",
            "|spotify:track:001...|(100001,[80893],[...|       1.0|\n",
            "|spotify:track:001...|(100001,[50318,63...|       1.0|\n",
            "|spotify:track:001...|(100001,[2270,191...|       1.0|\n",
            "|spotify:track:001...|(100001,[10656,31...|       1.0|\n",
            "|spotify:track:002...|(100001,[93642],[...|       1.0|\n",
            "|spotify:track:002...|(100001,[12674],[...|       1.0|\n",
            "|spotify:track:002...|(100001,[43238,87...|       1.0|\n",
            "|spotify:track:002...|(100001,[1,5324,1...|       1.0|\n",
            "+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_playlsit.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbCUU0GzYswY",
        "outputId": "5dfe8f94-7221-4052-b925-0f4054bee181"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "|  name|collaborative| pid|modified_at|num_tracks|num_albums|num_followers|              tracks|num_edits|duration_ms|num_artists|\n",
            "+------+-------------+----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "|disney|        false|1000| 1457827200|       189|        16|            1|[{31, Daughters o...|        4|   31428282|         65|\n",
            "+------+-------------+----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}