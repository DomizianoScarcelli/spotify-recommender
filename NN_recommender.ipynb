{
	"cells": [
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"colab_type": "text",
				"id": "view-in-github"
			},
			"source": [
				"<a href=\"https://colab.research.google.com/github/DomizianoScarcelli/big-data-project/blob/fix-training/NN_recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "XvQ6e0PgCOZg"
			},
			"source": [
				"### Install dependencies"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {
				"id": "XVvKeJoU4hq4"
			},
			"outputs": [],
			"source": [
				"import os\n",
				"def is_running_on_colab():\n",
				"    return \"COLAB_GPU\" in os.environ\n",
				"\n",
				"LOCAL = not is_running_on_colab()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 2,
			"metadata": {
				"colab": {
					"base_uri": "https://localhost:8080/"
				},
				"id": "bjPz4xH4WFYB",
				"outputId": "f5d9d6ce-5c21-4cd0-b480-dce06b97dffd"
			},
			"outputs": [
				{
					"output_type": "stream",
					"name": "stdout",
					"text": [
						"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.0/284.0 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
						"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
						"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
						"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
						"\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
						"  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
						"The following additional packages will be installed:\n",
						"  libxtst6 openjdk-8-jre-headless\n",
						"Suggested packages:\n",
						"  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n",
						"  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
						"  fonts-wqy-zenhei fonts-indic\n",
						"The following NEW packages will be installed:\n",
						"  libxtst6 openjdk-8-jdk-headless openjdk-8-jre-headless\n",
						"0 upgraded, 3 newly installed, 0 to remove and 15 not upgraded.\n",
						"Need to get 36.5 MB of archives.\n",
						"After this operation, 144 MB of additional disk space will be used.\n",
						"Selecting previously unselected package libxtst6:amd64.\n",
						"(Reading database ... 123069 files and directories currently installed.)\n",
						"Preparing to unpack .../libxtst6_2%3a1.2.3-1_amd64.deb ...\n",
						"Unpacking libxtst6:amd64 (2:1.2.3-1) ...\n",
						"Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
						"Preparing to unpack .../openjdk-8-jre-headless_8u372-ga~us1-0ubuntu1~20.04_amd64.deb ...\n",
						"Unpacking openjdk-8-jre-headless:amd64 (8u372-ga~us1-0ubuntu1~20.04) ...\n",
						"Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
						"Preparing to unpack .../openjdk-8-jdk-headless_8u372-ga~us1-0ubuntu1~20.04_amd64.deb ...\n",
						"Unpacking openjdk-8-jdk-headless:amd64 (8u372-ga~us1-0ubuntu1~20.04) ...\n",
						"Setting up libxtst6:amd64 (2:1.2.3-1) ...\n",
						"Setting up openjdk-8-jre-headless:amd64 (8u372-ga~us1-0ubuntu1~20.04) ...\n",
						"update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
						"update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
						"update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
						"Setting up openjdk-8-jdk-headless:amd64 (8u372-ga~us1-0ubuntu1~20.04) ...\n",
						"update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
						"update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
						"update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
						"update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
						"update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
						"update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
						"update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
						"update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
						"update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
						"update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
						"update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
						"update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
						"Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n"
					]
				}
			],
			"source": [
				"if not LOCAL:\n",
				"    !pip install petastorm -qq\n",
				"    !pip install pyspark -qq\n",
				"    !pip install -U -q PyDrive -qq\n",
				"    !apt install openjdk-8-jdk-headless -qq"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 3,
			"metadata": {
				"cellView": "form",
				"id": "oozTtW3om3Ab"
			},
			"outputs": [],
			"source": [
				"#@title Imports\n",
				"import requests\n",
				"import pandas as pd\n",
				"import numpy as np\n",
				"import matplotlib.pyplot as plt\n",
				"%matplotlib inline\n",
				"import plotly\n",
				"\n",
				"import pyspark\n",
				"import pyspark.sql.functions as F\n",
				"from pyspark.sql import SparkSession, DataFrame, Row\n",
				"from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType, FloatType, LongType\n",
				"from pyspark import SparkContext, SparkConf\n",
				"from pyspark.ml.linalg import SparseVector, DenseVector, VectorUDT\n",
				"\n",
				"from tqdm.notebook import tqdm\n",
				"import time\n",
				"import gc\n",
				"\n",
				"if not LOCAL:\n",
				"    from google.colab import drive\n",
				"\n",
				"from typing import Tuple\n",
				"from functools import reduce\n",
				"import pickle\n",
				"import torch\n",
				"from petastorm import make_batch_reader\n",
				"from petastorm.pytorch import DataLoader"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 4,
			"metadata": {
				"id": "XG5sA53iP9z0"
			},
			"outputs": [],
			"source": [
				"#@title Set up variables\n",
				"if not LOCAL:\n",
				"    JAVA_HOME = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
				"    GDRIVE_DIR = \"/content/drive\"\n",
				"    GDRIVE_HOME_DIR = GDRIVE_DIR + \"/MyDrive\"\n",
				"    GDRIVE_DATA_DIR = GDRIVE_HOME_DIR + \"/Big Data/datasets\"\n",
				"    DATASET_FILE = os.path.join(GDRIVE_DATA_DIR, \"pyspark_friendly_spotify_playlist_dataset\")\n",
				"    AUDIO_FEATURES_FILE = os.path.join(GDRIVE_DATA_DIR, \"pyspark_track_features\")\n",
				"    LITTLE_SLICE_FILE = os.path.join(GDRIVE_DATA_DIR, \"little_slice\")\n",
				"    SMALL_SLICE_FLIE = os.path.join(GDRIVE_DATA_DIR, \"small_slice\")\n",
				"    LITTLE_SLICE_AUDIO_FEATURES = os.path.join(GDRIVE_DATA_DIR, \"little_slice_audio_features\")\n",
				"    MICRO_SLICE_AUDIO_FEATURES = os.path.join(GDRIVE_DATA_DIR, \"micro_slice_audio_features\")\n",
				"    SPLITTED_SLICE_AUDIO_FEATURES = os.path.join(GDRIVE_DATA_DIR, \"splitted_pyspark_track_features\")\n",
				"    SAVED_DFS_PATH = os.path.join(GDRIVE_DATA_DIR, \"saved_dfs\")\n",
				"    SAVED_MODELS = os.path.join(GDRIVE_DATA_DIR, \"saved_models\")\n",
				"else:\n",
				"    GDRIVE_DATA_DIR = os.path.abspath(\"./data\")\n",
				"    GDRIVE_HOME_DIR = os.path.abspath(\"./data\")\n",
				"    SAVED_DFS_PATH = os.path.join(GDRIVE_DATA_DIR, \"saved_dfs\")\n",
				"    SAVED_MODELS = os.path.join(GDRIVE_DATA_DIR, \"saved_models\")\n",
				"    JAVA_HOME = \"/opt/homebrew/opt/openjdk\"\n",
				"RANDOM_SEED = 42 # for reproducibility\n",
				"os.environ[\"JAVA_HOME\"] = JAVA_HOME\n",
				"os.environ[\"PYSPARK_PYTHON\"]=\"python\""
			]
		},
		{
			"cell_type": "code",
			"execution_count": 5,
			"metadata": {
				"id": "G20Yir8g4hq6",
				"outputId": "212b55f2-b6c9-4e36-9587-be8ce4037d7a",
				"colab": {
					"base_uri": "https://localhost:8080/"
				},
				"id": "G20Yir8g4hq6",
				"outputId": "6c76f393-18a0-4eb4-c060-ef3b2ebc49d9"
			},
			"outputs": [],
			"source": [
				"if not LOCAL:\n",
				"    drive.mount(GDRIVE_DIR, force_remount=True)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"metadata": {
				"cellView": "form",
				"id": "4m7VztzdZgm6"
			},
			"outputs": [
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"23/06/21 03:38:46 WARN Utils: Your hostname, MacBook-Air-di-Domiziano.local resolves to a loopback address: 127.0.0.1; using 192.168.1.175 instead (on interface en0)\n",
						"23/06/21 03:38:46 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
						"Setting default log level to \"WARN\".\n",
						"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
						"23/06/21 03:38:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
					]
				}
			],
			"source": [
				"#@title Create the session\n",
				"config = SparkConf().\\\n",
				"                set('spark.ui.port', \"4050\").\\\n",
				"                set('spark.executor.memory', '12G').\\\n",
				"                set('spark.driver.memory', '12G').\\\n",
				"                set('spark.driver.maxResultSize', '100G').\\\n",
				"                set(\"spark.executor.extraJavaOptions\", \"-XX:+UseG1GC\").\\\n",
				"                setAppName(\"PySparkTutorial\").\\\n",
				"                setMaster(\"local[*]\")\n",
				"\n",
				"# Create the context\n",
				"sc = pyspark.SparkContext(conf=config)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 7,
			"metadata": {
				"id": "SyrTHVZR4hq8"
			},
			"outputs": [],
			"source": [
				"spark = SparkSession.builder.getOrCreate()"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "VJeY9PpvaHUJ"
			},
			"source": [
				"# Data acquisition"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 8,
			"metadata": {
				"id": "icd2lj-RRvhU"
			},
			"outputs": [],
			"source": [
				"playlist_schema_mapped = StructType([\n",
				"    StructField(\"name\", StringType(), True),\n",
				"    StructField(\"collaborative\", StringType(), True),\n",
				"    StructField(\"pid\", IntegerType(), True),\n",
				"    StructField(\"modified_at\", IntegerType(), True),\n",
				"    StructField(\"num_tracks\", IntegerType(), True),\n",
				"    StructField(\"num_albums\", IntegerType(), True),\n",
				"    StructField(\"num_followers\", IntegerType(), True),\n",
				"    StructField(\"tracks\", VectorUDT(), True),\n",
				"    StructField(\"num_edits\", IntegerType(), True),\n",
				"    StructField(\"duration_ms\", IntegerType(), True),\n",
				"    StructField(\"num_artists\", IntegerType(), True),\n",
				"])\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 9,
			"metadata": {
				"id": "JAu9mQsxTxHj"
			},
			"outputs": [],
			"source": [
				"import warnings\n",
				"warnings.filterwarnings('ignore')"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 10,
			"metadata": {
				"id": "fGgc9DHjT09S"
			},
			"outputs": [],
			"source": [
				"NUM_PLAYLISTS = 200_000\n",
				"SONGS_EMBEDDINGS_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_songs_embeddings-train-{NUM_PLAYLISTS}.json\")\n",
				"SONGS_INFO_DF_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_songs_info_df-{NUM_PLAYLISTS}.json\")\n",
				"SONGS_VECTOR_LENGTH_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_songs_vector_length-{NUM_PLAYLISTS}.txt\")\n",
				"\n",
				"ARTIST_VECTOR_LENGTH_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_artist_vector_length-{NUM_PLAYLISTS}.txt\")\n",
				"ARTISTS_EMBEDDINGS_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_artists_embeddings-train-{NUM_PLAYLISTS}.json\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 11,
			"metadata": {
				"id": "BIalKyiH4hq9"
			},
			"outputs": [],
			"source": [
				"# The DF used for train (80% of the original) (playlist are different)\n",
				"TRAIN_DF_PATH = os.path.join(SAVED_DFS_PATH, f\"train_df-{NUM_PLAYLISTS}.json\")\n",
				"# The DF used for testing (20% of the original) (playlist are different)\n",
				"TEST_DF_PATH = os.path.join(SAVED_DFS_PATH, f\"test_df-{NUM_PLAYLISTS}.json\")\n",
				"\n",
				"# The DF used for train in the NN model (can be filtered or not)\n",
				"NN_TRAIN_DF_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_train_df-{NUM_PLAYLISTS}.json\")\n",
				"# The DF used for testing in the NN model (can be filtered or not)\n",
				"NN_TEST_DF_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_test_df-{NUM_PLAYLISTS}.json\")\n",
				"# The partition in train test of the NN test set. (Same playlists, different songs)\n",
				"NN_TEST_DF_TRAIN_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_test_df-train-{NUM_PLAYLISTS}.json\")\n",
				"NN_TEST_DF_TEST_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_test_df-test-{NUM_PLAYLISTS}.json\")\n",
				"\n",
				"NN_EVAL_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_eval_df-{NUM_PLAYLISTS}.json\")\n",
				"NN_EVAL_TRAIN_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_eval_df-train-{NUM_PLAYLISTS}.json\")\n",
				"NN_EVAL_TEST_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_eval_df-test-{NUM_PLAYLISTS}.json\")\n",
				"# New one:\n",
				"ARTISTS_EMBEDDINGS_TRAIN = os.path.join(SAVED_DFS_PATH, f\"nn_artists_embeddings-train-{NUM_PLAYLISTS}.json\")\n",
				"ARTISTS_EMBEDDINGS_TEST_TRAIN = os.path.join(SAVED_DFS_PATH, f\"nn_artists_embeddings-test-train-{NUM_PLAYLISTS}.json\")\n",
				"ARTISTS_EMBEDDINGS_TEST_TEST = os.path.join(SAVED_DFS_PATH, f\"nn_artists_embeddings-test-test{NUM_PLAYLISTS}.json\")\n",
				"\n",
				"ARTISTS_EMBEDDINGS_EVAL = os.path.join(SAVED_DFS_PATH, f\"nn_artists_embeddings-eval-{NUM_PLAYLISTS}.json\")\n",
				"ARTISTS_EMBEDDINGS_EVAL_TRAIN = os.path.join(SAVED_DFS_PATH, f\"nn_artists_embeddings-eval-train-{NUM_PLAYLISTS}.json\")\n",
				"ARTISTS_EMBEDDINGS_EVAL_TEST = os.path.join(SAVED_DFS_PATH, f\"nn_artists_embeddings-eval-test{NUM_PLAYLISTS}.json\")\n",
				"\n",
				"# The length of the artist vector length (Artist vectors are only used in the NN model)\n",
				"ARTIST_VECTOR_LENGTH_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_artist_vector_length-{NUM_PLAYLISTS}.txt\")\n",
				"\n",
				"SONGS_VECTOR_LENGTH_PATH = os.path.join(SAVED_DFS_PATH, f\"songs_vector_length-{NUM_PLAYLISTS}.txt\")\n",
				"# This may be filtered or not\n",
				"FILTERED_SONGS_VECTOR_LENGTH_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_songs_vector_length-{NUM_PLAYLISTS}.txt\")\n",
				"\n",
				"SONGS_EMBEDDINGS_TRAIN = os.path.join(SAVED_DFS_PATH, f\"songs_embeddings-train-{NUM_PLAYLISTS}.json\")\n",
				"SONGS_EMBEDDINGS_TEST = os.path.join(SAVED_DFS_PATH, f\"songs_embeddings-test-{NUM_PLAYLISTS}.json\")\n",
				"\n",
				"NN_SONGS_EMBEDDINGS_TRAIN = os.path.join(SAVED_DFS_PATH, f\"nn_songs_embeddings-train-{NUM_PLAYLISTS}.json\")\n",
				"NN_SONGS_EMBEDDINGS_TEST_TRAIN = os.path.join(SAVED_DFS_PATH, f\"nn_songs_embeddings-test-train-{NUM_PLAYLISTS}.json\")\n",
				"NN_SONGS_EMBEDDINGS_TEST_TEST = os.path.join(SAVED_DFS_PATH, f\"nn_songs_embeddings-test-test-{NUM_PLAYLISTS}.json\")\n",
				"\n",
				"NN_SONGS_EMBEDDINGS_EVAL = os.path.join(SAVED_DFS_PATH, f\"nn_songs_embeddings-eval-{NUM_PLAYLISTS}.json\") #TODO: The logic to produce this still has to be coded.\n",
				"NN_SONGS_EMBEDDINGS_EVAL_TRAIN = os.path.join(SAVED_DFS_PATH, f\"nn_songs_embeddings-eval-train-{NUM_PLAYLISTS}.json\")\n",
				"NN_SONGS_EMBEDDINGS_EVAL_TEST = os.path.join(SAVED_DFS_PATH, f\"nn_songs_embeddings-eval-test-{NUM_PLAYLISTS}.json\")\n",
				"\n",
				"SONGS_INFO_DF = os.path.join(SAVED_DFS_PATH, f\"songs_info_df-{NUM_PLAYLISTS}.json\")\n",
				"FILTERED_SONGS_INFO_DF = os.path.join(SAVED_DFS_PATH, f\"nn_songs_info_df-{NUM_PLAYLISTS}.json\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 12,
			"metadata": {
				"id": "lo8gbiN1U1XJ"
			},
			"outputs": [],
			"source": [
				"songs_embeddings = spark.read.schema(playlist_schema_mapped).json(SONGS_EMBEDDINGS_PATH)\n",
				"artists_embeddings = spark.read.schema(playlist_schema_mapped).json(ARTISTS_EMBEDDINGS_PATH)\n",
				"song_mapping = spark.read.json(SONGS_INFO_DF_PATH)\n",
				"\n",
				"songs_embeddings_eval_train = spark.read.schema(playlist_schema_mapped).json(NN_SONGS_EMBEDDINGS_EVAL_TRAIN)\n",
				"songs_embeddings_eval_test = spark.read.schema(playlist_schema_mapped).json(NN_SONGS_EMBEDDINGS_EVAL_TEST)\n",
				"\n",
				"artists_embeddings_eval_train = spark.read.schema(playlist_schema_mapped).json(ARTISTS_EMBEDDINGS_EVAL_TRAIN)\n",
				"artists_embeddings_eval_test = spark.read.schema(playlist_schema_mapped).json(ARTISTS_EMBEDDINGS_EVAL_TEST)\n",
				"\n",
				"with open(ARTIST_VECTOR_LENGTH_PATH, \"r\") as f:\n",
				"  content = f.read()\n",
				"  ARTIST_VECTOR_LENGTH = int(content)\n",
				"with open(SONGS_VECTOR_LENGTH_PATH, \"r\") as f:\n",
				"  content = f.read()\n",
				"  SONGS_VECTOR_LENGTH = int(content)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 13,
			"metadata": {
				"colab": {
					"base_uri": "https://localhost:8080/"
				},
				"id": "BY_szFyLTps4",
				"outputId": "aadd74d7-11e5-4c71-8140-9bd8295e086f"
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+--------------------+-------------+------+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
						"|                name|collaborative|   pid|modified_at|num_tracks|num_albums|num_followers|              tracks|num_edits|duration_ms|num_artists|\n",
						"+--------------------+-------------+------+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
						"|                 70s|        false|241678| 1467331200|        88|        73|            1|(997255,[7496,916...|        2|   19309960|         34|\n",
						"|                 Air|        false|374234| 1412553600|         9|         8|            1|(997255,[13005,23...|        2|    2229851|          7|\n",
						"|          Chill pill|        false|886743| 1504483200|       104|        87|            1|(997255,[1359,274...|       34|   22710241|         67|\n",
						"|               Coast|        false|374470| 1489881600|        39|        36|            1|(997255,[323,8863...|       20|   11178701|         35|\n",
						"|             Country|        false|714760| 1509148800|       143|       104|            2|(997255,[58,1403,...|       22|   32160667|         48|\n",
						"|              Disney|        false|316107| 1435881600|        19|        13|            1|(997255,[6789,308...|        2|    3229131|         18|\n",
						"|  Don't Kill My Vibe|        false|578972| 1383782400|        22|        21|            1|(997255,[2011,201...|       10|    5749143|         19|\n",
						"|              Elvis |        false|568387| 1392508800|        19|        15|            1|(997255,[2033,411...|        2|    3077640|          3|\n",
						"| Panic! At The Disco|        false|852235| 1509148800|        76|        18|            1|(997255,[1317,134...|       21|   15432136|          9|\n",
						"|         Skinny Love|        false|568873| 1506297600|        82|        59|            2|(997255,[2914,426...|       31|   19528470|         52|\n",
						"|               feels|        false|637561| 1508716800|        74|        61|            1|(997255,[6,656,21...|       28|   17068757|         54|\n",
						"|                jazz|        false|578699| 1489622400|        71|        51|            1|(997255,[7514,773...|       30|   22718258|         34|\n",
						"|                  ❤️|        false|456690| 1506384000|        81|        50|            2|(997255,[23,2048,...|       37|   19646931|         33|\n",
						"|            !!summer|        false|231620| 1378857600|        20|        18|            1|(997255,[4735,190...|       15|    4591754|         17|\n",
						"|               !Star|         true|450637| 1507852800|       154|       142|            2|(997255,[135,808,...|      116|   31994395|        129|\n",
						"|               #2000|        false|241735| 1400803200|        37|        32|            1|(997255,[2775,473...|        4|    8353587|         28|\n",
						"|               #2017|        false|271395| 1497744000|        31|        25|            1|(997255,[2254,136...|       17|    7380015|         21|\n",
						"|                #ERG|        false|389002| 1509062400|        47|        39|            1|(997255,[2793,358...|       23|   11205159|         36|\n",
						"|               #NSFW|        false|321289| 1501718400|        57|        51|            2|(997255,[708,2782...|       19|   14296875|         44|\n",
						"|         #Sing-along|        false|578304| 1507939200|        59|        59|            3|(997255,[2068,673...|        3|   13273108|         59|\n",
						"+--------------------+-------------+------+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
						"only showing top 20 rows\n",
						"\n",
						"+--------------------+-------------+------+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
						"|                name|collaborative|   pid|modified_at|num_tracks|num_albums|num_followers|              tracks|num_edits|duration_ms|num_artists|\n",
						"+--------------------+-------------+------+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
						"|                 70s|        false|241678| 1467331200|        88|        73|            1|(149977,[1320,255...|        2|   19309960|         34|\n",
						"|                 Air|        false|374234| 1412553600|         9|         8|            1|(149977,[1153,161...|        2|    2229851|          7|\n",
						"|          Chill pill|        false|886743| 1504483200|       104|        87|            1|(149977,[126,894,...|       34|   22710241|         67|\n",
						"|               Coast|        false|374470| 1489881600|        39|        36|            1|(149977,[2015,225...|       20|   11178701|         35|\n",
						"|             Country|        false|714760| 1509148800|       143|       104|            2|(149977,[409,862,...|       22|   32160667|         48|\n",
						"|              Disney|        false|316107| 1435881600|        19|        13|            1|(149977,[414,1472...|        2|    3229131|         18|\n",
						"|  Don't Kill My Vibe|        false|578972| 1383782400|        22|        21|            1|(149977,[126,5141...|       10|    5749143|         19|\n",
						"|              Elvis |        false|568387| 1392508800|        19|        15|            1|(149977,[38444,57...|        2|    3077640|          3|\n",
						"| Panic! At The Disco|        false|852235| 1509148800|        76|        18|            1|(149977,[37445,42...|       21|   15432136|          9|\n",
						"|         Skinny Love|        false|568873| 1506297600|        82|        59|            2|(149977,[877,1046...|       31|   19528470|         52|\n",
						"|               feels|        false|637561| 1508716800|        74|        61|            1|(149977,[129,131,...|       28|   17068757|         54|\n",
						"|                jazz|        false|578699| 1489622400|        71|        51|            1|(149977,[2336,256...|       30|   22718258|         34|\n",
						"|                  ❤️|        false|456690| 1506384000|        81|        50|            2|(149977,[1,1338,1...|       37|   19646931|         33|\n",
						"|            !!summer|        false|231620| 1378857600|        20|        18|            1|(149977,[7,129,16...|       15|    4591754|         17|\n",
						"|               !Star|         true|450637| 1507852800|       154|       142|            2|(149977,[564,735,...|      116|   31994395|        129|\n",
						"|               #2000|        false|241735| 1400803200|        37|        32|            1|(149977,[409,3275...|        4|    8353587|         28|\n",
						"|               #2017|        false|271395| 1497744000|        31|        25|            1|(149977,[1610,209...|       17|    7380015|         21|\n",
						"|                #ERG|        false|389002| 1509062400|        47|        39|            1|(149977,[461,565,...|       23|   11205159|         36|\n",
						"|               #NSFW|        false|321289| 1501718400|        57|        51|            2|(149977,[126,572,...|       19|   14296875|         44|\n",
						"|         #Sing-along|        false|578304| 1507939200|        59|        59|            3|(149977,[131,1957...|        3|   13273108|         59|\n",
						"+--------------------+-------------+------+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
						"only showing top 20 rows\n",
						"\n"
					]
				},
				{
					"data": {
						"text/plain": [
							"(None, None, 149977, 997255)"
						]
					},
					"execution_count": 13,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"songs_embeddings.show(), artists_embeddings.show(), ARTIST_VECTOR_LENGTH, SONGS_VECTOR_LENGTH"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "lPOD60GQQGse"
			},
			"source": [
				"# Convert PySpark DataFrame into PyTorch DataLoader"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 14,
			"metadata": {
				"id": "QCKbUCcaEpQS"
			},
			"outputs": [],
			"source": [
				"def convert_sparse_to_indices(df: DataFrame, column_name: str) -> DataFrame:\n",
				"  \"\"\"\n",
				"  Given a dataframe fo columns \"pos\":int and \"tracks\":SparseVector, it returns a new dataframe where\n",
				"  the SparseVector are replaced with a list of the indices where the values are.\n",
				"  (The value information is lost, but we don't care since they are binary values so they will be all ones)\n",
				"  \"\"\"\n",
				"\n",
				"  @F.udf(returnType=ArrayType(IntegerType()))\n",
				"  def transform_array(item: SparseVector):\n",
				"    \"\"\"\n",
				"    Given a SparseVector (binary) it returns the tuple that represent it, of the type (size, indices)\n",
				"    \"\"\"\n",
				"    indices_list = item.indices.tolist()\n",
				"    padding_width = max_songs - len(indices_list)\n",
				"    return indices_list + [-1] * padding_width\n",
				"\n",
				"  max_songs = songs_embeddings.select(F.max(\"num_tracks\")).first()[0]\n",
				"  print(f\"Max number of songs: {max_songs}\")\n",
				"  df = df.withColumn(f\"{column_name}_indices\", transform_array(F.col(column_name))).drop(column_name)\n",
				"  return df\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 15,
			"metadata": {
				"id": "eIIqDVeN7cU0"
			},
			"outputs": [],
			"source": [
				"def padded_tensors_to_sparse_matrix(padded_tensor: torch.Tensor, shape: tuple) -> torch.Tensor:\n",
				"  batch_size, max_songs = padded_tensor.size(0), padded_tensor.size(1)\n",
				"  rows = []\n",
				"  for row_idx in range(batch_size):\n",
				"    row = padded_tensor[row_idx]\n",
				"    indices = row[row != -1]\n",
				"    sparse_tensor = torch.sparse_coo_tensor(indices.unsqueeze(0), torch.ones(indices.shape), shape)\n",
				"    rows.append(sparse_tensor)\n",
				"  return torch.stack(rows)\n",
				"\n",
				"def padded_tensors_to_dense_matrix(padded_tensor: torch.Tensor, shape: tuple) -> torch.Tensor:\n",
				"  batch_size, max_songs = padded_tensor.size(0), padded_tensor.size(1)\n",
				"  rows = []\n",
				"  for row_idx in range(batch_size):\n",
				"    row = padded_tensor[row_idx]\n",
				"    indices = row[row != -1]\n",
				"    sparse_tensor = torch.sparse_coo_tensor(indices.unsqueeze(0), torch.ones(indices.shape), shape)\n",
				"    dense = sparse_tensor.to_dense()\n",
				"    rows.append(dense)\n",
				"  unpadded = torch.stack(rows)\n",
				"  return unpadded"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "UNak5bEo4cmV"
			},
			"source": [
				"In the paper they have two matrices,l et $n$ be the number of unique songs, $m$ the number of playlists and $k$ the number of unique artists:\n",
				"\n",
				"- $P \\in \\mathbb{R}^{m \\times n}$ where $p_i = 1$ if song $i$ is in the playlist, $p_i=0$ otherwise\n",
				"- $A \\in \\mathbb{R}^{m \\times k}$ where $a_i=1$ if the artist is present in the playlist, $a_i = 0$ otherwise"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 16,
			"metadata": {
				"colab": {
					"base_uri": "https://localhost:8080/"
				},
				"id": "y_pKgJx26s73",
				"outputId": "25ced304-08bb-4f04-af07-3a0f22058bd0"
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Max number of songs: 376\n"
					]
				},
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"Converting floating-point columns to float32\n"
					]
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Max number of songs: 376\n",
						"197004 197004 197004\n"
					]
				}
			],
			"source": [
				"from petastorm.spark import SparkDatasetConverter, make_spark_converter\n",
				"\n",
				"CACHE = os.path.join(GDRIVE_HOME_DIR, \"cache\")\n",
				"spark.conf.set(SparkDatasetConverter.PARENT_CACHE_DIR_URL_CONF, f'file://{CACHE}')\n",
				"\n",
				"pytorch_songs_df = convert_sparse_to_indices(songs_embeddings.select(\"tracks\", \"pid\"), column_name=\"tracks\")\n",
				"# songs_converter = make_spark_converter(pytorch_songs_df)\n",
				"pytorch_artists_df = convert_sparse_to_indices(artists_embeddings.withColumnRenamed(\"tracks\", \"artists\").select(\"pid\", \"artists\"), column_name=\"artists\")\n",
				"# artist_converter = make_spark_converter(pytorch_artists_df)\n",
				"songs_artists_df = pytorch_songs_df.join(pytorch_artists_df, on=\"pid\")\n",
				"pytorch_merged_dataloader = make_spark_converter(songs_artists_df)\n",
				"\n",
				"\n",
				"print(pytorch_songs_df.count(), pytorch_artists_df.count(), songs_artists_df.count()) #Everything good here, this is nice!"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 17,
			"metadata": {
				"id": "W0kCYA724hq_"
			},
			"outputs": [],
			"source": [
				"# songs_embeddings.show(), artists_embeddings.show()\n",
				"# artists_embeddings = artists_embeddings.withColumnRenamed(\"tracks\", \"artists\").select(\"pid\", \"artists\")\n",
				"# df = songs_embeddings.join(artists_embeddings, on=\"pid\").show()"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "RueabAy34hq_"
			},
			"source": [
				"Creating the dataloader for the evaluation set"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "m0Av0W0P66lC"
			},
			"source": [
				"# PyTorch Model"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 18,
			"metadata": {
				"id": "6-YbESXD66Oh"
			},
			"outputs": [],
			"source": [
				"import torch\n",
				"import torch.nn as nn\n",
				"import torch.optim as optim\n",
				"import numpy as np\n",
				"import pickle\n",
				"\n",
				"class DAE_tied(nn.Module):\n",
				"    def __init__(self, conf):\n",
				"        super(DAE_tied, self).__init__()\n",
				"        self.save_dir = conf[\"save\"]\n",
				"        if LOCAL:\n",
				"            self.device = torch.device(\"mps\")\n",
				"        else:\n",
				"            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
				"        self.initval_dir = conf[\"initval\"]\n",
				"\n",
				"        self.n_batch = conf[\"batch\"]\n",
				"        self.n_input = conf[\"n_input\"]\n",
				"        self.n_hidden = conf[\"hidden\"]\n",
				"        self.reg_lambda = conf[\"reg_lambda\"]\n",
				"\n",
				"        self.keep_prob = torch.tensor(conf[\"keep_prob\"], dtype=torch.float32)\n",
				"        self.input_keep_prob = torch.tensor(conf[\"input_keep_prob\"], dtype=torch.float32)\n",
				"\n",
				"        self.weights = {}\n",
				"        self.biases = {}\n",
				"        self.d_params = []\n",
				"\n",
				"        self.z = None\n",
				"\n",
				"    def init_weight(self):\n",
				"        if self.initval_dir == 'NULL':\n",
				"            self.weights['encoder_h'] = nn.Parameter(torch.FloatTensor(self.n_input, self.n_hidden).to(self.device))\n",
				"            nn.init.xavier_uniform_(self.weights['encoder_h'])\n",
				"            self.biases['encoder_b'] = nn.Parameter(torch.FloatTensor(self.n_hidden).to(self.device))\n",
				"            nn.init.zeros_(self.biases['encoder_b'])\n",
				"            self.biases['decoder_b'] = nn.Parameter(torch.FloatTensor(self.n_input).to(self.device))\n",
				"            nn.init.zeros_(self.biases['decoder_b'])\n",
				"        else:\n",
				"            with open(self.initval_dir, 'rb') as f:\n",
				"                emb = pickle.load(f)\n",
				"            self.weights['encoder_h'] = nn.Parameter(torch.FloatTensor(emb[0]).to(self.device))\n",
				"            self.biases['encoder_b'] = nn.Parameter(torch.FloatTensor(emb[2]).to(self.device))\n",
				"            self.biases['decoder_b'] = nn.Parameter(torch.FloatTensor(emb[3]).to(self.device))\n",
				"        self.d_params = [self.weights['encoder_h'], self.weights['encoder_h'], self.biases['encoder_b'], self.biases['decoder_b']]\n",
				"\n",
				"\n",
				"    # Building the encoder\n",
				"    def encoder(self, x):\n",
				"        # Encoder Hidden layer with sigmoid activation #1\n",
				"        layer = torch.add(torch.matmul(x, self.weights['encoder_h']), self.biases['encoder_b'])\n",
				"        layer = torch.sigmoid(layer)\n",
				"        layer = torch.nn.functional.dropout(layer, p=1 - self.keep_prob)\n",
				"\n",
				"        return layer\n",
				"\n",
				"    # Building the decoder\n",
				"    def decoder(self, x):\n",
				"        # Decoder Hidden layer with sigmoid activation #1\n",
				"        layer = torch.sigmoid(torch.add(torch.matmul(x, self.weights['encoder_h'].t()), self.biases['decoder_b']))\n",
				"        return layer\n",
				"\n",
				"    def l2_loss(self):\n",
				"        # encoder_h_l2 = (torch.sum(self.weights['encoder_h']) ** 2)/2\n",
				"        # decoder_b_l2 = (torch.sum(self.biases['decoder_b']) ** 2)/2\n",
				"        # encoder_b_l2 = (torch.sum(self.biases['encoder_b']) ** 2)/2\n",
				"\n",
				"        encoder_h_l1 = torch.sum(torch.abs(self.weights['encoder_h']))\n",
				"        decoder_b_l1 = torch.sum(torch.abs(self.biases['decoder_b']))\n",
				"        encoder_b_l1 = torch.sum(torch.abs(self.biases['encoder_b']))\n",
				"\n",
				"        # l2 = encoder_h_l2 + decoder_b_l2 + encoder_b_l2\n",
				"        l1 = encoder_h_l1 + decoder_b_l1 + encoder_b_l1\n",
				"        return l1\n",
				"\n",
				"    def forward(self, x, y):\n",
				"        self.x = x.t()\n",
				"        self.y = y.t()\n",
				"\n",
				"        x_dropout = torch.nn.functional.dropout(self.x, p= 1 - self.input_keep_prob)\n",
				"        reduce_sum = torch.sum(x_dropout, dim=1, keepdim=True)\n",
				"        self.x_dropout = torch.div(x_dropout, reduce_sum + 1e-10)\n",
				"\n",
				"        encoder_op = self.encoder(self.x_dropout)\n",
				"\n",
				"        self.z = encoder_op\n",
				"        self.y_pred = self.decoder(encoder_op)\n",
				"\n",
				"        l2 = self.l2_loss()\n",
				"\n",
				"        L = -torch.sum(self.y * torch.log(self.y_pred + 1e-10) +\n",
				"                       0.55 * (1 - self.y) * torch.log(1 - self.y_pred + 1e-10), dim=1)\n",
				"        self.cost = torch.mean(L) + self.reg_lambda * l2\n",
				"\n",
				"    def save_model(self):\n",
				"        params = [param.detach().numpy() for param in self.d_params]\n",
				"        with open(self.save_dir, 'wb') as f:\n",
				"            pickle.dump(params, f)\n",
				"\n",
				"\n",
				"class DAE(DAE_tied):\n",
				"    def __init__(self, conf):\n",
				"        super(DAE, self).__init__(conf)\n",
				"\n",
				"    def init_weight(self):\n",
				"        if self.initval_dir == 'NULL':\n",
				"            self.weights['encoder_h'] = nn.Parameter(torch.FloatTensor(self.n_input, self.n_hidden).to(self.device))\n",
				"            nn.init.xavier_uniform_(self.weights['encoder_h'])\n",
				"            self.weights['decoder_h'] = nn.Parameter(torch.FloatTensor(self.n_input, self.n_hidden).to(self.device))\n",
				"            nn.init.xavier_uniform_(self.weights['decoder_h'])\n",
				"            self.biases['encoder_b'] = nn.Parameter(torch.FloatTensor(self.n_hidden).to(self.device))\n",
				"            nn.init.zeros_(self.biases['encoder_b'])\n",
				"            self.biases['decoder_b'] = nn.Parameter(torch.FloatTensor(self.n_input).to(self.device))\n",
				"            nn.init.zeros_(self.biases['decoder_b'])\n",
				"        else:\n",
				"            with open(self.initval_dir, 'rb') as f:\n",
				"                emb = pickle.load(f)\n",
				"            self.weights['encoder_h'] = nn.Parameter(torch.FloatTensor(emb[0]).to(self.device))\n",
				"            self.weights['decoder_h'] = nn.Parameter(torch.FloatTensor(emb[1]).to(self.device))\n",
				"            self.biases['encoder_b'] = nn.Parameter(torch.FloatTensor(emb[2]).to(self.device))\n",
				"            self.biases['decoder_b'] = nn.Parameter(torch.FloatTensor(emb[3]).to(self.device))\n",
				"\n",
				"        self.d_params = [self.weights['encoder_h'], self.weights['decoder_h'],\n",
				"                         self.biases['encoder_b'], self.biases['decoder_b']]\n",
				"\n",
				"    def decoder(self, x):\n",
				"        # Decoder Hidden layer with sigmoid activation #1\n",
				"        layer = torch.sigmoid(torch.add(torch.matmul(x, self.weights['decoder_h'].t()), self.biases['decoder_b']))\n",
				"        return layer\n",
				"\n",
				"    def l2_loss(self):\n",
				"    #   encoder_h_l2 = (torch.sum(self.weights['encoder_h']) ** 2)/2\n",
				"    #   decoder_b_l2 = (torch.sum(self.biases['decoder_b']) ** 2)/2\n",
				"    #   encoder_b_l2 = (torch.sum(self.biases['encoder_b']) ** 2)/2\n",
				"    #   decoder_h_l2 = (torch.sum(self.weights['decoder_h']) ** 2)/2\n",
				"\n",
				"      encoder_h_l1 = torch.sum(torch.abs(self.weights['encoder_h']))\n",
				"      decoder_b_l1 = torch.sum(torch.abs(self.biases['decoder_b']))\n",
				"      encoder_b_l1 = torch.sum(torch.abs(self.biases['encoder_b']))\n",
				"      decoder_h_l1 = torch.sum(torch.abs(self.weights['decoder_h']))\n",
				"\n",
				"\n",
				"      l1 = encoder_h_l1 + decoder_b_l1 + encoder_b_l1 + decoder_h_l1\n",
				"\n",
				"    #   l2 = encoder_h_l2 + decoder_b_l2 + encoder_b_l2 + decoder_h_l2\n",
				"\n",
				"      return l1"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 19,
			"metadata": {
				"id": "kQPVslug4hrB"
			},
			"outputs": [],
			"source": [
				"from typing import List\n",
				"def k_prec(input: torch.Tensor, eval_preds: torch.Tensor, ground_truth: torch.Tensor) -> List[float]:\n",
				"    batch_size = 32\n",
				"    precs = []\n",
				"\n",
				"    for i in range(batch_size):\n",
				"        input_idx = torch.nonzero(input[i] == 1).squeeze().flatten()\n",
				"        num_input_songs = input_idx.shape[0]\n",
				"\n",
				"        ground_truth_idx = torch.nonzero(ground_truth[i] == 1).squeeze().flatten()\n",
				"        num_ground_truth_songs = ground_truth_idx.shape[0]\n",
				"\n",
				"        k = num_input_songs + num_ground_truth_songs\n",
				"\n",
				"        print(eval_preds.shape)\n",
				"        top_k_preds = eval_preds[i].topk(k, dim=0)\n",
				"        top_k_preds_idx = top_k_preds.indices.flatten().cpu()\n",
				"\n",
				"        confidences = top_k_preds.values.flatten()\n",
				"\n",
				"        already_in_playlist = np.intersect1d(top_k_preds_idx.detach().numpy(), input_idx.cpu().detach().numpy())\n",
				"\n",
				"\n",
				"        top_k_preds_idx = np.array(sorted([item for item in top_k_preds_idx if item not in already_in_playlist]))[:num_ground_truth_songs]\n",
				"\n",
				"        common_elements = np.intersect1d(top_k_preds_idx, ground_truth_idx.cpu().detach().numpy())\n",
				"        num_common_elements = len(common_elements)\n",
				"        precs.append(num_common_elements/num_ground_truth_songs)\n",
				"\n",
				"    return precs\n",
				"\n",
				"def ndcg(eval_preds: torch.Tensor, ground_truth: torch.Tensor) -> float:\n",
				"    return 0\n",
				"\n",
				"def evaluate(input: torch.Tensor, eval_preds: torch.Tensor, ground_truth: torch.Tensor) -> List[float]:\n",
				"    return k_prec(input, eval_preds, ground_truth)"
			]
		},
		{
			"cell_type": "code",
			"source": [
				"def test_k_prec(eval_preds: torch.Tensor, ground_truth: torch.Tensor) -> List[float]:\n",
				"    batch_size = 32\n",
				"    precs = []\n",
				"\n",
				"    for i in range(batch_size):\n",
				"        ground_truth_idx = torch.nonzero(ground_truth[i] == 1).squeeze().flatten()\n",
				"        num_ground_truth_songs = ground_truth_idx.shape[0]\n",
				"\n",
				"        k = num_ground_truth_songs\n",
				"        top_k_preds = eval_preds[i].topk(k, dim=0)\n",
				"        top_k_preds_idx = top_k_preds.indices.flatten().cpu()\n",
				"\n",
				"        confidences = top_k_preds.values.flatten()\n",
				"\n",
				"\n",
				"        common_elements = np.intersect1d(top_k_preds_idx, ground_truth_idx.cpu().detach().numpy())\n",
				"        num_common_elements = len(common_elements)\n",
				"        precs.append(num_common_elements/num_ground_truth_songs)\n",
				"    print(\"precs: \", precs)\n",
				"\n",
				"    return precs"
			],
			"metadata": {
				"id": "SK52nYJ-Edb9"
			},
			"execution_count": 22,
			"outputs": []
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"id": "OYT35yY74hrB"
			},
			"source": [
				"Creating the petastorm converters for validation set"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 23,
			"metadata": {
				"id": "UNcWBM0U4hrB",
				"outputId": "734b146d-f1e4-4461-d82f-d192ecf0aff9",
				"colab": {
					"base_uri": "https://localhost:8080/"
				},
				"id": "UNcWBM0U4hrB",
				"outputId": "bb7ffacf-9c0e-4f9b-a851-de2bcec5b9c6"
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Max number of songs: 376\n",
						"Max number of songs: 376\n",
						"Max number of songs: 376\n"
					]
				},
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"Max number of songs: 376\n"
					]
				}
			],
			"source": [
				"pytorch_songs_eval_train_df = convert_sparse_to_indices(songs_embeddings_eval_train.withColumnRenamed(\"tracks\", \"train_tracks\").select(\"train_tracks\", \"pid\"), column_name=\"train_tracks\")\n",
				"pytorch_artists_eval_train_df = convert_sparse_to_indices(artists_embeddings_eval_train.withColumnRenamed(\"tracks\", \"train_artists\").select(\"pid\", \"train_artists\"), column_name=\"train_artists\")\n",
				"songs_artists_eval_train_df = pytorch_songs_eval_train_df.join(pytorch_artists_eval_train_df, on=\"pid\")\n",
				"\n",
				"pytorch_songs_eval_test_df = convert_sparse_to_indices(songs_embeddings_eval_test.withColumnRenamed(\"tracks\", \"test_tracks\").select(\"test_tracks\", \"pid\"), column_name=\"test_tracks\")\n",
				"pytorch_artists_eval_test_df = convert_sparse_to_indices(artists_embeddings_eval_test.withColumnRenamed(\"tracks\", \"test_artists\").select(\"pid\", \"test_artists\"), column_name=\"test_artists\")\n",
				"songs_artists_eval_test_df = pytorch_songs_eval_test_df.join(pytorch_artists_eval_test_df, on=\"pid\")\n",
				"\n",
				"eval_merged_df = songs_artists_eval_train_df.join(songs_artists_eval_test_df, on=\"pid\")\n",
				"\n",
				"# counter = F.udf(lambda x: len([item for item in x if item != -1]), returnType=IntegerType())\n",
				"# eval_merged_df = eval_merged_df\\\n",
				"#     .withColumn(\"train_tracks_count\", counter(F.col(\"train_tracks_indices\")))\\\n",
				"#     .withColumn(\"test_tracks_count\", counter(F.col(\"test_tracks_indices\")))\n",
				"# eval_merged_df = eval_merged_df.filter(\"train_tracks_count > 100\")\n",
				"eval_merged_dataloader = make_spark_converter(eval_merged_df)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 24,
			"metadata": {
				"id": "yP8xk2L34hrB"
			},
			"outputs": [],
			"source": [
				"def validate(model: DAE_tied) -> Tuple[torch.Tensor, float, float]:\n",
				"    \"\"\"\n",
				"    Given the model, performs an evaluation on the validation set.\n",
				"    \"\"\"\n",
				"    ARTIST_SHAPE = (ARTIST_VECTOR_LENGTH, )\n",
				"    SONG_SHAPE = (SONGS_VECTOR_LENGTH, )\n",
				"    precs = []\n",
				"    tot_k = 0\n",
				"    model.eval()\n",
				"    with eval_merged_dataloader.make_torch_dataloader(batch_size=conf[\"batch\"], num_epochs = 1) as eval_dataloader:\n",
				"        for batch_idx, row in enumerate(eval_dataloader):\n",
				"            with torch.no_grad():\n",
				"                if batch_idx == 1:\n",
				"                    break #TODO: faster but less generalized, remove for the final training\n",
				"                padded_eval_song_tensor = row[\"train_tracks_indices\"]\n",
				"                padded_eval_artist_tensor = row[\"train_artists_indices\"]\n",
				"\n",
				"                song_dense = padded_tensors_to_dense_matrix(padded_eval_song_tensor, SONG_SHAPE)\n",
				"                artist_dense = padded_tensors_to_dense_matrix(padded_eval_artist_tensor, ARTIST_SHAPE)\n",
				"\n",
				"                song_dense = song_dense.to(device)\n",
				"                artist_dense = artist_dense.to(device)\n",
				"\n",
				"                del padded_eval_song_tensor\n",
				"                del padded_eval_artist_tensor\n",
				"\n",
				"                x = torch.concat((song_dense, artist_dense), dim=1).t()\n",
				"                y = torch.concat((song_dense, artist_dense), dim=1).t()\n",
				"\n",
				"                model(x, y)\n",
				"\n",
				"                eval_preds = model.y_pred[:, :SONGS_VECTOR_LENGTH]\n",
				"\n",
				"                padded_eval_song_tensor_test = row[\"test_tracks_indices\"]\n",
				"\n",
				"                ground_truth = padded_tensors_to_dense_matrix(padded_eval_song_tensor_test, SONG_SHAPE)\n",
				"\n",
				"                ground_truth = ground_truth.to(device)\n",
				"\n",
				"                prec_list = evaluate(song_dense, eval_preds, ground_truth)\n",
				"                precs.extend(prec_list)\n",
				"\n",
				"        mean_prec: float = sum(precs) / len(precs)\n",
				"        model.train()\n",
				"        return model.cost, mean_prec\n"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "aHXRUYad4hrB"
			},
			"source": [
				"Define the validation function that is invoked during the training in order to save the model parameters that optimize the performance evaluation on the validation set."
			]
		},
		{
			"cell_type": "code",
			"execution_count": 25,
			"metadata": {
				"id": "I75MLKjC4hrC"
			},
			"outputs": [],
			"source": [
				"def perform_validation_step(model: DAE_tied, max_prec: float, save_path:str, save: bool):\n",
				"    eval_loss, prec = validate(model)\n",
				"\n",
				"    if prec > max_prec:\n",
				"        max_prec = prec\n",
				"        best_params = [param.cpu().detach().numpy() for param in model.d_params]\n",
				"        if save:\n",
				"          with open(save_path, \"wb\") as f:\n",
				"              pickle.dump(best_params, f)\n",
				"          print(f\"Best prec achieved: {prec}, parameters saved!\")\n",
				"        else:\n",
				"          print(f\"Best prec achieved: {prec}!\")\n",
				"    return max_prec"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 26,
			"metadata": {
				"id": "aykoeJfhOUBV"
			},
			"outputs": [],
			"source": [
				"if LOCAL:\n",
				"    device = torch.device(\"mps\")\n",
				"else:\n",
				"    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 27,
			"metadata": {
				"colab": {
					"base_uri": "https://localhost:8080/"
				},
				"id": "DVGpMdqs7dQQ",
				"outputId": "a6b7d56d-2f05-492c-d397-f54f5e7d3517"
			},
			"outputs": [
				{
					"data": {
						"text/plain": [
							"DAE_tied()"
						]
					},
					"execution_count": 24,
					"metadata": {},
					"execution_count": 27
				}
			],
			"source": [
				"BEST_PARAMS_PATH = os.path.join(SAVED_MODELS, \"best_params.pickle\")\n",
				"BEST_PARAMS_PATH_2 = os.path.join(SAVED_MODELS, \"best_params_reg.pickle\")\n",
				"\n",
				"#Hyperparameters used in the paper\n",
				"conf = {\n",
				"    'batch': 32,\n",
				"    'n_input': SONGS_VECTOR_LENGTH + ARTIST_VECTOR_LENGTH,\n",
				"    'hidden': 128,\n",
				"    'lr': 0.001,\n",
				"    'reg_lambda': 0.0005,\n",
				"    'initval': \"NULL\",\n",
				"    \"keep_prob\": 0.8,\n",
				"    \"input_keep_prob\": 0.8, # This isn't used for now because of the .uniform()\n",
				"    'save': os.path.join(SAVED_MODELS, \"dae_model.pickle\")\n",
				"}\n",
				"pretrain_model = DAE_tied(conf)\n",
				"pretrain_model.init_weight()\n",
				"pretrain_model.train()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 28,
			"metadata": {
				"id": "mNPmA2YijSO1"
			},
			"outputs": [],
			"source": [
				"pretrain_optimizer = optim.Adam(pretrain_model.d_params, lr=conf[\"lr\"])"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 29,
			"metadata": {
				"colab": {
					"base_uri": "https://localhost:8080/"
				},
				"id": "5jAqv6QBEiK9",
				"outputId": "f0b5fa18-810b-4b34-e33e-2975284d8452"
			},
			"outputs": [
				{
					"data": {
						"text/plain": [
							"device(type='mps', index=0)"
						]
					},
					"execution_count": 26,
					"metadata": {},
					"execution_count": 29
				}
			],
			"source": [
				"pretrain_model.weights['encoder_h'].device"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 27,
			"metadata": {
				"id": "MeuVole7-WWC"
			},
			"execution_count": 30,
			"outputs": []
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "k2pR2ild4hrC"
			},
			"source": [
				"Testing if the ordering is correct"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"id": "65Q1vQHZ4hrC"
			},
			"outputs": [],
			"source": [
				"# from tqdm.notebook import tqdm\n",
				"# import random\n",
				"# # os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"\n",
				"# NUM_EPOCHS = 5\n",
				"# with pytorch_merged_dataloader.make_torch_dataloader(batch_size=conf[\"batch\"], num_epochs = NUM_EPOCHS) as train_dataloader:\n",
				"#     ARTIST_SHAPE = (ARTIST_VECTOR_LENGTH, )\n",
				"#     SONG_SHAPE = (SONGS_VECTOR_LENGTH, )\n",
				"#     for batch_idx, row in tqdm(enumerate(train_dataloader), desc=f\"Training model\", total= (NUM_PLAYLISTS / conf[\"batch\"]) * NUM_EPOCHS):\n",
				"#       # Pick random input_keep_prob between 0.5 and 0.8\n",
				"#     #   pretrain_model.input_keep_prob = random.uniform(0.5, 0.8) #TODO: make this dynamic inside the conf\n",
				"#       pretrain_model.input_keep_prob = random.uniform(0.5, 0.8) #TODO: make this dynamic inside the conf\n",
				"\n",
				"#       padded_song_tensor = row[\"tracks_indices\"]\n",
				"#       padded_artist_tensor = row[\"artists_indices\"]\n",
				"\n",
				"#       song_dense = padded_tensors_to_dense_matrix(padded_song_tensor, SONG_SHAPE)[:, 1:]\n",
				"#       artist_dense = padded_tensors_to_dense_matrix(padded_artist_tensor, ARTIST_SHAPE)[:, 1:]\n",
				"\n",
				"#       song_indices = sorted(list(set(torch.nonzero(song_dense[0] == 1).squeeze().flatten().cpu().detach().tolist())))\n",
				"#       print(torch.nonzero(song_dense[0] == 1))\n",
				"#       songs_artists_df.show()\n",
				"#       artist_indices = torch.nonzero(artist_dense == 1).squeeze().flatten()\n",
				"\n",
				"#     #   print(song_indices)\n",
				"#     #   print(artist_indices)\n",
				"#       break\n"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "GuqQMu_E0yaN"
			},
			"source": [
				"## Train the model"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 31,
			"metadata": {
				"id": "jIg2DIDNjEKm"
			},
			"outputs": [],
			"source": [
				"min_loss = 2000\n",
				"max_prec = 0\n",
				"max_test_prec = 0\n",
				"best_params = []\n",
				"losses = []"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "SFvPuc5hqirK"
			},
			"source": [
				"Pretrain with `DAE_tied`"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 30,
			"metadata": {
				"colab": {
					"base_uri": "https://localhost:8080/",
					"height": 1000,
					"referenced_widgets": [
						"489975773ec0499cbace7cae6ac15d06",
						"fc710cd691b4434fb36a2c18918b5ee6",
						"ba06d14e31314d078a4c6efdf076f73a",
						"a8e6455e5056443d9915f855f3cd7c3b",
						"22f37ad07c524b85b57a1b9173eab0ff",
						"dc7f30dacf5143b1803d37a56c1ba1c1",
						"3c9b12e4657940ecbe58b00d4969de9c",
						"c37ea40712a6454296dba3bf91be9e61",
						"52f58503a7f34fb9b33ce766f3d0fc34",
						"79d9abd62bc14970ab35f58815434564",
						"d6ee478fde1a4e5aa024bccd905feecb"
					]
				},
				"id": "Z_BjjpshDD2H",
				"outputId": "5e9afb09-3322-4f25-c8cb-36de5aa6e6d0"
			},
			"outputs": [
				{
					"data": {
						"application/vnd.jupyter.widget-view+json": {
							"model_id": "ea5f325dbe79469486dc7e8b3df1f9e1",
							"version_major": 2,
							"version_minor": 0
						},
						"text/plain": [
							"Training model:   0%|          | 0/12500.0 [00:00<?, ?it/s]"
						],
						"application/vnd.jupyter.widget-view+json": {
							"version_major": 2,
							"version_minor": 0,
							"model_id": "489975773ec0499cbace7cae6ac15d06"
						}
					},
					"metadata": {},
					"output_type": "display_data"
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0055248618784530384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"Max test prec: 0.00017265193370165745!\n",
						"Loss: 437489.09375\n",
						"Current max precision: 0\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"Best prec achieved: 0.0012181409295352324!\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023952095808383235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007692307692307693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"Max test prec: 0.0009888876093965915!\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04245283018867924, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04265402843601896, 0.0, 0.010256410256410256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"Max test prec: 0.0029801021525346395!\n",
						"precs:  [0.011494252873563218, 0.0, 0.0, 0.0, 0.0, 0.00847457627118644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007042253521126761, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017699115044247787, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.017857142857142856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007462686567164179, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004672897196261682, 0.0, 0.017699115044247787, 0.021739130434782608, 0.0, 0.011049723756906077, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010101010101010102, 0.0, 0.0, 0.0, 0.037037037037037035, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009259259259259259, 0.0, 0.004484304932735426, 0.018518518518518517, 0.008771929824561403, 0.0, 0.0, 0.0, 0.0, 0.012195121951219513, 0.008695652173913044, 0.005681818181818182, 0.0]\n",
						"Max test prec: 0.0035857703743772647!\n",
						"precs:  [0.0, 0.0, 0.0, 0.0056179775280898875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008620689655172414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"Best prec achieved: 0.002491918103448276!\n",
						"precs:  [0.0, 0.0, 0.0, 0.03067484662576687, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006896551724137931, 0.0, 0.0, 0.0, 0.029239766081871343, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005813953488372093, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019230769230769232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004484304932735426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009174311926605505, 0.0, 0.0, 0.0, 0.0, 0.005917159763313609, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.030927835051546393, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04964539007092199, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.006369426751592357, 0.02912621359223301, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013793103448275862, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03731343283582089, 0.022222222222222223, 0.0, 0.0, 0.0, 0.02142857142857143, 0.0, 0.028409090909090908, 0.0, 0.0, 0.0]\n",
						"Max test prec: 0.00495818941211896!\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04316546762589928, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01652892561983471, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016129032258064516, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004201680672268907, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0425531914893617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.023255813953488372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005847953216374269, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012987012987012988, 0.014388489208633094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06329113924050633]\n",
						"Best prec achieved: 0.005332827194357367!\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010638297872340425, 0.0, 0.0, 0.0, 0.04032258064516129, 0.0, 0.0, 0.0, 0.02617801047120419, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015873015873015872, 0.0, 0.0, 0.0, 0.03680981595092025, 0.0, 0.0, 0.0, 0.0, 0.009216589861751152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006289308176100629, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011049723756906077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006535947712418301, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007874015748031496, 0.0, 0.016129032258064516, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012738853503184714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008928571428571428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01818181818181818, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023809523809523808, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021621621621621623, 0.0, 0.0, 0.0, 0.02054794520547945, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009345794392523364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08085106382978724, 0.0, 0.0, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013513513513513514, 0.0, 0.0, 0.0, 0.0, 0.033707865168539325, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00909090909090909, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0047169811320754715, 0.02702702702702703, 0.0, 0.0, 0.0, 0.03424657534246575, 0.0, 0.0]\n",
						"Loss: 42724.9140625\n",
						"Current max precision: 0.005332827194357367\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.006802721088435374, 0.0, 0.0, 0.0, 0.0, 0.004524886877828055, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05660377358490566, 0.0, 0.0, 0.0, 0.006289308176100629, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06635071090047394, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0379746835443038, 0.0, 0.0, 0.0043859649122807015]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012121212121212121, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017543859649122806, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012121212121212121, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04484304932735426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.03225806451612903, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025906735751295335, 0.0, 0.0, 0.0, 0.008620689655172414, 0.05172413793103448, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004098360655737705, 0.0, 0.0, 0.012269938650306749, 0.023622047244094488, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0056179775280898875, 0.0, 0.0, 0.0]\n",
						"precs:  [0.006578947368421052, 0.01652892561983471, 0.0, 0.0, 0.0, 0.0, 0.008620689655172414, 0.0, 0.0, 0.02358490566037736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010101010101010102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.006578947368421052, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017045454545454544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025252525252525252, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004672897196261682, 0.011363636363636364, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04128440366972477, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005988023952095809, 0.0, 0.0, 0.04149377593360996, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.04591836734693878, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031007751937984496, 0.0, 0.0, 0.006666666666666667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0064516129032258064, 0.0, 0.011904761904761904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006369426751592357]\n",
						"precs:  [0.0, 0.012345679012345678, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013793103448275862, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05504587155963303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0045045045045045045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022727272727272728, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02962962962962963, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014814814814814815, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004484304932735426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.011627906976744186, 0.0, 0.0, 0.0, 0.023809523809523808, 0.0, 0.0, 0.0, 0.0, 0.004149377593360996, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006802721088435374, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006289308176100629, 0.0, 0.0, 0.0049261083743842365, 0.0, 0.0, 0.0, 0.008849557522123894, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.008695652173913044, 0.0, 0.0, 0.0, 0.017241379310344827, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005208333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014598540145985401, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04219409282700422, 0.0, 0.0, 0.0, 0.004132231404958678, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.011560693641618497, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008130081300813009, 0.01834862385321101, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008928571428571428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"Loss: 20762.98828125\n",
						"Current max precision: 0.005332827194357367\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0053475935828877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0051813471502590676, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.02054794520547945, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006578947368421052, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012605042016806723, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0707070707070707, 0.008064516129032258, 0.0, 0.0, 0.0, 0.005494505494505495, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012345679012345678, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00423728813559322, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007246376811594203, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013157894736842105, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04046242774566474, 0.0, 0.0, 0.0, 0.01680672268907563, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012048192771084338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04145077720207254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00510204081632653, 0.0, 0.0, 0.0, 0.022058823529411766, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.035398230088495575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024271844660194174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02976190476190476, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"Best prec achieved: 0.005904374535488666!\n",
						"precs:  [0.018691588785046728, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.014705882352941176, 0.0, 0.013333333333333334, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008928571428571428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009615384615384616, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008849557522123894, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015873015873015872]\n",
						"precs:  [0.008064516129032258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009708737864077669, 0.0, 0.02586206896551724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048034934497816595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02857142857142857, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03208556149732621]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.0, 0.017857142857142856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0273972602739726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006756756756756757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006711409395973154, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.031413612565445025, 0.0, 0.016666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007575757575757576, 0.0, 0.012295081967213115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008928571428571428, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005813953488372093, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021551724137931036, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006802721088435374, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011560693641618497, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008695652173913044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010752688172043012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019417475728155338, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013157894736842105, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016129032258064516, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.013513513513513514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017699115044247787, 0.017543859649122806, 0.0, 0.0, 0.0, 0.0, 0.006993006993006993]\n",
						"precs:  [0.0, 0.06866952789699571, 0.0, 0.0, 0.0, 0.008620689655172414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013513513513513514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005649717514124294, 0.0, 0.0, 0.0125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.02072538860103627, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005208333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014492753623188406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03255813953488372, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010309278350515464, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.009216589861751152, 0.0, 0.0, 0.0, 0.01834862385321101, 0.020202020202020204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00641025641025641, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"Loss: 14320.298828125\n",
						"Current max precision: 0.005904374535488666\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.055865921787709494, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009852216748768473, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.018018018018018018, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027932960893854747, 0.0, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019230769230769232, 0.0, 0.0, 0.0, 0.0, 0.022727272727272728, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029411764705882353, 0.0, 0.0, 0.0, 0.011363636363636364, 0.0, 0.0049261083743842365, 0.0, 0.0, 0.011904761904761904, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006060606060606061, 0.011235955056179775, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011764705882352941, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010309278350515464, 0.0, 0.0, 0.011627906976744186, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.006944444444444444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005952380952380952, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011695906432748537, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014388489208633094, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004424778761061947, 0.0, 0.005681818181818182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01282051282051282]\n",
						"precs:  [0.0, 0.010869565217391304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05785123966942149, 0.008620689655172414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.004878048780487805, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0072992700729927005, 0.0, 0.014084507042253521, 0.0, 0.0, 0.0, 0.0, 0.017857142857142856, 0.0, 0.0, 0.008333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038461538461538464, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.013761467889908258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014814814814814815, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0392156862745098, 0.0, 0.041379310344827586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.006172839506172839, 0.0, 0.0, 0.0, 0.019230769230769232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009174311926605505]\n",
						"precs:  [0.010869565217391304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010416666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009259259259259259, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012269938650306749, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004098360655737705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.015384615384615385, 0.011627906976744186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021739130434782608, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028985507246376812, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00909090909090909, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004608294930875576, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0, 0.0, 0.018018018018018018, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005988023952095809, 0.041474654377880185, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.010309278350515464, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01694915254237288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009009009009009009, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024844720496894408, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.010309278350515464, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010101010101010102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03482587064676617, 0.0, 0.052884615384615384, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019801980198019802, 0.0, 0.0, 0.0, 0.0, 0.030303030303030304, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03418803418803419, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0055248618784530384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"Loss: 12170.75\n",
						"Current max precision: 0.005904374535488666\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008771929824561403, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01020408163265306, 0.007874015748031496, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009259259259259259, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012195121951219513, 0.057971014492753624, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024509803921568627, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010638297872340425, 0.03289473684210526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014084507042253521]\n",
						"precs:  [0.0, 0.013422818791946308, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012195121951219513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.009433962264150943, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014084507042253521, 0.0, 0.014285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00641025641025641, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006211180124223602]\n",
						"precs:  [0.0, 0.0, 0.0, 0.016129032258064516, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014084507042253521, 0.05504587155963303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06382978723404255, 0.0, 0.0, 0.01, 0.0, 0.041176470588235294, 0.0, 0.014285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05389221556886228, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02127659574468085, 0.0, 0.0, 0.0, 0.0, 0.03875968992248062, 0.0, 0.0, 0.04864864864864865, 0.0, 0.0, 0.0, 0.021551724137931036, 0.0, 0.0, 0.0]\n",
						"Max test prec: 0.005754027313206358!\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006097560975609756, 0.0, 0.0, 0.042735042735042736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013513513513513514, 0.0, 0.0, 0.0, 0.0, 0.008547008547008548, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015151515151515152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008403361344537815, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.00975609756097561, 0.05128205128205128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027522935779816515, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02112676056338028, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011363636363636364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.013605442176870748, 0.0, 0.0, 0.00558659217877095, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017094017094017096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01098901098901099, 0.00546448087431694, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014814814814814815, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.011764705882352941, 0.0, 0.0, 0.0, 0.0, 0.00558659217877095, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005291005291005291, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005208333333333333, 0.012738853503184714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009433962264150943, 0.0, 0.0, 0.0, 0.038461538461538464, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02531645569620253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0049261083743842365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018691588785046728, 0.0, 0.012048192771084338, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005128205128205128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.010309278350515464, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024691358024691357, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019230769230769232, 0.0, 0.009569377990430622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005952380952380952, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015151515151515152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00847457627118644, 0.0]\n",
						"Loss: 10701.12109375\n",
						"Current max precision: 0.005904374535488666\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00641025641025641, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008403361344537815, 0.0, 0.008968609865470852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016483516483516484, 0.006896551724137931, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03389830508474576, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006172839506172839]\n",
						"precs:  [0.01020408163265306, 0.0, 0.0, 0.04504504504504504, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011111111111111112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010309278350515464, 0.0, 0.004464285714285714, 0.013513513513513514, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007633587786259542, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.010752688172043012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029535864978902954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005154639175257732, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.011764705882352941, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007751937984496124, 0.0, 0.0, 0.02702702702702703, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.017543859649122806, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015873015873015872]\n",
						"Best prec achieved: 0.006316218802748976!\n",
						"precs:  [0.0, 0.0, 0.010416666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0070921985815602835, 0.0, 0.0, 0.0, 0.011627906976744186, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022988505747126436, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.010101010101010102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00980392156862745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01652892561983471, 0.0, 0.0, 0.0, 0.0, 0.007751937984496124, 0.0, 0.008264462809917356, 0.0]\n",
						"precs:  [0.0, 0.04807692307692308, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0425531914893617, 0.0, 0.0, 0.0, 0.0, 0.014084507042253521, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03271028037383177, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043209876543209874, 0.0, 0.0, 0.0, 0.0045045045045045045, 0.0, 0.0]\n",
						"precs:  [0.0, 0.015873015873015872, 0.0, 0.0, 0.0, 0.0, 0.008695652173913044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013888888888888888, 0.0, 0.03398058252427184, 0.0, 0.009615384615384616, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01834862385321101, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0380952380952381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0136986301369863, 0.0, 0.0]\n",
						"precs:  [0.012195121951219513, 0.0, 0.0, 0.0, 0.004098360655737705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07623318385650224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018957345971563982, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018018018018018018, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02127659574468085, 0.0, 0.0, 0.0, 0.0182648401826484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023622047244094488, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0273972602739726, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02702702702702703, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.008130081300813009, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005128205128205128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009433962264150943, 0.034482758620689655, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016483516483516484, 0.004310344827586207, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009708737864077669, 0.023076923076923078, 0.047619047619047616, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011627906976744186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.006578947368421052, 0.0, 0.012345679012345678, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02830188679245283, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017142857142857144, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014492753623188406, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018867924528301886, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"Loss: 10150.763671875\n",
						"Current max precision: 0.006316218802748976\n",
						"precs:  [0.0, 0.0, 0.0, 0.00411522633744856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010309278350515464, 0.0, 0.0, 0.03365384615384615, 0.0, 0.0, 0.0, 0.015037593984962405, 0.0, 0.0, 0.0]\n",
						"precs:  [0.03804347826086957, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00625, 0.0, 0.012345679012345678, 0.0, 0.0, 0.0, 0.022058823529411766, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009708737864077669, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024844720496894408, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.010638297872340425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010638297872340425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.007633587786259542, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01818181818181818, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006535947712418301, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02586206896551724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.00819672131147541, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004166666666666667, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009345794392523364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004694835680751174, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.04060913705583756, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0189873417721519, 0.010309278350515464, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00684931506849315, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009009009009009009, 0.0, 0.0, 0.030864197530864196, 0.0, 0.005319148936170213, 0.0, 0.0, 0.0, 0.0, 0.004807692307692308, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010582010582010581, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008888888888888889, 0.0, 0.0, 0.030303030303030304, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.016260162601626018, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010416666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.004347826086956522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00980392156862745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.012096774193548387, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010869565217391304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0064516129032258064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00684931506849315, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022123893805309734, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004132231404958678, 0.0, 0.013513513513513514, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.008064516129032258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0064516129032258064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022058823529411766, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.020833333333333332, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.016129032258064516, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"Loss: 9594.673828125\n",
						"Current max precision: 0.006316218802748976\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0049504950495049506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007352941176470588, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007518796992481203, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.019230769230769232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006578947368421052, 0.0, 0.0, 0.0, 0.013824884792626729, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00909090909090909, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006993006993006993, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.005076142131979695, 0.0, 0.0, 0.0, 0.019138755980861243, 0.009523809523809525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01764705882352941, 0.004310344827586207, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.016304347826086956, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015544041450777202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02054794520547945, 0.0, 0.014084507042253521, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.011764705882352941, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012195121951219513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023952095808383235, 0.0, 0.0, 0.0, 0.0, 0.011834319526627219, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005917159763313609, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005208333333333333, 0.0, 0.0, 0.0, 0.0, 0.009433962264150943, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01639344262295082, 0.0, 0.0, 0.0, 0.0, 0.0043859649122807015, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.025477707006369428, 0.0, 0.0, 0.010638297872340425, 0.04700854700854701, 0.0, 0.0, 0.0, 0.0, 0.0072992700729927005, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00641025641025641, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020689655172413793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023391812865497075]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005319148936170213, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005555555555555556, 0.0, 0.0, 0.0, 0.0, 0.004424778761061947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015748031496062992, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013513513513513514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028089887640449437, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"Best prec achieved: 0.007736673348203521!\n",
						"precs:  [0.00980392156862745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01020408163265306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004651162790697674, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.005847953216374269, 0.005405405405405406, 0.0, 0.017045454545454544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0070921985815602835, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.005847953216374269, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016853932584269662, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.014634146341463415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014150943396226415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0045871559633027525, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004784688995215311, 0.0, 0.006369426751592357, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010526315789473684, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"Loss: 9329.234375\n",
						"Current max precision: 0.007736673348203521\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006172839506172839, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005291005291005291, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008403361344537815, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008130081300813009, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012345679012345678, 0.0055248618784530384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00819672131147541, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00847457627118644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013392857142857142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025380710659898477, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008695652173913044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.016574585635359115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005405405405405406, 0.0, 0.0, 0.004761904761904762, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005747126436781609, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007633587786259542, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008403361344537815]\n",
						"precs:  [0.0, 0.0051813471502590676, 0.0, 0.0, 0.0, 0.007633587786259542, 0.008547008547008548, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.005494505494505495, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03139013452914798, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006493506493506494, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015037593984962405, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009523809523809525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00966183574879227, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0053475935828877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00980392156862745, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0053475935828877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00684931506849315, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.010471204188481676, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006172839506172839, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023255813953488372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0045871559633027525, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005555555555555556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"Loss: 9022.376953125\n",
						"Current max precision: 0.007736673348203521\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013793103448275862, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005208333333333333, 0.0, 0.0, 0.0, 0.014598540145985401, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.014388489208633094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007194244604316547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011111111111111112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005494505494505495, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008849557522123894, 0.005780346820809248, 0.0, 0.0, 0.00847457627118644, 0.0, 0.029940119760479042, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0058823529411764705, 0.0, 0.0, 0.0, 0.008695652173913044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00851063829787234]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006535947712418301, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011494252873563218, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022598870056497175, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.011235955056179775, 0.023952095808383235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011695906432748537, 0.0, 0.0, 0.0, 0.013888888888888888, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.004424778761061947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011764705882352941, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.011494252873563218, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02830188679245283, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015151515151515152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019736842105263157, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020161290322580645, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.007142857142857143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011494252873563218, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004651162790697674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.006289308176100629, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.044444444444444446, 0.0, 0.0, 0.0, 0.014285714285714285, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021897810218978103, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02857142857142857, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011904761904761904]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0049504950495049506, 0.0, 0.0, 0.046610169491525424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01282051282051282, 0.0, 0.0, 0.0, 0.0, 0.03333333333333333, 0.0, 0.0, 0.012195121951219513, 0.0, 0.0, 0.0]\n",
						"precs:  [0.010638297872340425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008333333333333333, 0.0, 0.0, 0.012195121951219513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0064516129032258064, 0.0, 0.0, 0.0, 0.03278688524590164, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008130081300813009, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00980392156862745, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0045662100456621, 0.0, 0.0, 0.0, 0.0, 0.009523809523809525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03017241379310345, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007575757575757576, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007042253521126761, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01694915254237288, 0.010471204188481676, 0.0, 0.03048780487804878, 0.0, 0.017241379310344827, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010416666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00423728813559322, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.009615384615384616, 0.0, 0.03755868544600939, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022058823529411766, 0.0, 0.028112449799196786, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005128205128205128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007936507936507936, 0.0, 0.011363636363636364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.007042253521126761, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009345794392523364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009345794392523364, 0.027210884353741496, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"Loss: 8911.01171875\n",
						"Current max precision: 0.007736673348203521\n",
						"precs:  [0.015544041450777202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005291005291005291, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013513513513513514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015503875968992248, 0.0, 0.0, 0.0, 0.0, 0.01639344262295082, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004405286343612335, 0.0, 0.0, 0.006666666666666667, 0.0, 0.024291497975708502, 0.0, 0.0, 0.0, 0.02247191011235955, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0211864406779661, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011627906976744186, 0.014084507042253521, 0.009345794392523364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012121212121212121, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.04739336492890995, 0.0, 0.0, 0.0, 0.0, 0.011695906432748537, 0.0, 0.0, 0.0, 0.026490066225165563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05511811023622047, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0049504950495049506, 0.0, 0.008, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007633587786259542, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.02197802197802198, 0.0, 0.0365296803652968, 0.006211180124223602, 0.0, 0.0, 0.0, 0.0, 0.01834862385321101, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01098901098901099, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.017341040462427744, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004975124378109453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008695652173913044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011764705882352941, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0234375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01948051948051948, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04580152671755725, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009174311926605505, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010416666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007633587786259542, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010752688172043012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009174311926605505, 0.04285714285714286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010582010582010581, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012658227848101266, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023696682464454975, 0.0779816513761468, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012987012987012988, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0234375, 0.0, 0.0, 0.0, 0.009174311926605505, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007142857142857143, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.02912621359223301, 0.0, 0.0, 0.0, 0.010101010101010102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04395604395604396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016260162601626018, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005952380952380952, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01276595744680851, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012048192771084338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009615384615384616]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006024096385542169, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010869565217391304, 0.0, 0.0, 0.0, 0.0, 0.015544041450777202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
						"precs:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00847457627118644, 0.0, 0.0, 0.0]\n"
					]
				}
			],
			"source": [
				"from tqdm.notebook import tqdm\n",
				"import random\n",
				"# os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"\n",
				"NUM_EPOCHS = 2\n",
				"with pytorch_merged_dataloader.make_torch_dataloader(batch_size=1, num_epochs = NUM_EPOCHS) as train_dataloader:\n",
				"    ARTIST_SHAPE = (ARTIST_VECTOR_LENGTH, )\n",
				"    SONG_SHAPE = (SONGS_VECTOR_LENGTH, )\n",
				"    for batch_idx, row in tqdm(enumerate(train_dataloader), desc=f\"Training model\", total= (NUM_PLAYLISTS / conf[\"batch\"]) * NUM_EPOCHS):\n",
				"      # Pick random input_keep_prob between 0.5 and 0.8\n",
				"      # pretrain_model.input_keep_prob = random.uniform(0.5, 0.8) #TODO: make this dynamic inside the conf\n",
				"\n",
				"      padded_song_tensor = row[\"tracks_indices\"]\n",
				"      padded_artist_tensor = row[\"artists_indices\"]\n",
				"\n",
				"      song_dense = padded_tensors_to_dense_matrix(padded_song_tensor, SONG_SHAPE)\n",
				"      artist_dense = padded_tensors_to_dense_matrix(padded_artist_tensor, ARTIST_SHAPE)\n",
				"\n",
				"      song_dense = song_dense.to(device)\n",
				"      artist_dense = artist_dense.to(device)\n",
				"\n",
				"      rand_int = np.random.randint(2)\n",
				"      if rand_int == 0:\n",
				"        #Zero-out the artists\n",
				"        pretrain_optimizer.zero_grad()\n",
				"        # x = torch.concat((song_dense, torch.zeros_like(artist_dense)), dim=1).t()\n",
				"        x = torch.concat((song_dense, artist_dense), dim=1).t()\n",
				"        y = torch.concat((song_dense, artist_dense), dim=1).t()\n",
				"        pretrain_model(x, y)\n",
				"        loss = pretrain_model.cost\n",
				"        pretrain_model.cost.backward()\n",
				"        pretrain_optimizer.step()\n",
				"      if rand_int == 1:\n",
				"        #Zero-out the tracks\n",
				"        pretrain_optimizer.zero_grad()\n",
				"        # x = torch.concat((torch.zeros_like(song_dense), artist_dense), dim=1).t()\n",
				"        x = torch.concat((song_dense, artist_dense), dim=1).t()\n",
				"        y = torch.concat((song_dense, artist_dense), dim=1).t()\n",
				"        pretrain_model(x, y)\n",
				"        loss = pretrain_model.cost\n",
				"        pretrain_model.cost.backward()\n",
				"        pretrain_optimizer.step()\n",
				"      # if rand_int == 3:\n",
				"      #   #Do not zero-out anything\n",
				"      #   pretrain_optimizer.zero_grad()\n",
				"      #   x = torch.concat((song_dense, artist_dense), dim=1).t()\n",
				"      #   y = torch.concat((song_dense, artist_dense), dim=1).t()\n",
				"      #   pretrain_model(x, y)\n",
				"      #   loss = pretrain_model.cost\n",
				"      #   pretrain_model.cost.backward()\n",
				"      #   pretrain_optimizer.step()\n",
				"\n",
				"      if batch_idx % 20 == 0:\n",
				"        losses.append(loss)\n",
				"\n",
				"      test_prec = np.array(test_k_prec(pretrain_model.y_pred, song_dense)).mean()\n",
				"      if test_prec > max_test_prec:\n",
				"        max_test_prec = test_prec\n",
				"        print(f\"Max test prec: {max_test_prec}!\")\n",
				"\n",
				"      max_prec = perform_validation_step(pretrain_model, max_prec, BEST_PARAMS_PATH, save=False)\n",
				"\n",
				"      if batch_idx % 30 == 0:\n",
				"        print(f\"Loss: {loss}\")\n",
				"        print(f\"Current max precision: {max_prec}\")\n",
				"        # print(f\"Current confidences: \", confidences[0])"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 31,
			"metadata": {
				"id": "F85w_ZpmPD9t"
			},
			"outputs": [],
			"source": [
				"params = [param.cpu().detach().numpy() for param in pretrain_model.d_params]\n",
				"with open(BEST_PARAMS_PATH_2, 'wb') as f:\n",
				"  pickle.dump(params, f)"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "sFOoS7eGqlrH"
			},
			"source": [
				"Train with `DAE` loading the pretrained `DAE_tied` model"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 35,
			"metadata": {
				"id": "IFAj48uuqlbd"
			},
			"outputs": [],
			"source": [
				"conf = {\n",
				"    'batch': 32,\n",
				"    'n_input': SONGS_VECTOR_LENGTH + ARTIST_VECTOR_LENGTH,\n",
				"    'hidden': 256,\n",
				"    'lr': 0.0001,\n",
				"    'reg_lambda': 0.0000,\n",
				"    'initval': BEST_PARAMS_PATH,\n",
				"    \"keep_prob\": 0.8,\n",
				"    \"input_keep_prob\": 0.8, # This isn't used for now because of the .uniform()\n",
				"    'save': os.path.join(SAVED_MODELS, \"dae_model.pickle\")\n",
				"}\n",
				"dae_model = DAE(conf)\n",
				"dae_model.init_weight()\n",
				"optimizer = optim.Adam(dae_model.d_params, lr=conf['lr'])\n",
				"\n",
				"min_loss = 600\n",
				"losses = []\n",
				"best_params = []\n",
				"max_prec = 0\n",
				"FINE_TUNED_BEST_PARAMS_PATH = os.path.join(SAVED_MODELS, \"final_best_params.pickle\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 36,
			"metadata": {
				"id": "osIKMm2WCdLM"
			},
			"outputs": [],
			"source": [
				"torch.cuda.empty_cache()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 37,
			"metadata": {
				"id": "gyw3SnVYyRP1"
			},
			"outputs": [
				{
					"data": {
						"application/vnd.jupyter.widget-view+json": {
							"model_id": "43c9929d5c0049cea15d50a934382538",
							"version_major": 2,
							"version_minor": 0
						},
						"text/plain": [
							"Training model:   0%|          | 0/6250.0 [00:00<?, ?it/s]"
						]
					},
					"metadata": {},
					"output_type": "display_data"
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"torch.Size([32, 681805])\n",
						"torch.Size([32, 681805])\n",
						"torch.Size([32, 681805])\n",
						"torch.Size([32, 681805])\n",
						"torch.Size([32, 681805])\n",
						"torch.Size([32, 681805])\n",
						"torch.Size([32, 681805])\n",
						"torch.Size([32, 681805])\n",
						"torch.Size([32, 681805])\n",
						"torch.Size([32, 681805])\n",
						"torch.Size([32, 681805])\n",
						"torch.Size([32, 681805])\n",
						"torch.Size([32, 681805])\n"
					]
				},
				{
					"ename": "ZeroDivisionError",
					"evalue": "division by zero",
					"output_type": "error",
					"traceback": [
						"\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
						"\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
						"Cell \u001b[0;32mIn[37], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mif\u001b[39;00m batch_idx \u001b[39m%\u001b[39m \u001b[39m20\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     45\u001b[0m   losses\u001b[39m.\u001b[39mappend(loss)\n\u001b[0;32m---> 47\u001b[0m confidences, max_prec \u001b[39m=\u001b[39m perform_validation_step(dae_model, max_prec, FINE_TUNED_BEST_PARAMS_PATH, save\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     49\u001b[0m \u001b[39mif\u001b[39;00m batch_idx \u001b[39m%\u001b[39m \u001b[39m30\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     50\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
						"Cell \u001b[0;32mIn[22], line 2\u001b[0m, in \u001b[0;36mperform_validation_step\u001b[0;34m(model, max_prec, save_path, save)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mperform_validation_step\u001b[39m(model: DAE_tied, max_prec: \u001b[39mfloat\u001b[39m, save_path:\u001b[39mstr\u001b[39m, save: \u001b[39mbool\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     eval_loss, prec \u001b[39m=\u001b[39m validate(model)\n\u001b[1;32m      4\u001b[0m     \u001b[39mif\u001b[39;00m prec \u001b[39m>\u001b[39m max_prec:\n\u001b[1;32m      5\u001b[0m         max_prec \u001b[39m=\u001b[39m prec\n",
						"Cell \u001b[0;32mIn[21], line 40\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     36\u001b[0m         ground_truth \u001b[39m=\u001b[39m padded_tensors_to_dense_matrix(padded_eval_song_tensor_test, SONG_SHAPE)\n\u001b[1;32m     38\u001b[0m         ground_truth \u001b[39m=\u001b[39m ground_truth\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 40\u001b[0m         prec_list \u001b[39m=\u001b[39m evaluate(song_dense, eval_preds, ground_truth)\n\u001b[1;32m     41\u001b[0m         precs\u001b[39m.\u001b[39mextend(prec_list)\n\u001b[1;32m     43\u001b[0m mean_prec: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(precs) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(precs)\n",
						"Cell \u001b[0;32mIn[19], line 36\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(input, eval_preds, ground_truth)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(\u001b[39minput\u001b[39m: torch\u001b[39m.\u001b[39mTensor, eval_preds: torch\u001b[39m.\u001b[39mTensor, ground_truth: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mfloat\u001b[39m]:\n\u001b[0;32m---> 36\u001b[0m     \u001b[39mreturn\u001b[39;00m k_prec(\u001b[39minput\u001b[39;49m, eval_preds, ground_truth)\n",
						"Cell \u001b[0;32mIn[19], line 28\u001b[0m, in \u001b[0;36mk_prec\u001b[0;34m(input, eval_preds, ground_truth)\u001b[0m\n\u001b[1;32m     26\u001b[0m     common_elements \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mintersect1d(top_k_preds_idx, ground_truth_idx\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy())\n\u001b[1;32m     27\u001b[0m     num_common_elements \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(common_elements)\n\u001b[0;32m---> 28\u001b[0m     precs\u001b[39m.\u001b[39mappend(num_common_elements\u001b[39m/\u001b[39;49mnum_ground_truth_songs)\n\u001b[1;32m     30\u001b[0m \u001b[39mreturn\u001b[39;00m precs\n",
						"\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
					]
				}
			],
			"source": [
				"from tqdm.notebook import tqdm\n",
				"import random\n",
				"# os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"\n",
				"NUM_EPOCHS = 2\n",
				"with pytorch_merged_dataloader.make_torch_dataloader(batch_size=conf[\"batch\"], num_epochs = NUM_EPOCHS) as train_dataloader:\n",
				"    ARTIST_SHAPE = (ARTIST_VECTOR_LENGTH, )\n",
				"    SONG_SHAPE = (SONGS_VECTOR_LENGTH, )\n",
				"    for batch_idx, row in tqdm(enumerate(train_dataloader), desc=f\"Training model\", total= (NUM_PLAYLISTS / conf[\"batch\"]) * NUM_EPOCHS):\n",
				"      # Pick random input_keep_prob between 0.5 and 0.8\n",
				"    #   dae_model.input_keep_prob = random.uniform(0.5, 0.8) #TODO: make this dynamic inside the conf\n",
				"\n",
				"      dae_model.input_keep_prob = random.uniform(0.3, 1) #TODO: make this dynamic inside the conf\n",
				"      dae_model.keep_prob = random.uniform(0.3, 1) #TODO: make this dynamic inside the conf\n",
				"\n",
				"      padded_song_tensor = row[\"tracks_indices\"]\n",
				"      padded_artist_tensor = row[\"artists_indices\"]\n",
				"\n",
				"      song_dense = padded_tensors_to_dense_matrix(padded_song_tensor, SONG_SHAPE)\n",
				"      artist_dense = padded_tensors_to_dense_matrix(padded_artist_tensor, ARTIST_SHAPE)\n",
				"\n",
				"      song_dense = song_dense.to(device)\n",
				"      artist_dense = artist_dense.to(device)\n",
				"\n",
				"      rand_int = np.random.randint(2)\n",
				"      if rand_int == 0:\n",
				"        #Zero-out the artists\n",
				"        optimizer.zero_grad()\n",
				"        x = torch.concat((song_dense, artist_dense), dim=1).t()\n",
				"        y = torch.concat((song_dense, artist_dense), dim=1).t()\n",
				"        dae_model(x, y)\n",
				"        loss = dae_model.cost\n",
				"        dae_model.cost.backward()\n",
				"        optimizer.step()\n",
				"      if rand_int == 1:\n",
				"        #Zero-out the tracks\n",
				"        optimizer.zero_grad()\n",
				"        x = torch.concat((song_dense, artist_dense), dim=1).t()\n",
				"        y = torch.concat((song_dense, artist_dense), dim=1).t()\n",
				"        dae_model(x, y)\n",
				"        loss = dae_model.cost\n",
				"        dae_model.cost.backward()\n",
				"        optimizer.step()\n",
				"\n",
				"      if batch_idx % 20 == 0:\n",
				"        losses.append(loss)\n",
				"\n",
				"      confidences, max_prec = perform_validation_step(dae_model, max_prec, FINE_TUNED_BEST_PARAMS_PATH, save=False)\n",
				"\n",
				"      if batch_idx % 30 == 0:\n",
				"        print(f\"Loss: {loss}\")\n",
				"        print(f\"Current max precision: {max_prec}\")\n",
				"        # k = torch.sum(y == 1, dim=0)\n",
				"        # counts = evaluate(pretrain_model.y_pred, y.t(), k)\n",
				"        # print(\"Precisions: \", torch.tensor(counts)/k.cpu())"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "JQL3P9JByR7Q"
			},
			"source": [
				"Let's see how the loss decreases"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"id": "qF9gP0FMLdw2"
			},
			"outputs": [],
			"source": [
				"SAVE_MODEL_PATH = os.path.join(SAVED_DFS_PATH, f\"model_new.pickle\")\n",
				"params = [param.cpu().detach().numpy() for param in dae_model.d_params]\n",
				"with open(SAVE_MODEL_PATH, 'wb') as f:\n",
				"  pickle.dump(params, f)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"id": "V4JxgOCvx2TE"
			},
			"outputs": [],
			"source": [
				"import matplotlib.pyplot as plt\n",
				"x = np.arange(len(losses))\n",
				"plt.plot(x, [loss.item() for loss in losses])\n",
				"plt.xlabel('Iteration')\n",
				"plt.ylabel('Loss')\n",
				"plt.title('Loss Progression')\n",
				"plt.show()"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "Zqyho9fPl0ow"
			},
			"source": [
				"# Inference"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"id": "S9RFO76gK8Qb"
			},
			"outputs": [],
			"source": [
				"from pyspark.ml.linalg import VectorUDT\n",
				"song_schema = StructType([\n",
				"    StructField(\"pos\", IntegerType(), True),\n",
				"    StructField(\"artist_name\", StringType(), True),\n",
				"    StructField(\"track_uri\", StringType(), True),\n",
				"    StructField(\"artist_uri\", StringType(), True),\n",
				"    StructField(\"track_name\", StringType(), True),\n",
				"    StructField(\"album_uri\", StringType(), True),\n",
				"    StructField(\"duration_ms\", LongType(), True),\n",
				"    StructField(\"album_name\", StringType(), True)\n",
				"])\n",
				"\n",
				"playlist_schema = StructType([\n",
				"    StructField(\"name\", StringType(), True),\n",
				"    StructField(\"collaborative\", StringType(), True),\n",
				"    StructField(\"pid\", IntegerType(), True),\n",
				"    StructField(\"modified_at\", IntegerType(), True),\n",
				"    StructField(\"num_tracks\", IntegerType(), True),\n",
				"    StructField(\"num_albums\", IntegerType(), True),\n",
				"    StructField(\"num_followers\", IntegerType(), True),\n",
				"    StructField(\"tracks\", ArrayType(song_schema), True),\n",
				"    StructField(\"num_edits\", IntegerType(), True),\n",
				"    StructField(\"duration_ms\", IntegerType(), True),\n",
				"    StructField(\"num_artists\", IntegerType(), True),\n",
				"])"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"id": "5lgIPJo2tbUL"
			},
			"outputs": [],
			"source": [
				"SONGS_EMBEDDINGS_PATH_TEST_TRAIN = os.path.join(SAVED_DFS_PATH, f\"nn_songs_embeddings-test-train-{NUM_PLAYLISTS}.json\")\n",
				"SONGS_EMBEDDINGS_PATH_TEST_TEST = os.path.join(SAVED_DFS_PATH, f\"nn_songs_embeddings-test-test-{NUM_PLAYLISTS}.json\")\n",
				"\n",
				"ARTISTS_EMBEDDINGS_PATH_TEST_TRAIN = os.path.join(SAVED_DFS_PATH, f\"nn_artists_embeddings-test-train-{NUM_PLAYLISTS}.json\")\n",
				"ARTISTS_EMBEDDINGS_PATH_TEST_TEST = os.path.join(SAVED_DFS_PATH, f\"nn_artists_embeddings-test-test-{NUM_PLAYLISTS}.json\")\n",
				"\n",
				"songs_embeddings_test_train = spark.read.schema(playlist_schema_mapped).json(SONGS_EMBEDDINGS_PATH_TEST_TRAIN)\n",
				"songs_embeddings_test_test = spark.read.schema(playlist_schema_mapped).json(SONGS_EMBEDDINGS_PATH_TEST_TEST)\n",
				"\n",
				"artists_embeddings_test_train = spark.read.schema(playlist_schema_mapped).json(ARTISTS_EMBEDDINGS_PATH_TEST_TRAIN)\n",
				"artists_embeddings_test_test = spark.read.schema(playlist_schema_mapped).json(ARTISTS_EMBEDDINGS_PATH_TEST_TEST)\n",
				"\n",
				"TEST_TRAIN_DF_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_test_df-train-{NUM_PLAYLISTS}.json\")\n",
				"TEST_TEST_DF_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_test_df-test-{NUM_PLAYLISTS}.json\")\n",
				"\n",
				"test_train_df = spark.read.schema(playlist_schema).json(TEST_TRAIN_DF_PATH)\n",
				"test_test_df = spark.read.schema(playlist_schema).json(TEST_TEST_DF_PATH)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"id": "wKbyd0kRl3SH"
			},
			"outputs": [],
			"source": [
				"def construct_prediction_df(prediction: torch.Tensor, mapping: DataFrame, top_n: int = 50) -> DataFrame:\n",
				"  pred_np = prediction.detach().numpy()\n",
				"  indexes = np.arange(pred_np.shape[0]) # To compensate the index start at 1\n",
				"  schema = StructType([\n",
				"      StructField(\"pos\", IntegerType()),\n",
				"      StructField(\"confidence\", FloatType())\n",
				"  ])\n",
				"  prediction_df = spark.createDataFrame([(pos, conf) for pos, conf in zip(indexes.tolist(), pred_np.tolist())],schema)\n",
				"  prediction_info = prediction_df.join(mapping, \"pos\")\n",
				"  return prediction_info\n",
				"\n",
				"# prediction_df = construct_prediction_df(prediction, songs_df_test)\n",
				"# prediction_df.show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"id": "bQ9LquCdSbJJ"
			},
			"outputs": [],
			"source": [
				"def remove_existing_tracks(playlist_tracks: DataFrame, recommendations_df: DataFrame) -> DataFrame:\n",
				"  playlist_tracks = playlist_tracks.select(\"track_uri\").cache()\n",
				"  playlist_tracks_compatible = playlist_tracks.join(F.broadcast(recommendations_df), on=\"track_uri\")\n",
				"  playlist_tracks.unpersist()\n",
				"  return recommendations_df.exceptAll(F.broadcast(playlist_tracks_compatible))"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "Wx-tghy0bAkU"
			},
			"source": [
				"# Evaluation"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"id": "Hb793kgebBwJ"
			},
			"outputs": [],
			"source": [
				"def precision_at_k(recommendations, ground_truth, num_of_recommendations) -> float:\n",
				"    \"\"\"\n",
				"    Calculates precision at k for the recommendations.\n",
				"    \"\"\"\n",
				"    recommended_relevant_tracks = recommendations.join(ground_truth, \"track_uri\").cache()\n",
				"    reccomended_relevant_tracks_count = recommended_relevant_tracks.count() #this can be top_n_results.join in order to be more performant\n",
				"    recommended_relevant_tracks.unpersist()\n",
				"    precision = reccomended_relevant_tracks_count / float(num_of_recommendations)\n",
				"\n",
				"    return precision\n",
				"\n",
				"\n",
				"import math\n",
				"def normalized_discounted_cumulative_gain(recommendations: DataFrame, ground_truth: DataFrame, num_of_recommendations: int) -> float:\n",
				"  recommendations_list = recommendations.collect()\n",
				"  cumulative_gain = 0\n",
				"\n",
				"  intersection = recommendations.join(ground_truth, \"track_uri\").count()\n",
				"  if intersection == 0: return 0\n",
				"\n",
				"  ideal_cumulative_gain = 1 + np.array([(1 / math.log(i, 2)) for i in range(2, 2+intersection)]).sum() #TODO: replace this with sum([])\n",
				"  for index, row in enumerate(recommendations_list):\n",
				"    i = index + 1\n",
				"    is_rel = ground_truth.filter(F.col(\"track_uri\").isin(row.track_uri)).count() > 0\n",
				"    rel = 1 if is_rel else 0\n",
				"    if i == 1:\n",
				"      cumulative_gain += rel\n",
				"    else:\n",
				"      cumulative_gain += (rel / math.log(i, 2))\n",
				"  return cumulative_gain / ideal_cumulative_gain"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "VUYEe5iHbTHs"
			},
			"source": [
				"Creating the dataloaders for the test set"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"id": "LYXLsGIrbH2e"
			},
			"outputs": [],
			"source": [
				"spark.conf.set(SparkDatasetConverter.PARENT_CACHE_DIR_URL_CONF, f'file://{CACHE}')\n",
				"\n",
				"pytorch_songs_df_test = convert_sparse_to_indices(songs_embeddings_test_train.select(\"tracks\"))\n",
				"songs_converter_test = make_spark_converter(pytorch_songs_df_test)\n",
				"\n",
				"pytorch_artists_df_test = convert_sparse_to_indices(artists_embeddings_test_train.select(\"tracks\"))\n",
				"artist_converter_test = make_spark_converter(pytorch_artists_df_test)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"id": "9h7NRo3Ggt3h"
			},
			"outputs": [],
			"source": [
				"#Hyperparameters used in the paper\n",
				"conf = {\n",
				"    'batch': 32,\n",
				"    'n_input': SONGS_VECTOR_LENGTH + ARTIST_VECTOR_LENGTH,\n",
				"    'hidden': 25,\n",
				"    'lr': 0.0001,\n",
				"    'reg_lambda': 0.0000,\n",
				"    'initval': \"NULL\",\n",
				"    \"keep_prob\": 0.5,\n",
				"    \"input_keep_prob\": 0.5, # This isn't used for now because of the .uniform()\n",
				"    'save': os.path.join(SAVED_MODELS, \"dae_model.pickle\")\n",
				"}\n",
				"dae_model_test = DAE(conf)\n",
				"dae_model_test.init_weight()\n",
				"dae_model_test.eval()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"id": "dn2zrRCSdKQO"
			},
			"outputs": [],
			"source": [
				"ARTIST_SHAPE = (ARTIST_VECTOR_LENGTH, )\n",
				"SONG_SHAPE = (SONGS_VECTOR_LENGTH, )\n",
				"with songs_converter_test.make_torch_dataloader(batch_size=conf[\"batch\"], num_epochs =1) as songs_dataloader:\n",
				"  with artist_converter_test.make_torch_dataloader(batch_size=conf[\"batch\"], num_epochs=1) as artists_dataloader:\n",
				"    zipped_dataloaders = zip(songs_dataloader, artists_dataloader)\n",
				"    for batch_idx, (song, artist) in tqdm(enumerate(zipped_dataloaders), desc=f\"Evaluation...\", total= (NUM_PLAYLISTS / conf[\"batch\"])):\n",
				"      padded_song_tensor = song[\"embedding_indices\"]\n",
				"      padded_artist_tensor = artist[\"embedding_indices\"]\n",
				"\n",
				"      song_dense = padded_tensors_to_dense_matrix(padded_song_tensor, SONG_SHAPE)\n",
				"      artist_dense = padded_tensors_to_dense_matrix(padded_artist_tensor, ARTIST_SHAPE)\n",
				"\n",
				"      song_dense = song_dense.to(device)\n",
				"      artist_dense = artist_dense.to(device)\n",
				"\n",
				"      x = torch.concat((song_dense, artist_dense), dim=1).t()\n",
				"      y = torch.concat((song_dense, artist_dense), dim=1).t()\n",
				"\n",
				"      dae_model_test(x,y)\n",
				"\n",
				"      result = dae_model_test.y_pred\n",
				"      break"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"id": "hRZ9w5nr5TaK"
			},
			"outputs": [],
			"source": [
				"result"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"id": "yg8V8VSSu3XI"
			},
			"outputs": [],
			"source": [
				"# torch.concat((song_dense[:, 1:], artist_dense[:, 1:]), dim=1).t().shape\n",
				"# (song_dense[:, 0] == 0.).all(), (artist_dense[:, 0] == 0.).all()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"id": "kLpygSgaMVr6"
			},
			"outputs": [],
			"source": [
				"# result = result.to(\"cpu\")\n",
				"# prediction_df = construct_prediction_df(result[10][:SONGS_VECTOR_LENGTH_TEST], songs_df_test, 20)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"id": "-uYwzqLFMjWE"
			},
			"outputs": [],
			"source": [
				"# prediction_df.orderBy(\"pos\").show(truncate=False)\n",
				"# songs_df_test.show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"id": "-0wojIXkuFnN"
			},
			"outputs": [],
			"source": [
				"# def evaluate_batch(batch_result: torch.Tensor, batch_n: int) -> Tuple[float, float]:\n",
				"#   \"\"\"\n",
				"#   Returns the precision and NDCG for a given batch.\n",
				"#   \"\"\"\n",
				"\n",
				"#   return 0,0\n",
				"\n",
				"# def perform_evaluation(songs_dataloader, artists_dataloader, test_set):\n",
				"#   \"\"\"\n",
				"#   Returns the precision and NDCG, averaged from all the samples in the test set\n",
				"#   \"\"\"\n",
				"#   with songs_converter_test.make_torch_dataloader(num_epochs =1) as songs_dataloader:\n",
				"#     with artist_converter_test.make_torch_dataloader(num_epochs=1) as artists_dataloader:\n",
				"#       zipped_dataloaders = zip(songs_dataloader, artists_dataloader)\n",
				"#       for batch_idx, (song, artist) in tqdm(enumerate(zipped_dataloaders), desc=f\"Evaluation...\", total= (NUM_PLAYLISTS / 32) * NUM_EPOCHS):\n",
				"#         padded_song_tensor = song[\"embedding_indices\"]\n",
				"#         padded_artist_tensor = artist[\"embedding_indices\"]\n",
				"\n",
				"#         song_dense = padded_tensors_to_dense_matrix(padded_song_tensor, SONG_SHAPE)\n",
				"#         artist_dense = padded_tensors_to_dense_matrix(padded_artist_tensor, ARTIST_SHAPE)\n",
				"\n",
				"#         x = torch.concat((song_dense, artist_dense), dim=1).t()\n",
				"#         y = torch.concat((song_dense, artist_dense), dim=1).t()\n",
				"#         dae_model(x,y)\n",
				"#         batch_result = dae_model.y_pred\n",
				"#         break\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"id": "W4LWsnwWeVAV"
			},
			"outputs": [],
			"source": [
				"#Testing the first batch\n",
				"\n",
				"results = []\n",
				"# for i in tqdm(range(32)):\n",
				"PID = 71860\n",
				"ground_truth = test_test_df.filter(F.col(\"pid\") == PID).select(F.explode(\"tracks\")).select(\"col.*\")\n",
				"playlist_train_songs = test_train_df.filter(F.col(\"pid\") == PID).select(F.explode(\"tracks\")).select(\"col.*\")\n",
				"\n",
				"#Removing rare songs (that the model didn't consider)\n",
				"#This may be not the best approach since the train songs or ground truth may become 0\n",
				"clean_ground_truth = ground_truth.join(song_mapping, on=\"track_uri\").cache()\n",
				"clean_playlist_train_songs = playlist_train_songs.join(song_mapping, on=\"track_uri\").cache()\n",
				"\n",
				"# n_recommendations = ground_truth.count() or 1\n",
				"n_recommendations = 500\n",
				"result = result.cpu()\n",
				"\n",
				"#The result[i] has to be aligned with the PID. i != PID.\n",
				"prediction_df = construct_prediction_df(result[1][:SONGS_VECTOR_LENGTH], song_mapping, n_recommendations).cache()\n",
				"clean_prediction_df = remove_existing_tracks(clean_playlist_train_songs, prediction_df)\n",
				"\n",
				"clean_prediction_df = prediction_df.orderBy(F.col(\"confidence\").desc()).limit(n_recommendations).cache()\n",
				"\n",
				"prec = precision_at_k(clean_prediction_df, clean_ground_truth, n_recommendations)\n",
				"gain = normalized_discounted_cumulative_gain(clean_prediction_df, clean_ground_truth, n_recommendations)\n",
				"print(PID, prec, gain)\n",
				"results.append((prec, gain))\n",
				"\n",
				"ground_truth.unpersist()\n",
				"clean_ground_truth.unpersist()\n",
				"playlist_train_songs.unpersist()\n",
				"clean_playlist_train_songs.unpersist()\n",
				"prediction_df.unpersist()\n",
				"clean_prediction_df.unpersist()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"id": "8XUxFpPGVLf-"
			},
			"outputs": [],
			"source": [
				"print(\"Playlist train songs\")\n",
				"playlist_train_songs.show(truncate=False)\n",
				"print(\"Clean playlist train songs\")\n",
				"clean_playlist_train_songs.show(truncate=False)\n",
				"print(\"Ground truth songs\")\n",
				"ground_truth.show(truncate=False)\n",
				"print(\"Clean ground truth songs\")\n",
				"clean_ground_truth.show(truncate=False)\n",
				"print(f\"Prediction df songs (num recommendations: {n_recommendations})\")\n",
				"prediction_df.show(truncate=False)\n",
				"print(f\"Clean Prediction df songs (num recommendations: {n_recommendations})\")\n",
				"clean_prediction_df.show(truncate=False)\n",
				"prec, gain"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"id": "iN8Fk_7Jel4-"
			},
			"outputs": [],
			"source": [
				"def average_results(results):\n",
				"  prec_avg = sum(prec for prec, _ in results) / len(results)\n",
				"  gain_avg = sum(gain for _, gain in results) / len(results)\n",
				"  return prec_avg, gain_avg\n",
				"\n",
				"average_results(results)"
			]
		}
	],
	"metadata": {
		"accelerator": "GPU",
		"colab": {
			"collapsed_sections": [
				"XvQ6e0PgCOZg"
			],
			"include_colab_link": true,
			"provenance": [],
			"toc_visible": true,
			"gpuType": "T4",
			"include_colab_link": true
		},
		"kernelspec": {
			"display_name": "Python 3",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.10.9"
		},
		"widgets": {
			"application/vnd.jupyter.widget-state+json": {
				"489975773ec0499cbace7cae6ac15d06": {
					"model_module": "@jupyter-widgets/controls",
					"model_module_version": "1.5.0",
					"model_name": "HBoxModel",
					"state": {
						"_dom_classes": [],
						"_model_module": "@jupyter-widgets/controls",
						"_model_module_version": "1.5.0",
						"_model_name": "HBoxModel",
						"_view_count": null,
						"_view_module": "@jupyter-widgets/controls",
						"_view_module_version": "1.5.0",
						"_view_name": "HBoxView",
						"box_style": "",
						"children": [
							"IPY_MODEL_fc710cd691b4434fb36a2c18918b5ee6",
							"IPY_MODEL_ba06d14e31314d078a4c6efdf076f73a",
							"IPY_MODEL_a8e6455e5056443d9915f855f3cd7c3b"
						],
						"layout": "IPY_MODEL_22f37ad07c524b85b57a1b9173eab0ff"
					}
				},
				"fc710cd691b4434fb36a2c18918b5ee6": {
					"model_module": "@jupyter-widgets/controls",
					"model_name": "HTMLModel",
					"model_module_version": "1.5.0",
					"state": {
						"_model_module": "@jupyter-widgets/base",
						"_model_module_version": "1.2.0",
						"_model_name": "LayoutModel",
						"_view_count": null,
						"_view_module": "@jupyter-widgets/controls",
						"_view_module_version": "1.5.0",
						"_view_name": "HTMLView",
						"description": "",
						"description_tooltip": null,
						"layout": "IPY_MODEL_dc7f30dacf5143b1803d37a56c1ba1c1",
						"placeholder": "​",
						"style": "IPY_MODEL_3c9b12e4657940ecbe58b00d4969de9c",
						"value": "Training model:   3%"
					}
				},
				"ba06d14e31314d078a4c6efdf076f73a": {
					"model_module": "@jupyter-widgets/controls",
					"model_module_version": "1.5.0",
					"model_name": "FloatProgressModel",
					"state": {
						"_dom_classes": [],
						"_model_module": "@jupyter-widgets/controls",
						"_model_module_version": "1.5.0",
						"_model_name": "FloatProgressModel",
						"_view_count": null,
						"_view_module": "@jupyter-widgets/controls",
						"_view_module_version": "1.5.0",
						"_view_name": "ProgressView",
						"bar_style": "",
						"description": "",
						"description_tooltip": null,
						"layout": "IPY_MODEL_c37ea40712a6454296dba3bf91be9e61",
						"max": 12500,
						"min": 0,
						"orientation": "horizontal",
						"style": "IPY_MODEL_52f58503a7f34fb9b33ce766f3d0fc34",
						"value": 326
					}
				},
				"a8e6455e5056443d9915f855f3cd7c3b": {
					"model_module": "@jupyter-widgets/controls",
					"model_name": "HTMLModel",
					"model_module_version": "1.5.0",
					"state": {
						"_dom_classes": [],
						"_model_module": "@jupyter-widgets/controls",
						"_model_module_version": "1.5.0",
						"_model_name": "HTMLModel",
						"_view_count": null,
						"_view_module": "@jupyter-widgets/controls",
						"_view_module_version": "1.5.0",
						"_view_name": "HTMLView",
						"description": "",
						"description_tooltip": null,
						"layout": "IPY_MODEL_79d9abd62bc14970ab35f58815434564",
						"placeholder": "​",
						"style": "IPY_MODEL_d6ee478fde1a4e5aa024bccd905feecb",
						"value": " 326/12500.0 [05:44&lt;3:50:54,  1.14s/it]"
					}
				},
				"22f37ad07c524b85b57a1b9173eab0ff": {
					"model_module": "@jupyter-widgets/base",
					"model_name": "LayoutModel",
					"model_module_version": "1.2.0",
					"state": {
						"_model_module": "@jupyter-widgets/base",
						"_model_module_version": "1.2.0",
						"_model_name": "LayoutModel",
						"_view_count": null,
						"_view_module": "@jupyter-widgets/base",
						"_view_module_version": "1.2.0",
						"_view_name": "LayoutView",
						"align_content": null,
						"align_items": null,
						"align_self": null,
						"border": null,
						"bottom": null,
						"display": null,
						"flex": null,
						"flex_flow": null,
						"grid_area": null,
						"grid_auto_columns": null,
						"grid_auto_flow": null,
						"grid_auto_rows": null,
						"grid_column": null,
						"grid_gap": null,
						"grid_row": null,
						"grid_template_areas": null,
						"grid_template_columns": null,
						"grid_template_rows": null,
						"height": null,
						"justify_content": null,
						"justify_items": null,
						"left": null,
						"margin": null,
						"max_height": null,
						"max_width": null,
						"min_height": null,
						"min_width": null,
						"object_fit": null,
						"object_position": null,
						"order": null,
						"overflow": null,
						"overflow_x": null,
						"overflow_y": null,
						"padding": null,
						"right": null,
						"top": null,
						"visibility": null,
						"width": null
					}
				},
				"dc7f30dacf5143b1803d37a56c1ba1c1": {
					"model_module": "@jupyter-widgets/base",
					"model_name": "LayoutModel",
					"model_module_version": "1.2.0",
					"state": {
						"_model_module": "@jupyter-widgets/base",
						"_model_module_version": "1.2.0",
						"_model_name": "LayoutModel",
						"_view_count": null,
						"_view_module": "@jupyter-widgets/base",
						"_view_module_version": "1.2.0",
						"_view_name": "LayoutView",
						"align_content": null,
						"align_items": null,
						"align_self": null,
						"border": null,
						"bottom": null,
						"display": null,
						"flex": null,
						"flex_flow": null,
						"grid_area": null,
						"grid_auto_columns": null,
						"grid_auto_flow": null,
						"grid_auto_rows": null,
						"grid_column": null,
						"grid_gap": null,
						"grid_row": null,
						"grid_template_areas": null,
						"grid_template_columns": null,
						"grid_template_rows": null,
						"height": null,
						"justify_content": null,
						"justify_items": null,
						"left": null,
						"margin": null,
						"max_height": null,
						"max_width": null,
						"min_height": null,
						"min_width": null,
						"object_fit": null,
						"object_position": null,
						"order": null,
						"overflow": null,
						"overflow_x": null,
						"overflow_y": null,
						"padding": null,
						"right": null,
						"top": null,
						"visibility": null,
						"width": null
					}
				},
				"3c9b12e4657940ecbe58b00d4969de9c": {
					"model_module": "@jupyter-widgets/controls",
					"model_name": "DescriptionStyleModel",
					"model_module_version": "1.5.0",
					"state": {
						"_model_module": "@jupyter-widgets/controls",
						"_model_module_version": "1.5.0",
						"_model_name": "DescriptionStyleModel",
						"_view_count": null,
						"_view_module": "@jupyter-widgets/base",
						"_view_module_version": "1.2.0",
						"_view_name": "StyleView",
						"description_width": ""
					}
				},
				"c37ea40712a6454296dba3bf91be9e61": {
					"model_module": "@jupyter-widgets/base",
					"model_name": "LayoutModel",
					"model_module_version": "1.2.0",
					"state": {
						"_model_module": "@jupyter-widgets/base",
						"_model_module_version": "1.2.0",
						"_model_name": "LayoutModel",
						"_view_count": null,
						"_view_module": "@jupyter-widgets/base",
						"_view_module_version": "1.2.0",
						"_view_name": "LayoutView",
						"align_content": null,
						"align_items": null,
						"align_self": null,
						"border": null,
						"bottom": null,
						"display": null,
						"flex": null,
						"flex_flow": null,
						"grid_area": null,
						"grid_auto_columns": null,
						"grid_auto_flow": null,
						"grid_auto_rows": null,
						"grid_column": null,
						"grid_gap": null,
						"grid_row": null,
						"grid_template_areas": null,
						"grid_template_columns": null,
						"grid_template_rows": null,
						"height": null,
						"justify_content": null,
						"justify_items": null,
						"left": null,
						"margin": null,
						"max_height": null,
						"max_width": null,
						"min_height": null,
						"min_width": null,
						"object_fit": null,
						"object_position": null,
						"order": null,
						"overflow": null,
						"overflow_x": null,
						"overflow_y": null,
						"padding": null,
						"right": null,
						"top": null,
						"visibility": null,
						"width": null
					}
				},
				"52f58503a7f34fb9b33ce766f3d0fc34": {
					"model_module": "@jupyter-widgets/controls",
					"model_name": "ProgressStyleModel",
					"model_module_version": "1.5.0",
					"state": {
						"_model_module": "@jupyter-widgets/controls",
						"_model_module_version": "1.5.0",
						"_model_name": "ProgressStyleModel",
						"_view_count": null,
						"_view_module": "@jupyter-widgets/base",
						"_view_module_version": "1.2.0",
						"_view_name": "StyleView",
						"bar_color": null,
						"description_width": ""
					}
				},
				"79d9abd62bc14970ab35f58815434564": {
					"model_module": "@jupyter-widgets/base",
					"model_name": "LayoutModel",
					"model_module_version": "1.2.0",
					"state": {
						"_model_module": "@jupyter-widgets/base",
						"_model_module_version": "1.2.0",
						"_model_name": "LayoutModel",
						"_view_count": null,
						"_view_module": "@jupyter-widgets/base",
						"_view_module_version": "1.2.0",
						"_view_name": "LayoutView",
						"align_content": null,
						"align_items": null,
						"align_self": null,
						"border": null,
						"bottom": null,
						"display": null,
						"flex": null,
						"flex_flow": null,
						"grid_area": null,
						"grid_auto_columns": null,
						"grid_auto_flow": null,
						"grid_auto_rows": null,
						"grid_column": null,
						"grid_gap": null,
						"grid_row": null,
						"grid_template_areas": null,
						"grid_template_columns": null,
						"grid_template_rows": null,
						"height": null,
						"justify_content": null,
						"justify_items": null,
						"left": null,
						"margin": null,
						"max_height": null,
						"max_width": null,
						"min_height": null,
						"min_width": null,
						"object_fit": null,
						"object_position": null,
						"order": null,
						"overflow": null,
						"overflow_x": null,
						"overflow_y": null,
						"padding": null,
						"right": null,
						"top": null,
						"visibility": null,
						"width": null
					}
				},
				"d6ee478fde1a4e5aa024bccd905feecb": {
					"model_module": "@jupyter-widgets/controls",
					"model_name": "DescriptionStyleModel",
					"model_module_version": "1.5.0",
					"state": {
						"_model_module": "@jupyter-widgets/controls",
						"_model_module_version": "1.5.0",
						"_model_name": "DescriptionStyleModel",
						"_view_count": null,
						"_view_module": "@jupyter-widgets/base",
						"_view_module_version": "1.2.0",
						"_view_name": "StyleView",
						"description_width": ""
					}
				}
			}
		}
	},
	"nbformat": 4,
	"nbformat_minor": 0
}
