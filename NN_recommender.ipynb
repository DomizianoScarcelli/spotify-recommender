{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DomizianoScarcelli/big-data-project/blob/dev/NN_recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XvQ6e0PgCOZg"
      },
      "source": [
        "### Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "def is_running_on_colab():\n",
        "    return \"COLAB_GPU\" in os.environ\n",
        "\n",
        "LOCAL = not is_running_on_colab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bjPz4xH4WFYB",
        "outputId": "42c169d8-dd98-4d5b-ce88-cd35f1b7ca4c"
      },
      "outputs": [],
      "source": [
        "if not LOCAL:\n",
        "    !pip install petastorm -qq\n",
        "    !pip install pyspark -qq\n",
        "    !pip install -U -q PyDrive -qq\n",
        "    !apt install openjdk-8-jdk-headless -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "oozTtW3om3Ab"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import plotly\n",
        "\n",
        "import pyspark\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql import SparkSession, DataFrame, Row\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType, FloatType, LongType\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.ml.linalg import SparseVector, DenseVector, VectorUDT\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "import gc\n",
        "\n",
        "if not LOCAL:\n",
        "    from google.colab import drive\n",
        "\n",
        "from typing import Tuple\n",
        "from functools import reduce\n",
        "import pickle\n",
        "import torch\n",
        "from petastorm import make_batch_reader\n",
        "from petastorm.pytorch import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not LOCAL:\n",
        "    drive.mount(GDRIVE_DIR, force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XG5sA53iP9z0"
      },
      "outputs": [],
      "source": [
        "#@title Set up variables\n",
        "if not LOCAL:\n",
        "    JAVA_HOME = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "    GDRIVE_DIR = \"/content/drive\"\n",
        "    GDRIVE_HOME_DIR = GDRIVE_DIR + \"/MyDrive\"\n",
        "    GDRIVE_DATA_DIR = GDRIVE_HOME_DIR + \"/Big Data/datasets\"\n",
        "    DATASET_FILE = os.path.join(GDRIVE_DATA_DIR, \"pyspark_friendly_spotify_playlist_dataset\")\n",
        "    AUDIO_FEATURES_FILE = os.path.join(GDRIVE_DATA_DIR, \"pyspark_track_features\")\n",
        "    LITTLE_SLICE_FILE = os.path.join(GDRIVE_DATA_DIR, \"little_slice\")\n",
        "    SMALL_SLICE_FLIE = os.path.join(GDRIVE_DATA_DIR, \"small_slice\")\n",
        "    LITTLE_SLICE_AUDIO_FEATURES = os.path.join(GDRIVE_DATA_DIR, \"little_slice_audio_features\")\n",
        "    MICRO_SLICE_AUDIO_FEATURES = os.path.join(GDRIVE_DATA_DIR, \"micro_slice_audio_features\")\n",
        "    SPLITTED_SLICE_AUDIO_FEATURES = os.path.join(GDRIVE_DATA_DIR, \"splitted_pyspark_track_features\")\n",
        "    SAVED_DFS_PATH = os.path.join(GDRIVE_DATA_DIR, \"saved_dfs\")\n",
        "    SAVED_MODELS = os.path.join(GDRIVE_DATA_DIR, \"saved_models\")\n",
        "else:\n",
        "    GDRIVE_DATA_DIR = os.path.abspath(\"./data\")\n",
        "    SAVED_DFS_PATH = os.path.join(GDRIVE_DATA_DIR, \"saved_dfs\")\n",
        "    SAVED_MODELS = os.path.join(GDRIVE_DATA_DIR, \"saved_models\")\n",
        "    JAVA_HOME = \"/opt/homebrew/opt/openjdk\"\n",
        "RANDOM_SEED = 42 # for reproducibility\n",
        "os.environ[\"JAVA_HOME\"] = JAVA_HOME\n",
        "os.environ[\"PYSPARK_PYTHON\"]=\"python\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "4m7VztzdZgm6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/16 03:19:30 WARN Utils: Your hostname, MacBook-Air-di-Domiziano.local resolves to a loopback address: 127.0.0.1; using 192.168.1.175 instead (on interface en0)\n",
            "23/06/16 03:19:30 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "23/06/16 03:19:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
          ]
        }
      ],
      "source": [
        "#@title Create the session\n",
        "config = SparkConf().\\\n",
        "                set('spark.ui.port', \"4050\").\\\n",
        "                set('spark.executor.memory', '12G').\\\n",
        "                set('spark.driver.memory', '12G').\\\n",
        "                set('spark.driver.maxResultSize', '100G').\\\n",
        "                set(\"spark.executor.extraJavaOptions\", \"-XX:+UseG1GC\").\\\n",
        "                setAppName(\"PySparkTutorial\").\\\n",
        "                setMaster(\"local[*]\")\n",
        "\n",
        "# Create the context\n",
        "sc = pyspark.SparkContext(conf=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VJeY9PpvaHUJ"
      },
      "source": [
        "# Data acquisition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "icd2lj-RRvhU"
      },
      "outputs": [],
      "source": [
        "playlist_schema_mapped = StructType([\n",
        "    StructField(\"name\", StringType(), True),\n",
        "    StructField(\"collaborative\", StringType(), True),\n",
        "    StructField(\"pid\", IntegerType(), True),\n",
        "    StructField(\"modified_at\", IntegerType(), True),\n",
        "    StructField(\"num_tracks\", IntegerType(), True),\n",
        "    StructField(\"num_albums\", IntegerType(), True),\n",
        "    StructField(\"num_followers\", IntegerType(), True),\n",
        "    StructField(\"tracks\", VectorUDT(), True),\n",
        "    StructField(\"num_edits\", IntegerType(), True),\n",
        "    StructField(\"duration_ms\", IntegerType(), True),\n",
        "    StructField(\"num_artists\", IntegerType(), True),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JAu9mQsxTxHj"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fGgc9DHjT09S"
      },
      "outputs": [],
      "source": [
        "NUM_PLAYLISTS = 100_000\n",
        "SONGS_EMBEDDINGS_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_songs_embeddings-train-{NUM_PLAYLISTS}.json\")\n",
        "SONGS_INFO_DF_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_songs_info_df-{NUM_PLAYLISTS}.json\")\n",
        "SONGS_VECTOR_LENGTH_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_songs_vector_length-{NUM_PLAYLISTS}.txt\")\n",
        "\n",
        "ARTIST_VECTOR_LENGTH_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_artist_vector_length-{NUM_PLAYLISTS}.txt\")\n",
        "ARTISTS_EMBEDDINGS_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_artists_embeddings-train-{NUM_PLAYLISTS}.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The DF used for train (80% of the original) (playlist are different)\n",
        "TRAIN_DF_PATH = os.path.join(SAVED_DFS_PATH, f\"train_df-{NUM_PLAYLISTS}.json\")\n",
        "# The DF used for testing (20% of the original) (playlist are different)\n",
        "TEST_DF_PATH = os.path.join(SAVED_DFS_PATH, f\"test_df-{NUM_PLAYLISTS}.json\")\n",
        "\n",
        "# The DF used for train in the NN model (can be filtered or not)\n",
        "NN_TRAIN_DF_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_train_df-{NUM_PLAYLISTS}.json\")\n",
        "# The DF used for testing in the NN model (can be filtered or not)\n",
        "NN_TEST_DF_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_test_df-{NUM_PLAYLISTS}.json\")\n",
        "# The partition in train test of the NN test set. (Same playlists, different songs)\n",
        "NN_TEST_DF_TRAIN_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_test_df-train-{NUM_PLAYLISTS}.json\")\n",
        "NN_TEST_DF_TEST_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_test_df-test-{NUM_PLAYLISTS}.json\")\n",
        "\n",
        "NN_EVAL_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_eval_df-{NUM_PLAYLISTS}.json\")\n",
        "NN_EVAL_TRAIN_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_eval_df-train-{NUM_PLAYLISTS}.json\")\n",
        "NN_EVAL_TEST_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_eval_df-test-{NUM_PLAYLISTS}.json\")\n",
        "# New one:\n",
        "ARTISTS_EMBEDDINGS_TRAIN = os.path.join(SAVED_DFS_PATH, f\"nn_artists_embeddings-train-{NUM_PLAYLISTS}.json\")\n",
        "ARTISTS_EMBEDDINGS_TEST_TRAIN = os.path.join(SAVED_DFS_PATH, f\"nn_artists_embeddings-test-train-{NUM_PLAYLISTS}.json\")\n",
        "ARTISTS_EMBEDDINGS_TEST_TEST = os.path.join(SAVED_DFS_PATH, f\"nn_artists_embeddings-test-test{NUM_PLAYLISTS}.json\")\n",
        "\n",
        "ARTISTS_EMBEDDINGS_EVAL = os.path.join(SAVED_DFS_PATH, f\"nn_artists_embeddings-eval-{NUM_PLAYLISTS}.json\")\n",
        "ARTISTS_EMBEDDINGS_EVAL_TRAIN = os.path.join(SAVED_DFS_PATH, f\"nn_artists_embeddings-eval-train-{NUM_PLAYLISTS}.json\")\n",
        "ARTISTS_EMBEDDINGS_EVAL_TEST = os.path.join(SAVED_DFS_PATH, f\"nn_artists_embeddings-eval-test{NUM_PLAYLISTS}.json\")\n",
        "\n",
        "# The length of the artist vector length (Artist vectors are only used in the NN model)\n",
        "ARTIST_VECTOR_LENGTH_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_artist_vector_length-{NUM_PLAYLISTS}.txt\")\n",
        "\n",
        "SONGS_VECTOR_LENGTH_PATH = os.path.join(SAVED_DFS_PATH, f\"songs_vector_length-{NUM_PLAYLISTS}.txt\")\n",
        "# This may be filtered or not\n",
        "FILTERED_SONGS_VECTOR_LENGTH_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_songs_vector_length-{NUM_PLAYLISTS}.txt\")\n",
        "\n",
        "SONGS_EMBEDDINGS_TRAIN = os.path.join(SAVED_DFS_PATH, f\"songs_embeddings-train-{NUM_PLAYLISTS}.json\")\n",
        "SONGS_EMBEDDINGS_TEST = os.path.join(SAVED_DFS_PATH, f\"songs_embeddings-test-{NUM_PLAYLISTS}.json\")\n",
        "\n",
        "NN_SONGS_EMBEDDINGS_TRAIN = os.path.join(SAVED_DFS_PATH, f\"nn_songs_embeddings-train-{NUM_PLAYLISTS}.json\")\n",
        "NN_SONGS_EMBEDDINGS_TEST_TRAIN = os.path.join(SAVED_DFS_PATH, f\"nn_songs_embeddings-test-train-{NUM_PLAYLISTS}.json\")\n",
        "NN_SONGS_EMBEDDINGS_TEST_TEST = os.path.join(SAVED_DFS_PATH, f\"nn_songs_embeddings-test-test-{NUM_PLAYLISTS}.json\")\n",
        "\n",
        "NN_SONGS_EMBEDDINGS_EVAL = os.path.join(SAVED_DFS_PATH, f\"nn_songs_embeddings-eval-{NUM_PLAYLISTS}.json\") #TODO: The logic to produce this still has to be coded.\n",
        "NN_SONGS_EMBEDDINGS_EVAL_TRAIN = os.path.join(SAVED_DFS_PATH, f\"nn_songs_embeddings-eval-train-{NUM_PLAYLISTS}.json\")\n",
        "NN_SONGS_EMBEDDINGS_EVAL_TEST = os.path.join(SAVED_DFS_PATH, f\"nn_songs_embeddings-eval-test-{NUM_PLAYLISTS}.json\")\n",
        "\n",
        "SONGS_INFO_DF = os.path.join(SAVED_DFS_PATH, f\"songs_info_df-{NUM_PLAYLISTS}.json\")\n",
        "FILTERED_SONGS_INFO_DF = os.path.join(SAVED_DFS_PATH, f\"nn_songs_info_df-{NUM_PLAYLISTS}.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lo8gbiN1U1XJ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "songs_embeddings = spark.read.schema(playlist_schema_mapped).json(SONGS_EMBEDDINGS_PATH)\n",
        "artists_embeddings = spark.read.schema(playlist_schema_mapped).json(ARTISTS_EMBEDDINGS_PATH)\n",
        "song_mapping = spark.read.json(SONGS_INFO_DF_PATH)\n",
        "\n",
        "songs_embeddings_eval_train = spark.read.schema(playlist_schema_mapped).json(NN_SONGS_EMBEDDINGS_EVAL_TRAIN)\n",
        "songs_embeddings_eval_test = spark.read.schema(playlist_schema_mapped).json(NN_SONGS_EMBEDDINGS_EVAL_TEST)\n",
        "\n",
        "artists_embeddings_eval_train = spark.read.schema(playlist_schema_mapped).json(ARTISTS_EMBEDDINGS_EVAL_TRAIN)\n",
        "artists_embeddings_eval_test = spark.read.schema(playlist_schema_mapped).json(ARTISTS_EMBEDDINGS_EVAL_TEST)\n",
        "\n",
        "with open(ARTIST_VECTOR_LENGTH_PATH, \"r\") as f:\n",
        "  content = f.read()\n",
        "  ARTIST_VECTOR_LENGTH = int(content) + 1\n",
        "with open(SONGS_VECTOR_LENGTH_PATH, \"r\") as f:\n",
        "  content = f.read()\n",
        "  SONGS_VECTOR_LENGTH = int(content) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BY_szFyLTps4",
        "outputId": "764c5d24-4a9f-44d6-e349-6a2bca3bb948"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------+-------------+-----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "|               name|collaborative|  pid|modified_at|num_tracks|num_albums|num_followers|              tracks|num_edits|duration_ms|num_artists|\n",
            "+-------------------+-------------+-----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "|              Alone|        false|20080| 1496880000|        50|        48|            1|(681806,[4875,543...|       19|   11128916|         42|\n",
            "|       Country Hits|        false|14258| 1504828800|       130|        77|            1|(681806,[4,1667,1...|       61|   28245005|         44|\n",
            "|              Peter|        false|14812| 1446595200|        65|        56|            1|(681806,[214,541,...|       15|   14212644|         47|\n",
            "|          Rock.....|        false| 1938| 1500163200|        57|        39|            1|(681806,[2909,350...|        5|   16766883|         19|\n",
            "|               punk|        false| 1180| 1504483200|        67|        45|            1|(681806,[62,3299,...|       21|   15393647|         26|\n",
            "|#CODGhosts Playlist|        false|14362| 1382918400|        50|        50|            1|(681806,[1566,301...|        2|   13601217|         50|\n",
            "|             #Dance|        false|14103| 1463961600|        33|        28|            1|(681806,[390,7337...|       12|    6901015|         24|\n",
            "|      #boostyourrun|        false|14325| 1425686400|        21|        21|            1|(681806,[498,1342...|        2|    5002212|         20|\n",
            "|      #boostyourrun|        false|20976| 1399075200|        21|        21|            1|(681806,[4482,918...|        2|    5400100|         19|\n",
            "|      #boostyourrun|        false|78200| 1402704000|        22|        22|            1|(681806,[108940,1...|        2|    5825915|         21|\n",
            "|           #college|        false|78334| 1490400000|        21|        19|            2|(681806,[23984,82...|        4|    5068086|         18|\n",
            "|               #tbt|        false| 1168| 1436832000|        29|        22|            1|(681806,[3586,463...|        2|    6829177|         15|\n",
            "|             $andy$|        false|78110| 1457395200|       117|        63|            1|(681806,[1679,326...|       14|   28982414|         40|\n",
            "|                '17|        false|20507| 1505433600|        38|        31|            2|(681806,[1123,489...|       31|    8051141|         30|\n",
            "|                '17|        false|78571| 1509235200|        34|        29|            1|(681806,[83360,87...|       16|    7500239|         26|\n",
            "|            'Merica|        false|78912| 1499126400|       241|       237|            1|(681806,[14,609,7...|        6|   57441819|        217|\n",
            "|           'merica |        false|78916| 1499990400|        67|        45|            1|(681806,[1667,206...|       21|   14868475|         35|\n",
            "|   **That New New**|        false|14379| 1432771200|        63|        52|            1|(681806,[271,2072...|       21|   14353567|         47|\n",
            "|           *HANNAH*|        false|20194| 1506211200|        84|        22|            1|(681806,[27516,58...|        5|   11964693|          6|\n",
            "|             *sigh*|        false|14217| 1509321600|       154|       101|            4|(681806,[115,633,...|       25|   38055908|         64|\n",
            "+-------------------+-------------+-----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-------------------+-------------+-----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "|               name|collaborative|  pid|modified_at|num_tracks|num_albums|num_followers|              tracks|num_edits|duration_ms|num_artists|\n",
            "+-------------------+-------------+-----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "|              Alone|        false|20080| 1496880000|        50|        48|            1|(110064,[393,589,...|       19|   11128916|         42|\n",
            "|       Country Hits|        false|14258| 1504828800|       130|        77|            1|(110064,[2,850,10...|       61|   28245005|         44|\n",
            "|              Peter|        false|14812| 1446595200|        65|        56|            1|(110064,[4,194,19...|       15|   14212644|         47|\n",
            "|          Rock.....|        false| 1938| 1500163200|        57|        39|            1|(110064,[1263,137...|        5|   16766883|         19|\n",
            "|               punk|        false| 1180| 1504483200|        67|        45|            1|(110064,[199,313,...|       21|   15393647|         26|\n",
            "|#CODGhosts Playlist|        false|14362| 1382918400|        50|        50|            1|(110064,[1071,140...|        2|   13601217|         50|\n",
            "|             #Dance|        false|14103| 1463961600|        33|        28|            1|(110064,[106,108,...|       12|    6901015|         24|\n",
            "|      #boostyourrun|        false|14325| 1425686400|        21|        21|            1|(110064,[10644,13...|        2|    5002212|         20|\n",
            "|      #boostyourrun|        false|20976| 1399075200|        21|        21|            1|(110064,[1041,197...|        2|    5400100|         19|\n",
            "|      #boostyourrun|        false|78200| 1402704000|        22|        22|            1|(110064,[8081,147...|        2|    5825915|         21|\n",
            "|           #college|        false|78334| 1490400000|        21|        19|            2|(110064,[193,1470...|        4|    5068086|         18|\n",
            "|               #tbt|        false| 1168| 1436832000|        29|        22|            1|(110064,[1968,213...|        2|    6829177|         15|\n",
            "|             $andy$|        false|78110| 1457395200|       117|        63|            1|(110064,[101,971,...|       14|   28982414|         40|\n",
            "|                '17|        false|20507| 1505433600|        38|        31|            2|(110064,[485,858,...|       31|    8051141|         30|\n",
            "|                '17|        false|78571| 1509235200|        34|        29|            1|(110064,[102,2234...|       16|    7500239|         26|\n",
            "|            'Merica|        false|78912| 1499126400|       241|       237|            1|(110064,[11,194,4...|        6|   57441819|        217|\n",
            "|           'merica |        false|78916| 1499990400|        67|        45|            1|(110064,[46,850,8...|       21|   14868475|         35|\n",
            "|   **That New New**|        false|14379| 1432771200|        63|        52|            1|(110064,[15,101,1...|       21|   14353567|         47|\n",
            "|           *HANNAH*|        false|20194| 1506211200|        84|        22|            1|(110064,[8852,105...|        5|   11964693|          6|\n",
            "|             *sigh*|        false|14217| 1509321600|       154|       101|            4|(110064,[794,1071...|       25|   38055908|         64|\n",
            "+-------------------+-------------+-----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(None, None, 110064, 681806)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "songs_embeddings.show(), artists_embeddings.show(), ARTIST_VECTOR_LENGTH, SONGS_VECTOR_LENGTH"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lPOD60GQQGse"
      },
      "source": [
        "# Convert PySpark DataFrame into PyTorch DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QCKbUCcaEpQS"
      },
      "outputs": [],
      "source": [
        "def convert_sparse_to_indices(df: DataFrame, column_name: str) -> DataFrame:\n",
        "  \"\"\"\n",
        "  Given a dataframe fo columns \"pos\":int and \"tracks\":SparseVector, it returns a new dataframe where\n",
        "  the SparseVector are replaced with a list of the indices where the values are.\n",
        "  (The value information is lost, but we don't care since they are binary values so they will be all ones)\n",
        "  \"\"\"\n",
        "\n",
        "  @F.udf(returnType=ArrayType(IntegerType()))\n",
        "  def transform_array(item: SparseVector):\n",
        "    \"\"\"\n",
        "    Given a SparseVector (binary) it returns the tuple that represent it, of the type (size, indices)\n",
        "    \"\"\"\n",
        "    indices_list = item.indices.tolist()\n",
        "    padding_width = max_songs - len(indices_list)\n",
        "    return indices_list + [-1] * padding_width\n",
        "  \n",
        "  max_songs = songs_embeddings.select(F.max(\"num_tracks\")).first()[0]\n",
        "  print(f\"Max number of songs: {max_songs}\")\n",
        "  df = df.withColumn(f\"{column_name}_indices\", transform_array(F.col(column_name))).drop(column_name)\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "eIIqDVeN7cU0"
      },
      "outputs": [],
      "source": [
        "def padded_tensors_to_sparse_matrix(padded_tensor: torch.Tensor, shape: tuple) -> torch.Tensor:\n",
        "  batch_size, max_songs = padded_tensor.size(0), padded_tensor.size(1)\n",
        "  rows = []\n",
        "  for row_idx in range(batch_size):\n",
        "    row = padded_tensor[row_idx]\n",
        "    indices = row[row != -1]\n",
        "    sparse_tensor = torch.sparse_coo_tensor(indices.unsqueeze(0), torch.ones(indices.shape), shape)\n",
        "    rows.append(sparse_tensor)\n",
        "  return torch.stack(rows)\n",
        "\n",
        "def padded_tensors_to_dense_matrix(padded_tensor: torch.Tensor, shape: tuple) -> torch.Tensor:\n",
        "  batch_size, max_songs = padded_tensor.size(0), padded_tensor.size(1)\n",
        "  rows = []\n",
        "  for row_idx in range(batch_size):\n",
        "    row = padded_tensor[row_idx]\n",
        "    indices = row[row != -1]\n",
        "    sparse_tensor = torch.sparse_coo_tensor(indices.unsqueeze(0) + 1, torch.ones(indices.shape), shape)\n",
        "    dense = sparse_tensor.to_dense()\n",
        "    rows.append(dense)\n",
        "  unpadded = torch.stack(rows)\n",
        "  return unpadded"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UNak5bEo4cmV"
      },
      "source": [
        "In the paper they have two matrices,l et $n$ be the number of unique songs, $m$ the number of playlists and $k$ the number of unique artists:\n",
        "\n",
        "- $P \\in \\mathbb{R}^{m \\times n}$ where $p_i = 1$ if song $i$ is in the playlist, $p_i=0$ otherwise\n",
        "- $A \\in \\mathbb{R}^{m \\times k}$ where $a_i=1$ if the artist is present in the playlist, $a_i = 0$ otherwise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_pKgJx26s73",
        "outputId": "fe16bfd0-5d64-4cf5-d160-1e7dbea99d2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max number of songs: 250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Converting floating-point columns to float32\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max number of songs: 250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/16 03:19:43 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
            "The median size 3980660 B (< 50 MB) of the parquet files is too small. Total size: 32581874 B. Increase the median file size by calling df.repartition(n) or df.coalesce(n), which might help improve the performance. Parquet files: file:///Users/dov/Desktop/big-data-project/data/cache/20230616031935-appid-local-1686878371467-f57075b6-231c-432d-b7af-f2a27adbecca/part-00001-b0cd3af4-fda4-4915-9766-9dfe4bba7038-c000.parquet, ...\n",
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98465 98465 98465\n"
          ]
        }
      ],
      "source": [
        "from petastorm.spark import SparkDatasetConverter, make_spark_converter\n",
        "\n",
        "CACHE = os.path.join(GDRIVE_DATA_DIR, \"cache\")\n",
        "spark.conf.set(SparkDatasetConverter.PARENT_CACHE_DIR_URL_CONF, f'file://{CACHE}')\n",
        "\n",
        "pytorch_songs_df = convert_sparse_to_indices(songs_embeddings.select(\"tracks\", \"pid\"), column_name=\"tracks\")\n",
        "# songs_converter = make_spark_converter(pytorch_songs_df)\n",
        "pytorch_artists_df = convert_sparse_to_indices(artists_embeddings.withColumnRenamed(\"tracks\", \"artists\").select(\"pid\", \"artists\"), column_name=\"artists\")\n",
        "# artist_converter = make_spark_converter(pytorch_artists_df)\n",
        "songs_artists_df = pytorch_songs_df.join(pytorch_artists_df, on=\"pid\")\n",
        "pytorch_merged_dataloader = make_spark_converter(songs_artists_df)\n",
        "\n",
        "\n",
        "print(pytorch_songs_df.count(), pytorch_artists_df.count(), songs_artists_df.count()) #Everything good here, this is nice!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# songs_embeddings.show(), artists_embeddings.show()\n",
        "# artists_embeddings = artists_embeddings.withColumnRenamed(\"tracks\", \"artists\").select(\"pid\", \"artists\")\n",
        "# df = songs_embeddings.join(artists_embeddings, on=\"pid\").show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating the dataloader for the evaluation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pytorch_songs_eval_train_df = convert_sparse_to_indices(songs_embeddings_eval_train.select(\"tracks\", \"pid\"), column_name=\"tracks\")\n",
        "# pytorch_artists_eval_train_df = convert_sparse_to_indices(artists_embeddings_eval_train.withColumnRenamed(\"tracks\", \"artists\").select(\"pid\", \"artists\"), column_name=\"artists\")\n",
        "# songs_artists_eval_train_df = pytorch_songs_eval_train_df.join(pytorch_artists_eval_train_df, on=\"pid\")\n",
        "\n",
        "# pytorch_songs_eval_train_df.orderBy(\"pid\").show(), pytorch_artists_eval_train_df.orderBy(\"pid\").show() #TODO: pid do not match, go to data preparation to fix this\n",
        "\n",
        "\n",
        "# # songs_artists_eval_train_df.withColumnRenamed(\"artists_indices\", \"artists_train_indices\").show()\n",
        "\n",
        "# # songs_artist_eval_train_converter = make_spark_converter(songs_artists_eval_train_df)\n",
        "\n",
        "# # pytorch_songs_eval_test_df = convert_sparse_to_indices(songs_embeddings_eval_test.select(\"tracks\", \"pid\"), column_name=\"tracks\")\n",
        "# # pytorch_artists_eval_test_df = convert_sparse_to_indices(artists_embeddings_eval_test.withColumnRenamed(\"tracks\", \"artists\").select(\"pid\", \"artists\"), column_name=\"artists\")\n",
        "# # songs_artists_eval_test_df = pytorch_songs_eval_test_df.join(pytorch_artists_eval_test_df, on=\"pid\")\n",
        "\n",
        "# # songs_artist_eval_test_converter = make_spark_converter(songs_artists_eval_test_df)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "m0Av0W0P66lC"
      },
      "source": [
        "# PyTorch Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6-YbESXD66Oh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "class DAE_tied(nn.Module):\n",
        "    def __init__(self, conf):\n",
        "        super(DAE_tied, self).__init__()\n",
        "        self.save_dir = conf[\"save\"]\n",
        "        # self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.device = torch.device(\"mps\")\n",
        "        self.initval_dir = conf[\"initval\"]\n",
        "\n",
        "        self.n_batch = conf[\"batch\"]\n",
        "        self.n_input = conf[\"n_input\"]\n",
        "        self.n_hidden = conf[\"hidden\"]\n",
        "        self.reg_lambda = conf[\"reg_lambda\"]\n",
        "\n",
        "        self.keep_prob = torch.tensor(conf[\"keep_prob\"], dtype=torch.float32)\n",
        "        self.input_keep_prob = torch.tensor(conf[\"input_keep_prob\"], dtype=torch.float32)\n",
        "\n",
        "        self.weights = {}\n",
        "        self.biases = {}\n",
        "        self.d_params = []\n",
        "\n",
        "        self.z = None\n",
        "\n",
        "    def init_weight(self):\n",
        "        if self.initval_dir == 'NULL':\n",
        "            self.weights['encoder_h'] = nn.Parameter(torch.FloatTensor(self.n_input, self.n_hidden).to(self.device))\n",
        "            nn.init.xavier_uniform_(self.weights['encoder_h'])\n",
        "            self.biases['encoder_b'] = nn.Parameter(torch.FloatTensor(self.n_hidden).to(self.device))\n",
        "            nn.init.zeros_(self.biases['encoder_b'])\n",
        "            self.biases['decoder_b'] = nn.Parameter(torch.FloatTensor(self.n_input).to(self.device))\n",
        "            nn.init.zeros_(self.biases['decoder_b'])\n",
        "        else:\n",
        "            with open(self.initval_dir, 'rb') as f:\n",
        "                emb = pickle.load(f)\n",
        "            self.weights['encoder_h'] = nn.Parameter(torch.FloatTensor(emb[0]).to(self.device))\n",
        "            self.weights['decoder_h'] = nn.Parameter(torch.FloatTensor(emb[1]).to(self.device))\n",
        "            self.biases['encoder_b'] = nn.Parameter(torch.FloatTensor(emb[2]).to(self.device))\n",
        "            self.biases['decoder_b'] = nn.Parameter(torch.FloatTensor(emb[3]).to(self.device))\n",
        "        self.d_params = [self.weights['encoder_h'], self.weights['encoder_h'], self.biases['encoder_b'], self.biases['decoder_b']]\n",
        "\n",
        "\n",
        "    # Building the encoder\n",
        "    def encoder(self, x):\n",
        "        # Encoder Hidden layer with sigmoid activation #1\n",
        "        layer = torch.add(torch.matmul(x, self.weights['encoder_h']), self.biases['encoder_b'])\n",
        "        layer = torch.sigmoid(layer)\n",
        "        layer = torch.nn.functional.dropout(layer, p=1 - self.keep_prob)\n",
        "\n",
        "        return layer\n",
        "\n",
        "    # Building the decoder\n",
        "    def decoder(self, x):\n",
        "        # Decoder Hidden layer with sigmoid activation #1\n",
        "        layer = torch.sigmoid(torch.add(torch.matmul(x, self.weights['encoder_h'].t()), self.biases['decoder_b']))\n",
        "        return layer\n",
        "\n",
        "    def l2_loss(self):\n",
        "      encoder_h_l2 = (torch.sum(self.weights['encoder_h']) ** 2)/2\n",
        "      decoder_b_l2 = (torch.sum(self.biases['decoder_b']) ** 2)/2\n",
        "      encoder_b_l2 = (torch.sum(self.biases['encoder_b']) ** 2)/2\n",
        "\n",
        "      l2 = encoder_h_l2 + decoder_b_l2 + encoder_b_l2\n",
        "      return l2\n",
        "\n",
        "    def forward(self, x, y):\n",
        "\n",
        "        # TODO: Take sparse matrix representation instead of dense\n",
        "        # self.x = x_positxions\n",
        "        # self.x_ones = x_ones\n",
        "        # self.y_positions = y_positions\n",
        "        # self.y_ones = y_ones\n",
        "\n",
        "        self.x = x.t()\n",
        "        self.y = y.t()\n",
        "\n",
        "        # x_sparse = torch.sparse.FloatTensor(self.x_positions.t(), self.x_ones, torch.Size([self.n_batch, self.n_input]))\n",
        "        # self.x = x_sparse.to_dense()\n",
        "        # y_sparse = torch.sparse.FloatTensor(self.y_positions.t(), self.y_ones, torch.Size([self.n_batch, self.n_input]))\n",
        "        # self.y = y_sparse.to_dense()\n",
        "\n",
        "        x_dropout = torch.nn.functional.dropout(self.x, p= 1 - self.input_keep_prob)\n",
        "        reduce_sum = torch.sum(x_dropout, dim=1, keepdim=True)\n",
        "        self.x_dropout = torch.div(x_dropout, reduce_sum + 1e-10)\n",
        "\n",
        "        encoder_op = self.encoder(self.x_dropout)\n",
        "\n",
        "        self.z = encoder_op\n",
        "        self.y_pred = self.decoder(encoder_op)\n",
        "\n",
        "        l2 = self.l2_loss()\n",
        "\n",
        "        L = -torch.sum(self.y * torch.log(self.y_pred + 1e-10) +\n",
        "                       0.55 * (1 - self.y) * torch.log(1 - self.y_pred + 1e-10), dim=1)\n",
        "        self.cost = torch.mean(L) + self.reg_lambda * l2\n",
        "\n",
        "    def save_model(self):\n",
        "        params = [param.detach().numpy() for param in self.d_params]\n",
        "        with open(self.save_dir, 'wb') as f:\n",
        "            pickle.dump(params, f)\n",
        "\n",
        "            \n",
        "class DAE(DAE_tied):\n",
        "    def __init__(self, conf):\n",
        "        super(DAE, self).__init__(conf)\n",
        "\n",
        "    def init_weight(self):\n",
        "        if self.initval_dir == 'NULL':\n",
        "            self.weights['encoder_h'] = nn.Parameter(torch.FloatTensor(self.n_input, self.n_hidden).to(self.device))\n",
        "            nn.init.xavier_uniform_(self.weights['encoder_h'])\n",
        "            self.weights['decoder_h'] = nn.Parameter(torch.FloatTensor(self.n_input, self.n_hidden).to(self.device))\n",
        "            nn.init.xavier_uniform_(self.weights['decoder_h'])\n",
        "            self.biases['encoder_b'] = nn.Parameter(torch.FloatTensor(self.n_hidden).to(self.device))\n",
        "            nn.init.zeros_(self.biases['encoder_b'])\n",
        "            self.biases['decoder_b'] = nn.Parameter(torch.FloatTensor(self.n_input).to(self.device))\n",
        "            nn.init.zeros_(self.biases['decoder_b'])\n",
        "        else:\n",
        "            with open(self.initval_dir, 'rb') as f:\n",
        "                emb = pickle.load(f)\n",
        "            self.weights['encoder_h'] = nn.Parameter(torch.FloatTensor(emb[0]).to(self.device))\n",
        "            self.weights['decoder_h'] = nn.Parameter(torch.FloatTensor(emb[1]).to(self.device))\n",
        "            self.biases['encoder_b'] = nn.Parameter(torch.FloatTensor(emb[2]).to(self.device))\n",
        "            self.biases['decoder_b'] = nn.Parameter(torch.FloatTensor(emb[3]).to(self.device))\n",
        "\n",
        "        self.d_params = [self.weights['encoder_h'], self.weights['decoder_h'],\n",
        "                         self.biases['encoder_b'], self.biases['decoder_b']]\n",
        "\n",
        "    def decoder(self, x):\n",
        "        # Decoder Hidden layer with sigmoid activation #1\n",
        "        layer = torch.sigmoid(torch.add(torch.matmul(x, self.weights['decoder_h'].t()), self.biases['decoder_b']))\n",
        "        return layer\n",
        "\n",
        "    def l2_loss(self):\n",
        "      encoder_h_l2 = (torch.sum(self.weights['encoder_h']) ** 2)/2\n",
        "      decoder_b_l2 = (torch.sum(self.biases['decoder_b']) ** 2)/2\n",
        "      encoder_b_l2 = (torch.sum(self.biases['encoder_b']) ** 2)/2\n",
        "      decoder_h_l2 = (torch.sum(self.weights['decoder_h']) ** 2)/2\n",
        "\n",
        "      l2 = encoder_h_l2 + decoder_b_l2 + encoder_b_l2 + decoder_h_l2\n",
        "      return l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "aykoeJfhOUBV"
      },
      "outputs": [],
      "source": [
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = torch.device(\"mps\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVGpMdqs7dQQ",
        "outputId": "2001aebc-9e53-4b86-fb7d-2a2ba9463fed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DAE_tied()"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "BEST_PARAMS_PATH = os.path.join(SAVED_MODELS, \"best_params.pickle\")\n",
        "BEST_PARAMS_PATH_2 = os.path.join(SAVED_MODELS, \"best_params_reg.pickle\")\n",
        "\n",
        "#Hyperparameters used in the paper\n",
        "conf = {\n",
        "    'batch': 32,\n",
        "    'n_input': SONGS_VECTOR_LENGTH + ARTIST_VECTOR_LENGTH - 2, #-2 to compense the first row of zeros since the pos in the df start at 1\n",
        "    'hidden': 200,\n",
        "    'lr': 0.0001,\n",
        "    'reg_lambda': 0.0,\n",
        "    'initval': \"NULL\",\n",
        "    \"keep_prob\": 0.8, \n",
        "    \"input_keep_prob\": 0.8, # This isn't used for now because of the .uniform()\n",
        "    'save': os.path.join(SAVED_MODELS, \"dae_model.pickle\")\n",
        "}\n",
        "pretrain_model = DAE_tied(conf)\n",
        "pretrain_model.init_weight()\n",
        "pretrain_model.train()\n",
        "# optimizer = optim.SGD(dae_model.d_params, lr=conf['lr'], momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mNPmA2YijSO1"
      },
      "outputs": [],
      "source": [
        "pretrain_optimizer = optim.Adam(pretrain_model.d_params, lr=conf['lr'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jAqv6QBEiK9",
        "outputId": "c0716d37-5a7f-4966-c860-65e8041a4f74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='mps', index=0)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pretrain_model.weights['encoder_h'].device"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the validation function that is invoked during the training in order to save the model parameters that optimize the performance evaluation on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List\n",
        "def k_prec(eval_preds: torch.Tensor, ground_truth: torch.Tensor, k: torch.Tensor) -> List[float]:\n",
        "    batch_size = 32\n",
        "    counts = []\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        top_k_preds_idx = eval_preds[i].topk(k[i], dim=0).indices.flatten()\n",
        "        ground_truth_idx = torch.nonzero(ground_truth[i] == 1).squeeze().flatten()\n",
        "\n",
        "        common_elements = np.intersect1d(top_k_preds_idx.cpu().detach().numpy(), ground_truth_idx.cpu().detach().numpy())\n",
        "        num_common_elements = len(common_elements)\n",
        "        counts.append(num_common_elements)\n",
        "\n",
        "    return counts\n",
        "\n",
        "def ndcg(eval_preds: torch.Tensor, ground_truth: torch.Tensor) -> float:\n",
        "    return 0\n",
        "\n",
        "def evaluate(eval_preds: torch.Tensor, ground_truth: torch.Tensor, k: torch.Tensor) -> List[float]:\n",
        "    return k_prec(eval_preds, ground_truth, k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def validate(y_preds: torch.Tensor) -> Tuple[float, float]:\n",
        "#     \"\"\"\n",
        "#     Given the model predictions, performs an evaluation on the validation set.\n",
        "#     \"\"\"\n",
        "#     ARTIST_SHAPE = (ARTIST_VECTOR_LENGTH, )\n",
        "#     SONG_SHAPE = (SONGS_VECTOR_LENGTH, )\n",
        "#     precs = []\n",
        "#     tot_k = 0\n",
        "#     with songs_eval_train_converter.make_torch_dataloader(batch_size=conf[\"batch\"], num_epochs = 1) as songs_eval_train_dataloader:\n",
        "#         with artists_eval_train_converter.make_torch_dataloader(batch_size=conf[\"batch\"], num_epochs = 1) as artist_eval_train_dataloader:\n",
        "#             with songs_eval_test_converter.make_torch_dataloader(batch_size=conf[\"batch\"], num_epochs = 1) as songs_eval_test_dataloader:\n",
        "#                 with artists_eval_test_converter.make_torch_dataloader(batch_size=conf[\"batch\"], num_epochs = 1) as artist_eval_test_dataloader:\n",
        "#                     zipped_train_dataloaders = zip(songs_eval_train_dataloader, artist_eval_train_dataloader)\n",
        "#                     zipped_test_dataloaders = zip(songs_eval_test_dataloader, artist_eval_test_dataloader)\n",
        "\n",
        "#                     zipped_eval_dataloaders = zip(zipped_train_dataloaders, zipped_test_dataloaders)\n",
        "#                     pretrain_model.eval()\n",
        "#                     for batch_idx, ((song_eval_train, artist_eval_train), (song_eval_test, artist_eval_test)) in enumerate(zipped_eval_dataloaders):\n",
        "#                         with torch.no_grad():\n",
        "#                             if batch_idx == 1:\n",
        "#                                 break #TODO: faster but less generalized\n",
        "#                             padded_eval_song_tensor = song_eval_train[\"embedding_indices\"]\n",
        "#                             padded_eval_artist_tensor = artist_eval_train[\"embedding_indices\"]\n",
        "                            \n",
        "#                             song_dense = padded_tensors_to_dense_matrix(padded_eval_song_tensor, SONG_SHAPE)[:, 1:]\n",
        "#                             artist_dense = padded_tensors_to_dense_matrix(padded_eval_artist_tensor, ARTIST_SHAPE)[:, 1:]\n",
        "#                             if (song_dense.shape[0] != 32) or (artist_dense.shape[0] != 32): break #exlude last batch\n",
        "#                             song_dense = song_dense.to(device)\n",
        "#                             artist_dense = artist_dense.to(device)\n",
        "\n",
        "#                             del padded_eval_song_tensor\n",
        "#                             del padded_eval_artist_tensor\n",
        "                            \n",
        "#                             x = torch.concat((song_dense, artist_dense), dim=1).t()\n",
        "#                             y = torch.concat((song_dense, artist_dense), dim=1).t()\n",
        "                            \n",
        "#                             pretrain_model(x, y)\n",
        "\n",
        "#                             pretrain_model.train()\n",
        "#                             eval_preds = pretrain_model.y_pred[: SONGS_VECTOR_LENGTH]\n",
        "\n",
        "#                             padded_eval_song_tensor_test = song_eval_test[\"embedding_indices\"]\n",
        "                            \n",
        "#                             ground_truth = padded_tensors_to_dense_matrix(padded_eval_song_tensor_test, SONG_SHAPE)[:, 1:]\n",
        "\n",
        "\n",
        "#                             ground_truth = ground_truth.to(device)\n",
        "\n",
        "#                             k = torch.sum(ground_truth == 1, dim=1)\n",
        "#                             tot_k += torch.sum(k)\n",
        "#                             prec_list = evaluate(eval_preds, ground_truth, k=k)\n",
        "#                             precs.extend(prec_list)\n",
        "\n",
        "#                     pretrain_model.train()\n",
        "#                     mean_prec = sum(precs) / tot_k\n",
        "#                     print(f\"Precision on validation set is: {mean_prec} on the list {precs}\")\n",
        "#                     return pretrain_model.cost, mean_prec\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testing if the ordering is correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from tqdm.notebook import tqdm\n",
        "# import random\n",
        "# # os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"\n",
        "# NUM_EPOCHS = 5\n",
        "# with pytorch_merged_dataloader.make_torch_dataloader(batch_size=conf[\"batch\"], num_epochs = NUM_EPOCHS) as train_dataloader:\n",
        "#     ARTIST_SHAPE = (ARTIST_VECTOR_LENGTH, )\n",
        "#     SONG_SHAPE = (SONGS_VECTOR_LENGTH, )\n",
        "#     for batch_idx, row in tqdm(enumerate(train_dataloader), desc=f\"Training model\", total= (NUM_PLAYLISTS / conf[\"batch\"]) * NUM_EPOCHS):\n",
        "#       # Pick random input_keep_prob between 0.5 and 0.8\n",
        "#     #   pretrain_model.input_keep_prob = random.uniform(0.5, 0.8) #TODO: make this dynamic inside the conf\n",
        "#       pretrain_model.input_keep_prob = random.uniform(0.5, 0.8) #TODO: make this dynamic inside the conf\n",
        "\n",
        "#       padded_song_tensor = row[\"tracks_indices\"]\n",
        "#       padded_artist_tensor = row[\"artists_indices\"]\n",
        "      \n",
        "#       song_dense = padded_tensors_to_dense_matrix(padded_song_tensor, SONG_SHAPE)[:, 1:]\n",
        "#       artist_dense = padded_tensors_to_dense_matrix(padded_artist_tensor, ARTIST_SHAPE)[:, 1:]\n",
        "\n",
        "#       song_indices = sorted(list(set(torch.nonzero(song_dense[0] == 1).squeeze().flatten().cpu().detach().tolist())))\n",
        "#       print(torch.nonzero(song_dense[0] == 1))\n",
        "#       songs_artists_df.show()\n",
        "#       artist_indices = torch.nonzero(artist_dense == 1).squeeze().flatten()\n",
        "\n",
        "#     #   print(song_indices)\n",
        "#     #   print(artist_indices)\n",
        "#       break\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GuqQMu_E0yaN"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "jIg2DIDNjEKm"
      },
      "outputs": [],
      "source": [
        "min_loss = 2000\n",
        "max_prec = 0\n",
        "best_params = []\n",
        "losses = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.Tensor([[1,3,4,0,0,0], [1,3,5,3,2,1]])\n",
        "torch.sum(a == 1, dim=1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SFvPuc5hqirK"
      },
      "source": [
        "Pretrain with `DAE_tied`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "800d36c1bd2f4519ad7215f62fe694b2",
            "025feace7e5548cebe8d42356ed1963e",
            "2e5ed18f6ed644898269df6699939a96",
            "210989b9506346409dcb494dc08a7c28",
            "bada53838d434c47bfd5185687d2e133",
            "4cc43c4c34974993ad879ab6789719dc",
            "3a7a8265d2f84b18b0556518474586cc",
            "56ff9818b0e24a4ca8fbe94afc45b797",
            "3af36fc968654a27826c33cbfa6a7b62",
            "1ecbd9fd2159484e9fd5f1ad4028717e",
            "c54d6d9cf7614f20b5f000c29c5a5b18"
          ]
        },
        "id": "Z_BjjpshDD2H",
        "outputId": "e1ab4815-5fa7-433f-b258-bb6317b2d657"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4ebcbdcfc444e0f877fcf099d07b2c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training model:   0%|          | 0/6250.0 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 301918.4375\n",
            "Precisions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Loss: 82138.40625\n",
            "Precisions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Loss: 37576.5234375\n",
            "Precisions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Loss: 20032.7109375\n",
            "Precisions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Loss: 13271.50390625\n",
            "Precisions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Loss: 9078.171875\n",
            "Precisions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Loss: 7211.185546875\n",
            "Precisions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Loss: 5630.58203125\n",
            "Precisions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Loss: 4610.35986328125\n",
            "Precisions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Loss: 3718.125244140625\n",
            "Precisions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Loss: 3289.8984375\n",
            "Precisions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Loss: 2996.613525390625\n",
            "Precisions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Loss: 2794.572265625\n",
            "Precisions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Loss: 2180.5419921875\n",
            "Precisions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Loss: 1970.592529296875\n",
            "Precisions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Loss: 1894.9908447265625\n",
            "Precisions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Loss: 1824.0225830078125\n",
            "Precisions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Loss: 1319.0634765625\n",
            "Precisions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[28], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m song_dense \u001b[39m=\u001b[39m padded_tensors_to_dense_matrix(padded_song_tensor, SONG_SHAPE)[:, \u001b[39m1\u001b[39m:]\n\u001b[1;32m     18\u001b[0m artist_dense \u001b[39m=\u001b[39m padded_tensors_to_dense_matrix(padded_artist_tensor, ARTIST_SHAPE)[:, \u001b[39m1\u001b[39m:]\n\u001b[0;32m---> 20\u001b[0m song_dense \u001b[39m=\u001b[39m song_dense\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     21\u001b[0m artist_dense \u001b[39m=\u001b[39m artist_dense\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     23\u001b[0m rand_int \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39m2\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from networkx import max_weight_clique\n",
        "from tqdm.notebook import tqdm\n",
        "import random\n",
        "# os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"\n",
        "NUM_EPOCHS = 2\n",
        "with pytorch_merged_dataloader.make_torch_dataloader(batch_size=conf[\"batch\"], num_epochs = NUM_EPOCHS) as train_dataloader:\n",
        "    ARTIST_SHAPE = (ARTIST_VECTOR_LENGTH, )\n",
        "    SONG_SHAPE = (SONGS_VECTOR_LENGTH, )\n",
        "    for batch_idx, row in tqdm(enumerate(train_dataloader), desc=f\"Training model\", total= (NUM_PLAYLISTS / conf[\"batch\"]) * NUM_EPOCHS):\n",
        "      # Pick random input_keep_prob between 0.5 and 0.8\n",
        "    #   pretrain_model.input_keep_prob = random.uniform(0.5, 0.8) #TODO: make this dynamic inside the conf\n",
        "      pretrain_model.input_keep_prob = random.uniform(0.5, 0.8) #TODO: make this dynamic inside the conf\n",
        "\n",
        "      padded_song_tensor = row[\"tracks_indices\"]\n",
        "      padded_artist_tensor = row[\"artists_indices\"]\n",
        "      \n",
        "      song_dense = padded_tensors_to_dense_matrix(padded_song_tensor, SONG_SHAPE)[:, 1:]\n",
        "      artist_dense = padded_tensors_to_dense_matrix(padded_artist_tensor, ARTIST_SHAPE)[:, 1:]\n",
        "\n",
        "      song_dense = song_dense.to(device)\n",
        "      artist_dense = artist_dense.to(device)\n",
        "\n",
        "      rand_int = np.random.randint(2)\n",
        "      if rand_int == 0:\n",
        "        #Zero-out the artists\n",
        "        pretrain_optimizer.zero_grad()\n",
        "        x = torch.concat((song_dense, torch.zeros_like(artist_dense)), dim=1).t()\n",
        "        y = torch.concat((song_dense, artist_dense), dim=1).t()\n",
        "        pretrain_model(x, y)\n",
        "        loss = pretrain_model.cost\n",
        "        pretrain_model.cost.backward()\n",
        "        pretrain_optimizer.step()\n",
        "      if rand_int == 1:\n",
        "        #Zero-out the tracks\n",
        "        pretrain_optimizer.zero_grad()\n",
        "        x = torch.concat((torch.zeros_like(song_dense), artist_dense), dim=1).t()\n",
        "        y = torch.concat((song_dense, artist_dense), dim=1).t()\n",
        "        pretrain_model(x, y)\n",
        "        loss = pretrain_model.cost\n",
        "        pretrain_model.cost.backward()\n",
        "        pretrain_optimizer.step()\n",
        "\n",
        "      losses.append(loss)\n",
        "     \n",
        "    #   if loss < min_loss:\n",
        "    #     min_loss = loss\n",
        "    #     del best_params\n",
        "    #     best_params = [param.cpu().detach().numpy() for param in pretrain_model.d_params]\n",
        "    #     with open(BEST_PARAMS_PATH, \"wb\") as f:\n",
        "    #       pickle.dump(best_params, f)\n",
        "    #     print(f\"Best loss achieved: {min_loss}, parameters saved!\")\n",
        "\n",
        "      if batch_idx % 100 == 0:\n",
        "        print(f\"Loss: {loss}\")\n",
        "        # print(f\"z: \", pretrain_model.z)\n",
        "        k = torch.sum(y == 1, dim=1)\n",
        "        counts = evaluate(pretrain_model.y_pred, y.t(), k)\n",
        "        print(\"Precisions: \", torch.tensor(counts)/k.cpu())\n",
        "        # if batch_idx != 0:\n",
        "            # eval_loss, prec = validate(pretrain_model.y_pred)\n",
        "            # print(\"Validation loss: \", eval_loss)\n",
        "            \n",
        "            # # if prec > max_prec:\n",
        "            #     # max_prec = prec\n",
        "            #     # best_params = [param.cpu().detach().numpy() for param in pretrain_model.d_params]\n",
        "            #     # with open(BEST_PARAMS_PATH, \"wb\") as f:\n",
        "            #         # pickle.dump(best_params, f)\n",
        "            #     # print(f\"Best prec achieved: {prec}, parameters saved!\")\n",
        "            # if eval_loss < min_loss:\n",
        "            #     min_loss = eval_loss\n",
        "            #     del best_params\n",
        "            #     best_params = [param.cpu().detach().numpy() for param in pretrain_model.d_params]\n",
        "            #     with open(BEST_PARAMS_PATH, \"wb\") as f:\n",
        "            #         pickle.dump(best_params, f)\n",
        "            #     print(f\"Best loss achieved: {eval_loss}, parameters saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "F85w_ZpmPD9t"
      },
      "outputs": [],
      "source": [
        "params = [param.cpu().detach().numpy() for param in pretrain_model.d_params]\n",
        "with open(BEST_PARAMS_PATH_2, 'wb') as f:\n",
        "  pickle.dump(params, f)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sFOoS7eGqlrH"
      },
      "source": [
        "Train with `DAE` loading the pretrained `DAE_tied` model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFAj48uuqlbd"
      },
      "outputs": [],
      "source": [
        "conf = {\n",
        "    'batch': 250,\n",
        "    'n_input': SONGS_VECTOR_LENGTH + ARTIST_VECTOR_LENGTH - 2, #-2 to compense the first row of zeros since the pos in the df start at 1\n",
        "    'hidden': 256,\n",
        "    'lr': 0.00005,\n",
        "    'reg_lambda': 0.0,\n",
        "    'initval': BEST_PARAMS_PATH,\n",
        "    \"keep_prob\": 0.8, \n",
        "    \"input_keep_prob\": 0.8, # This isn't used for now because of the .uniform()\n",
        "    'save': os.path.join(SAVED_MODELS, \"dae_model.pickle\")\n",
        "}\n",
        "dae_model = DAE(conf)\n",
        "dae_model.init_weight()\n",
        "optimizer = optim.Adam(dae_model.d_params, lr=conf['lr'])\n",
        "\n",
        "min_loss = 600\n",
        "losses = []\n",
        "best_params = []\n",
        "FINE_TUNED_BEST_PARAMS_PATH = os.path.join(SAVED_MODELS, \"final_best_params.pickle\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyw3SnVYyRP1"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import random\n",
        "NUM_EPOCHS = 20\n",
        "with songs_converter.make_torch_dataloader(batch_size=conf[\"batch\"], num_epochs = NUM_EPOCHS) as songs_dataloader:\n",
        "  with artist_converter.make_torch_dataloader(batch_size=conf[\"batch\"], num_epochs = NUM_EPOCHS) as artists_dataloader:\n",
        "    ARTIST_SHAPE = (ARTIST_VECTOR_LENGTH, )\n",
        "    SONG_SHAPE = (SONGS_VECTOR_LENGTH, )\n",
        "    # for epoch in tqdm(range(num_epochs), desc=\"Training...\"):\n",
        "    zipped_dataloaders = zip(songs_dataloader, artists_dataloader)\n",
        "    for batch_idx, (song, artist) in tqdm(enumerate(zipped_dataloaders), desc=f\"Training model\", total= (NUM_PLAYLISTS / conf[\"batch\"]) * NUM_EPOCHS):\n",
        "      # Pick random input_keep_prob between 0.5 and 0.8\n",
        "      dae_model.input_keep_prob = random.uniform(0.5, 0.8) #TODO: make this dynamic inside the conf\n",
        "\n",
        "      padded_song_tensor = song[\"embedding_indices\"]\n",
        "      padded_artist_tensor = artist[\"embedding_indices\"]\n",
        "      \n",
        "      song_dense = padded_tensors_to_dense_matrix(padded_song_tensor, SONG_SHAPE)[:, 1:]\n",
        "      artist_dense = padded_tensors_to_dense_matrix(padded_artist_tensor, ARTIST_SHAPE)[:, 1:]\n",
        "\n",
        "      song_dense = song_dense.to(device)\n",
        "      artist_dense = artist_dense.to(device)\n",
        "\n",
        "      rand_int = np.random.randint(2)\n",
        "      if rand_int == 0:\n",
        "        #Zero-out the artists\n",
        "        optimizer.zero_grad()\n",
        "        x = torch.concat((song_dense, torch.zeros_like(artist_dense)), dim=1).t()\n",
        "        y = torch.concat((song_dense, artist_dense), dim=1).t()\n",
        "        dae_model(x, y)\n",
        "        loss = dae_model.cost\n",
        "        dae_model.cost.backward()\n",
        "        optimizer.step()\n",
        "      if rand_int == 1:\n",
        "        #Zero-out the tracks\n",
        "        optimizer.zero_grad()\n",
        "        x = torch.concat((torch.zeros_like(song_dense), artist_dense), dim=1).t()\n",
        "        y = torch.concat((song_dense, artist_dense), dim=1).t()\n",
        "        dae_model(x, y)\n",
        "        loss = dae_model.cost\n",
        "        dae_model.cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "      losses.append(loss)\n",
        "\n",
        "     \n",
        "      if loss < min_loss:\n",
        "        min_loss = loss\n",
        "        del best_params\n",
        "        best_params = [param.cpu().detach().numpy() for param in dae_model.d_params]\n",
        "        with open(FINE_TUNED_BEST_PARAMS_PATH, \"wb\") as f:\n",
        "          pickle.dump(best_params, f)\n",
        "        print(f\"Best loss achieved: {min_loss}, parameters saved!\")\n",
        "\n",
        "      if batch_idx % 10 == 0:\n",
        "        print(f\"Loss: {loss}\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JQL3P9JByR7Q"
      },
      "source": [
        "Let's see how the loss decreases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qF9gP0FMLdw2"
      },
      "outputs": [],
      "source": [
        "SAVE_MODEL_PATH = os.path.join(SAVED_DFS_PATH, f\"model_new.pickle\")\n",
        "params = [param.cpu().detach().numpy() for param in dae_model.d_params]\n",
        "with open(SAVE_MODEL_PATH, 'wb') as f:\n",
        "  pickle.dump(params, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "V4JxgOCvx2TE"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x = np.arange(len(losses))\n",
        "plt.plot(x, [loss.item() for loss in losses])\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Progression')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Zqyho9fPl0ow"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9RFO76gK8Qb"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.linalg import VectorUDT\n",
        "song_schema = StructType([\n",
        "    StructField(\"pos\", IntegerType(), True),\n",
        "    StructField(\"artist_name\", StringType(), True),\n",
        "    StructField(\"track_uri\", StringType(), True),\n",
        "    StructField(\"artist_uri\", StringType(), True),\n",
        "    StructField(\"track_name\", StringType(), True),\n",
        "    StructField(\"album_uri\", StringType(), True),\n",
        "    StructField(\"duration_ms\", LongType(), True),\n",
        "    StructField(\"album_name\", StringType(), True)\n",
        "])\n",
        "\n",
        "playlist_schema = StructType([\n",
        "    StructField(\"name\", StringType(), True),\n",
        "    StructField(\"collaborative\", StringType(), True),\n",
        "    StructField(\"pid\", IntegerType(), True),\n",
        "    StructField(\"modified_at\", IntegerType(), True),\n",
        "    StructField(\"num_tracks\", IntegerType(), True),\n",
        "    StructField(\"num_albums\", IntegerType(), True),\n",
        "    StructField(\"num_followers\", IntegerType(), True),\n",
        "    StructField(\"tracks\", ArrayType(song_schema), True),\n",
        "    StructField(\"num_edits\", IntegerType(), True),\n",
        "    StructField(\"duration_ms\", IntegerType(), True),\n",
        "    StructField(\"num_artists\", IntegerType(), True),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lgIPJo2tbUL"
      },
      "outputs": [],
      "source": [
        "SONGS_EMBEDDINGS_PATH_TEST_TRAIN = os.path.join(SAVED_DFS_PATH, f\"nn_songs_embeddings-test-train-{NUM_PLAYLISTS}.json\")\n",
        "SONGS_EMBEDDINGS_PATH_TEST_TEST = os.path.join(SAVED_DFS_PATH, f\"nn_songs_embeddings-test-test-{NUM_PLAYLISTS}.json\")\n",
        "\n",
        "ARTISTS_EMBEDDINGS_PATH_TEST_TRAIN = os.path.join(SAVED_DFS_PATH, f\"nn_artists_embeddings-test-train-{NUM_PLAYLISTS}.json\")\n",
        "ARTISTS_EMBEDDINGS_PATH_TEST_TEST = os.path.join(SAVED_DFS_PATH, f\"nn_artists_embeddings-test-test-{NUM_PLAYLISTS}.json\")\n",
        "\n",
        "songs_embeddings_test_train = spark.read.schema(playlist_schema_mapped).json(SONGS_EMBEDDINGS_PATH_TEST_TRAIN)\n",
        "songs_embeddings_test_test = spark.read.schema(playlist_schema_mapped).json(SONGS_EMBEDDINGS_PATH_TEST_TEST)\n",
        "\n",
        "artists_embeddings_test_train = spark.read.schema(playlist_schema_mapped).json(ARTISTS_EMBEDDINGS_PATH_TEST_TRAIN)\n",
        "artists_embeddings_test_test = spark.read.schema(playlist_schema_mapped).json(ARTISTS_EMBEDDINGS_PATH_TEST_TEST)\n",
        "\n",
        "TEST_TRAIN_DF_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_test_df-train-{NUM_PLAYLISTS}.json\")\n",
        "TEST_TEST_DF_PATH = os.path.join(SAVED_DFS_PATH, f\"nn_test_df-test-{NUM_PLAYLISTS}.json\")\n",
        "\n",
        "test_train_df = spark.read.schema(playlist_schema).json(TEST_TRAIN_DF_PATH)\n",
        "test_test_df = spark.read.schema(playlist_schema).json(TEST_TEST_DF_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKbyd0kRl3SH"
      },
      "outputs": [],
      "source": [
        "def construct_prediction_df(prediction: torch.Tensor, mapping: DataFrame, top_n: int = 50) -> DataFrame:\n",
        "  pred_np = prediction.detach().numpy()\n",
        "  indexes = np.arange(pred_np.shape[0]) # To compensate the index start at 1\n",
        "  schema = StructType([\n",
        "      StructField(\"pos\", IntegerType()),\n",
        "      StructField(\"confidence\", FloatType())\n",
        "  ])\n",
        "  prediction_df = spark.createDataFrame([(pos, conf) for pos, conf in zip(indexes.tolist(), pred_np.tolist())],schema)\n",
        "  prediction_info = prediction_df.join(mapping, \"pos\")\n",
        "  return prediction_info\n",
        "\n",
        "# prediction_df = construct_prediction_df(prediction, songs_df_test)\n",
        "# prediction_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQ9LquCdSbJJ"
      },
      "outputs": [],
      "source": [
        "def remove_existing_tracks(playlist_tracks: DataFrame, recommendations_df: DataFrame) -> DataFrame:\n",
        "  playlist_tracks = playlist_tracks.select(\"track_uri\").cache()\n",
        "  playlist_tracks_compatible = playlist_tracks.join(F.broadcast(recommendations_df), on=\"track_uri\")\n",
        "  playlist_tracks.unpersist()\n",
        "  return recommendations_df.exceptAll(F.broadcast(playlist_tracks_compatible))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx-tghy0bAkU"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hb793kgebBwJ"
      },
      "outputs": [],
      "source": [
        "def precision_at_k(recommendations, ground_truth, num_of_recommendations) -> float:\n",
        "    \"\"\"\n",
        "    Calculates precision at k for the recommendations.\n",
        "    \"\"\"\n",
        "    recommended_relevant_tracks = recommendations.join(ground_truth, \"track_uri\").cache()\n",
        "    reccomended_relevant_tracks_count = recommended_relevant_tracks.count() #this can be top_n_results.join in order to be more performant\n",
        "    recommended_relevant_tracks.unpersist()\n",
        "    precision = reccomended_relevant_tracks_count / float(num_of_recommendations)\n",
        "\n",
        "    return precision\n",
        "\n",
        "\n",
        "import math\n",
        "def normalized_discounted_cumulative_gain(recommendations: DataFrame, ground_truth: DataFrame, num_of_recommendations: int) -> float:\n",
        "  recommendations_list = recommendations.collect()\n",
        "  cumulative_gain = 0\n",
        "\n",
        "  intersection = recommendations.join(ground_truth, \"track_uri\").count()\n",
        "  if intersection == 0: return 0\n",
        "\n",
        "  ideal_cumulative_gain = 1 + np.array([(1 / math.log(i, 2)) for i in range(2, 2+intersection)]).sum() #TODO: replace this with sum([])\n",
        "  for index, row in enumerate(recommendations_list):\n",
        "    i = index + 1\n",
        "    is_rel = ground_truth.filter(F.col(\"track_uri\").isin(row.track_uri)).count() > 0\n",
        "    rel = 1 if is_rel else 0\n",
        "    if i == 1:\n",
        "      cumulative_gain += rel\n",
        "    else:\n",
        "      cumulative_gain += (rel / math.log(i, 2))\n",
        "  return cumulative_gain / ideal_cumulative_gain"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VUYEe5iHbTHs"
      },
      "source": [
        "Creating the dataloaders for the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYXLsGIrbH2e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Converting floating-point columns to float32                                    \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max number of songs: 250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The median size 137021 B (< 50 MB) of the parquet files is too small. Total size: 233150 B. Increase the median file size by calling df.repartition(n) or df.coalesce(n), which might help improve the performance. Parquet files: file:///Users/dov/Desktop/big-data-project/data/cache/20230613203504-appid-local-1686674016052-044c5a3b-7e2e-4703-bde1-c5581a209825/part-00001-2209ea1f-fd7e-4e79-b87b-e7b847d72234-c000.parquet, ...\n",
            "Converting floating-point columns to float32\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max number of songs: 250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The median size 19056 B (< 50 MB) of the parquet files is too small. Total size: 134516 B. Increase the median file size by calling df.repartition(n) or df.coalesce(n), which might help improve the performance. Parquet files: file:///Users/dov/Desktop/big-data-project/data/cache/20230613203506-appid-local-1686674016052-989e6c66-19d3-4e2c-9408-5bb7a5ea72a5/part-00000-c95c506b-0a0b-41e6-8a3b-3a5d31d76cac-c000.parquet, ...\n"
          ]
        }
      ],
      "source": [
        "spark.conf.set(SparkDatasetConverter.PARENT_CACHE_DIR_URL_CONF, f'file://{CACHE}')\n",
        "\n",
        "pytorch_songs_df_test = convert_sparse_to_indices(songs_embeddings_test_train.select(\"tracks\"))\n",
        "songs_converter_test = make_spark_converter(pytorch_songs_df_test)\n",
        "\n",
        "pytorch_artists_df_test = convert_sparse_to_indices(artists_embeddings_test_train.select(\"tracks\"))\n",
        "artist_converter_test = make_spark_converter(pytorch_artists_df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9h7NRo3Ggt3h"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DAE()"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Hyperparameters used in the paper\n",
        "conf = {\n",
        "    'batch': 32,\n",
        "    'n_input': SONGS_VECTOR_LENGTH + ARTIST_VECTOR_LENGTH - 2, #-2 to compense the first row of zeros since the pos in the df starts at 1,\n",
        "    'hidden': 50,\n",
        "    'lr': 0.001, #original 0.001\n",
        "    'reg_lambda': 0.0,\n",
        "    'initval': BEST_PARAMS_PATH, #TODO: change it in fine_tuned path\n",
        "    \"keep_prob\": 1,\n",
        "    \"input_keep_prob\": 1,\n",
        "    'save': os.path.join(SAVED_MODELS, \"dae_model.pickle\")\n",
        "}\n",
        "dae_model_test = DAE(conf)\n",
        "dae_model_test.init_weight()\n",
        "dae_model_test.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dn2zrRCSdKQO"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc248691ce9346268ecdfbdc206f3b47",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluation...:   0%|          | 0/3125.0 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ARTIST_SHAPE = (ARTIST_VECTOR_LENGTH, )\n",
        "SONG_SHAPE = (SONGS_VECTOR_LENGTH, )\n",
        "with songs_converter_test.make_torch_dataloader(batch_size=conf[\"batch\"], num_epochs =1) as songs_dataloader:\n",
        "  with artist_converter_test.make_torch_dataloader(batch_size=conf[\"batch\"], num_epochs=1) as artists_dataloader:\n",
        "    zipped_dataloaders = zip(songs_dataloader, artists_dataloader)\n",
        "    for batch_idx, (song, artist) in tqdm(enumerate(zipped_dataloaders), desc=f\"Evaluation...\", total= (NUM_PLAYLISTS / conf[\"batch\"])):\n",
        "      padded_song_tensor = song[\"embedding_indices\"]\n",
        "      padded_artist_tensor = artist[\"embedding_indices\"]\n",
        "      \n",
        "      song_dense = padded_tensors_to_dense_matrix(padded_song_tensor, SONG_SHAPE)[:, 1:]\n",
        "      artist_dense = padded_tensors_to_dense_matrix(padded_artist_tensor, ARTIST_SHAPE)[:, 1:]\n",
        "\n",
        "      song_dense = song_dense.to(device)\n",
        "      artist_dense = artist_dense.to(device)\n",
        "\n",
        "      x = torch.concat((song_dense, artist_dense), dim=1).t()\n",
        "      y = torch.concat((song_dense, artist_dense), dim=1).t()\n",
        "      \n",
        "      dae_model_test(x,y)\n",
        "      \n",
        "      result = dae_model_test.y_pred\n",
        "      break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRZ9w5nr5TaK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0261, 0.0018, 0.0084,  ..., 0.0003, 0.0004, 0.0004],\n",
              "        [0.0270, 0.0019, 0.0088,  ..., 0.0003, 0.0004, 0.0004],\n",
              "        [0.0272, 0.0019, 0.0089,  ..., 0.0003, 0.0004, 0.0004],\n",
              "        ...,\n",
              "        [0.0292, 0.0022, 0.0098,  ..., 0.0004, 0.0005, 0.0005],\n",
              "        [0.0262, 0.0018, 0.0084,  ..., 0.0003, 0.0004, 0.0004],\n",
              "        [0.0264, 0.0018, 0.0086,  ..., 0.0003, 0.0004, 0.0004]],\n",
              "       device='mps:0', grad_fn=<SigmoidBackward0>)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yg8V8VSSu3XI"
      },
      "outputs": [],
      "source": [
        "# torch.concat((song_dense[:, 1:], artist_dense[:, 1:]), dim=1).t().shape\n",
        "# (song_dense[:, 0] == 0.).all(), (artist_dense[:, 0] == 0.).all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLpygSgaMVr6"
      },
      "outputs": [],
      "source": [
        "# result = result.to(\"cpu\")\n",
        "# prediction_df = construct_prediction_df(result[10][:SONGS_VECTOR_LENGTH_TEST], songs_df_test, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uYwzqLFMjWE"
      },
      "outputs": [],
      "source": [
        "# prediction_df.orderBy(\"pos\").show(truncate=False)\n",
        "# songs_df_test.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0wojIXkuFnN"
      },
      "outputs": [],
      "source": [
        "# def evaluate_batch(batch_result: torch.Tensor, batch_n: int) -> Tuple[float, float]:\n",
        "#   \"\"\"\n",
        "#   Returns the precision and NDCG for a given batch.\n",
        "#   \"\"\"\n",
        "  \n",
        "#   return 0,0\n",
        "\n",
        "# def perform_evaluation(songs_dataloader, artists_dataloader, test_set):\n",
        "#   \"\"\"\n",
        "#   Returns the precision and NDCG, averaged from all the samples in the test set\n",
        "#   \"\"\"\n",
        "#   with songs_converter_test.make_torch_dataloader(num_epochs =1) as songs_dataloader:\n",
        "#     with artist_converter_test.make_torch_dataloader(num_epochs=1) as artists_dataloader:\n",
        "#       zipped_dataloaders = zip(songs_dataloader, artists_dataloader)\n",
        "#       for batch_idx, (song, artist) in tqdm(enumerate(zipped_dataloaders), desc=f\"Evaluation...\", total= (NUM_PLAYLISTS / 32) * NUM_EPOCHS):\n",
        "#         padded_song_tensor = song[\"embedding_indices\"]\n",
        "#         padded_artist_tensor = artist[\"embedding_indices\"]\n",
        "        \n",
        "#         song_dense = padded_tensors_to_dense_matrix(padded_song_tensor, SONG_SHAPE)\n",
        "#         artist_dense = padded_tensors_to_dense_matrix(padded_artist_tensor, ARTIST_SHAPE)\n",
        "\n",
        "#         x = torch.concat((song_dense, artist_dense), dim=1).t()\n",
        "#         y = torch.concat((song_dense, artist_dense), dim=1).t()\n",
        "#         dae_model(x,y)\n",
        "#         batch_result = dae_model.y_pred\n",
        "#         break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4LWsnwWeVAV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/13 20:36:00 WARN TaskSetManager: Stage 35 contains a task of very large size (1209 KiB). The maximum recommended task size is 1000 KiB.\n",
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "71860 0.0 0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DataFrame[pos: int, confidence: float, track_uri: string]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Testing the first batch\n",
        "\n",
        "results = []\n",
        "# for i in tqdm(range(32)):\n",
        "PID = 71860\n",
        "ground_truth = test_test_df.filter(F.col(\"pid\") == PID).select(F.explode(\"tracks\")).select(\"col.*\")\n",
        "playlist_train_songs = test_train_df.filter(F.col(\"pid\") == PID).select(F.explode(\"tracks\")).select(\"col.*\")\n",
        "\n",
        "#Removing rare songs (that the model didn't consider)\n",
        "#This may be not the best approach since the train songs or ground truth may become 0\n",
        "clean_ground_truth = ground_truth.join(song_mapping, on=\"track_uri\").cache()\n",
        "clean_playlist_train_songs = playlist_train_songs.join(song_mapping, on=\"track_uri\").cache()\n",
        "\n",
        "# n_recommendations = ground_truth.count() or 1\n",
        "n_recommendations = 500\n",
        "result = result.cpu()\n",
        "\n",
        "#The result[i] has to be aligned with the PID. i != PID. \n",
        "prediction_df = construct_prediction_df(result[1][:SONGS_VECTOR_LENGTH], song_mapping, n_recommendations).cache()\n",
        "clean_prediction_df = remove_existing_tracks(clean_playlist_train_songs, prediction_df)\n",
        "\n",
        "clean_prediction_df = prediction_df.orderBy(F.col(\"confidence\").desc()).limit(n_recommendations).cache()\n",
        "\n",
        "prec = precision_at_k(clean_prediction_df, clean_ground_truth, n_recommendations)\n",
        "gain = normalized_discounted_cumulative_gain(clean_prediction_df, clean_ground_truth, n_recommendations)\n",
        "print(PID, prec, gain)\n",
        "results.append((prec, gain))\n",
        "\n",
        "ground_truth.unpersist()\n",
        "clean_ground_truth.unpersist()\n",
        "playlist_train_songs.unpersist()\n",
        "clean_playlist_train_songs.unpersist()\n",
        "prediction_df.unpersist()\n",
        "clean_prediction_df.unpersist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XUxFpPGVLf-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Playlist train songs\n",
            "+---+-------------+------------------------------------+-------------------------------------+---------------------------------------------------------------+------------------------------------+-----------+-----------------+\n",
            "|pos|artist_name  |track_uri                           |artist_uri                           |track_name                                                     |album_uri                           |duration_ms|album_name       |\n",
            "+---+-------------+------------------------------------+-------------------------------------+---------------------------------------------------------------+------------------------------------+-----------+-----------------+\n",
            "|17 |MIKA         |spotify:track:6AviHKu3ydzAePBmzEi62v|spotify:artist:5MmVJVhhYKQ86izuGHzJYA|Popular Song                                                   |spotify:album:6czdbbMtGbAkZ6ud2OMTcg|200213     |Yours Truly      |\n",
            "|8  |Ariana Grande|spotify:track:6EIsMa5lbvljYxqCkjZVDi|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Baby I                                                         |spotify:album:5xSvNPstcxHtR4ap2vvN8A|197600     |Yours Truly      |\n",
            "|16 |Ariana Grande|spotify:track:442j8VxaB60dWf9cBFuX5w|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Almost Is Never Enough                                         |spotify:album:6czdbbMtGbAkZ6ud2OMTcg|327773     |Yours Truly      |\n",
            "|12 |Ariana Grande|spotify:track:1xCqIXCApBgcjwRLostpKl|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Piano                                                          |spotify:album:5xSvNPstcxHtR4ap2vvN8A|234426     |Yours Truly      |\n",
            "|19 |Ariana Grande|spotify:track:7fYbFYt7X4FZvuJJC90EX0|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Problem                                                        |spotify:album:2ZnzBwKw4e2SHpGvOTWnj4|193893     |My Everything    |\n",
            "|9  |Ariana Grande|spotify:track:3yiopxxeHuwcpAg4e57Zjt|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Right There                                                    |spotify:album:5xSvNPstcxHtR4ap2vvN8A|247080     |Yours Truly      |\n",
            "|32 |Ariana Grande|spotify:track:3YQfqb3oFhDZa3iNcFu57G|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|You Don't Know Me                                              |spotify:album:5AMOKSM1ftb3opIbGT2d4q|233720     |My Everything    |\n",
            "|0  |Ariana Grande|spotify:track:1magKwGDsyU3RGjpo0BfPe|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Brand New You (feat. Brynn Williams & Caitlin Gann)            |spotify:album:48uMMsVHGfKipIsOuYcvjs|188093     |Brand New You    |\n",
            "|25 |Ariana Grande|spotify:track:26gXVZqHG3AThfmkXLlp3P|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Break Your Heart Right Back                                    |spotify:album:2ZnzBwKw4e2SHpGvOTWnj4|253386     |My Everything    |\n",
            "|5  |Ariana Grande|spotify:track:4r4V1wYecTxSAAXV11cFPD|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Focus                                                          |spotify:album:1TVt7uWfV3vLiU8bEmBEWL|211360     |Dangerous Woman  |\n",
            "|11 |Ariana Grande|spotify:track:7EpKfPAURnG9OCVer0S30N|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Lovin' It                                                      |spotify:album:5xSvNPstcxHtR4ap2vvN8A|180693     |Yours Truly      |\n",
            "|1  |Ariana Grande|spotify:track:5RNKIGhRllNHGjroVDPXat|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|A Little More Homework (feat. Graham Phillips) - Single Version|spotify:album:48uMMsVHGfKipIsOuYcvjs|302733     |Brand New You    |\n",
            "|37 |Ariana Grande|spotify:track:73pH60xHd2S87oNIlgztNY|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|True Love                                                      |spotify:album:2A1KyqHu1DmLtjXpIMNoQq|166466     |Christmas & Chill|\n",
            "|21 |Ariana Grande|spotify:track:6LZkF2fayIxtA1SIMmAGoX|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Why Try                                                        |spotify:album:2ZnzBwKw4e2SHpGvOTWnj4|211880     |My Everything    |\n",
            "|2  |Ariana Grande|spotify:track:1ADjWm8QNhgNV8yCNNgQ1T|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Santa Tell Me                                                  |spotify:album:2Y42QS2bGi5NokHzjticau|204093     |Santa Tell Me    |\n",
            "|29 |Ariana Grande|spotify:track:0b0hbaQZnkFDOGjOUkIbUK|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|My Everything                                                  |spotify:album:2ZnzBwKw4e2SHpGvOTWnj4|168546     |My Everything    |\n",
            "|35 |Ariana Grande|spotify:track:1gCC4V2iW0juUv4jaDABsp|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|December                                                       |spotify:album:2A1KyqHu1DmLtjXpIMNoQq|116800     |Christmas & Chill|\n",
            "|3  |Ariana Grande|spotify:track:2h1IPjP471JJRSShTHRUhi|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Dangerous Woman                                                |spotify:album:4lVR2fg3DAUQpGVJ6DciHW|235946     |Dangerous Woman  |\n",
            "|34 |Ariana Grande|spotify:track:2E5R3USq1SSOFDnl4SHe1Z|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Wit It This Christmas                                          |spotify:album:2A1KyqHu1DmLtjXpIMNoQq|161680     |Christmas & Chill|\n",
            "|23 |Ariana Grande|spotify:track:1BP617VnYByf7FzCnLEjbg|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Best Mistake                                                   |spotify:album:2ZnzBwKw4e2SHpGvOTWnj4|233733     |My Everything    |\n",
            "+---+-------------+------------------------------------+-------------------------------------+---------------------------------------------------------------+------------------------------------+-----------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Clean playlist train songs\n",
            "+------------------------------------+---+-------------+-------------------------------------+---------------------------------------------------------------+------------------------------------+-----------+-----------------+------+\n",
            "|track_uri                           |pos|artist_name  |artist_uri                           |track_name                                                     |album_uri                           |duration_ms|album_name       |pos   |\n",
            "+------------------------------------+---+-------------+-------------------------------------+---------------------------------------------------------------+------------------------------------+-----------+-----------------+------+\n",
            "|spotify:track:6EIsMa5lbvljYxqCkjZVDi|8  |Ariana Grande|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Baby I                                                         |spotify:album:5xSvNPstcxHtR4ap2vvN8A|197600     |Yours Truly      |440   |\n",
            "|spotify:track:1xCqIXCApBgcjwRLostpKl|12 |Ariana Grande|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Piano                                                          |spotify:album:5xSvNPstcxHtR4ap2vvN8A|234426     |Yours Truly      |645   |\n",
            "|spotify:track:1gCC4V2iW0juUv4jaDABsp|35 |Ariana Grande|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|December                                                       |spotify:album:2A1KyqHu1DmLtjXpIMNoQq|116800     |Christmas & Chill|5231  |\n",
            "|spotify:track:1BP617VnYByf7FzCnLEjbg|23 |Ariana Grande|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Best Mistake                                                   |spotify:album:2ZnzBwKw4e2SHpGvOTWnj4|233733     |My Everything    |6146  |\n",
            "|spotify:track:7fYbFYt7X4FZvuJJC90EX0|19 |Ariana Grande|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Problem                                                        |spotify:album:2ZnzBwKw4e2SHpGvOTWnj4|193893     |My Everything    |15043 |\n",
            "|spotify:track:0b0hbaQZnkFDOGjOUkIbUK|29 |Ariana Grande|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|My Everything                                                  |spotify:album:2ZnzBwKw4e2SHpGvOTWnj4|168546     |My Everything    |19506 |\n",
            "|spotify:track:2ofOe2OaXFpZF5ETbsc7Qu|7  |Ariana Grande|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Honeymoon Avenue                                               |spotify:album:5xSvNPstcxHtR4ap2vvN8A|339733     |Yours Truly      |23797 |\n",
            "|spotify:track:1X2Zd5wKGbY1oKzb8dzJRy|22 |Ariana Grande|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Break Free                                                     |spotify:album:2ZnzBwKw4e2SHpGvOTWnj4|214840     |My Everything    |28070 |\n",
            "|spotify:track:3yiopxxeHuwcpAg4e57Zjt|9  |Ariana Grande|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Right There                                                    |spotify:album:5xSvNPstcxHtR4ap2vvN8A|247080     |Yours Truly      |31049 |\n",
            "|spotify:track:2E5R3USq1SSOFDnl4SHe1Z|34 |Ariana Grande|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Wit It This Christmas                                          |spotify:album:2A1KyqHu1DmLtjXpIMNoQq|161680     |Christmas & Chill|32035 |\n",
            "|spotify:track:73pH60xHd2S87oNIlgztNY|37 |Ariana Grande|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|True Love                                                      |spotify:album:2A1KyqHu1DmLtjXpIMNoQq|166466     |Christmas & Chill|32849 |\n",
            "|spotify:track:4r4V1wYecTxSAAXV11cFPD|5  |Ariana Grande|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Focus                                                          |spotify:album:1TVt7uWfV3vLiU8bEmBEWL|211360     |Dangerous Woman  |36153 |\n",
            "|spotify:track:1ADjWm8QNhgNV8yCNNgQ1T|2  |Ariana Grande|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Santa Tell Me                                                  |spotify:album:2Y42QS2bGi5NokHzjticau|204093     |Santa Tell Me    |38574 |\n",
            "|spotify:track:6AviHKu3ydzAePBmzEi62v|17 |MIKA         |spotify:artist:5MmVJVhhYKQ86izuGHzJYA|Popular Song                                                   |spotify:album:6czdbbMtGbAkZ6ud2OMTcg|200213     |Yours Truly      |39098 |\n",
            "|spotify:track:5Pnny78GESkBSLnxFmhRYZ|18 |Ariana Grande|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Better Left Unsaid                                             |spotify:album:5xSvNPstcxHtR4ap2vvN8A|211226     |Yours Truly      |46939 |\n",
            "|spotify:track:6LZkF2fayIxtA1SIMmAGoX|21 |Ariana Grande|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Why Try                                                        |spotify:album:2ZnzBwKw4e2SHpGvOTWnj4|211880     |My Everything    |49053 |\n",
            "|spotify:track:5RNKIGhRllNHGjroVDPXat|1  |Ariana Grande|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|A Little More Homework (feat. Graham Phillips) - Single Version|spotify:album:48uMMsVHGfKipIsOuYcvjs|302733     |Brand New You    |54328 |\n",
            "|spotify:track:26gXVZqHG3AThfmkXLlp3P|25 |Ariana Grande|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Break Your Heart Right Back                                    |spotify:album:2ZnzBwKw4e2SHpGvOTWnj4|253386     |My Everything    |344842|\n",
            "|spotify:track:7bJwvubZZaoGE1AGEfu8Fi|20 |Ariana Grande|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|One Last Time                                                  |spotify:album:2ZnzBwKw4e2SHpGvOTWnj4|197253     |My Everything    |346905|\n",
            "|spotify:track:0zrQwV4XbcwZ2bS9r7F944|38 |Ariana Grande|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Winter Things                                                  |spotify:album:2A1KyqHu1DmLtjXpIMNoQq|158720     |Christmas & Chill|348561|\n",
            "+------------------------------------+---+-------------+-------------------------------------+---------------------------------------------------------------+------------------------------------+-----------+-----------------+------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Ground truth songs\n",
            "+---+-------------+------------------------------------+-------------------------------------+-------------------------------+------------------------------------+-----------+-----------------+\n",
            "|pos|artist_name  |track_uri                           |artist_uri                           |track_name                     |album_uri                           |duration_ms|album_name       |\n",
            "+---+-------------+------------------------------------+-------------------------------------+-------------------------------+------------------------------------+-----------+-----------------+\n",
            "|33 |Ariana Grande|spotify:track:4QgH3GXHnHuxMJu3RG69Hg|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Intro                          |spotify:album:2A1KyqHu1DmLtjXpIMNoQq|65960      |Christmas & Chill|\n",
            "|36 |Ariana Grande|spotify:track:09VVVW2VxsmXE5Pyo3T0ah|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Not Just On Christmas          |spotify:album:2A1KyqHu1DmLtjXpIMNoQq|123573     |Christmas & Chill|\n",
            "|4  |Ariana Grande|spotify:track:3tRFqxTYOjeTmCiVaGDCsq|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Be Alright                     |spotify:album:4lVR2fg3DAUQpGVJ6DciHW|179293     |Dangerous Woman  |\n",
            "|13 |Ariana Grande|spotify:track:7c86ULTZD9eNdAbJDQLRaC|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Daydreamin'                    |spotify:album:5xSvNPstcxHtR4ap2vvN8A|211293     |Yours Truly      |\n",
            "|30 |Jessie J     |spotify:track:3oEekS4xhmFQ88ieCVTZ7H|spotify:artist:2gsggkzM5R49q6jpPvazou|Bang Bang                      |spotify:album:5AMOKSM1ftb3opIbGT2d4q|199320     |My Everything    |\n",
            "|26 |Ariana Grande|spotify:track:45wBTYlOx3FsuFluuuRRQh|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Love Me Harder                 |spotify:album:2ZnzBwKw4e2SHpGvOTWnj4|236133     |My Everything    |\n",
            "|6  |Ariana Grande|spotify:track:5AKlnLpP3WLwZseNbjquND|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Let Me Love You                |spotify:album:3OZgEywV4krCZ814pTJWr7|223853     |Dangerous Woman  |\n",
            "|27 |Ariana Grande|spotify:track:5DsnMBbnSmEmqOQMFTwXRq|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Just A Little Bit Of Your Heart|spotify:album:2ZnzBwKw4e2SHpGvOTWnj4|232586     |My Everything    |\n",
            "|24 |Ariana Grande|spotify:track:6djcQtHtVZHfAKlRNydlIi|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Be My Baby                     |spotify:album:2ZnzBwKw4e2SHpGvOTWnj4|217053     |My Everything    |\n",
            "|15 |Ariana Grande|spotify:track:4PqIj0WOfPAq4QAvisjgpd|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Youll Never Know              |spotify:album:5xSvNPstcxHtR4ap2vvN8A|214280     |Yours Truly      |\n",
            "+---+-------------+------------------------------------+-------------------------------------+-------------------------------+------------------------------------+-----------+-----------------+\n",
            "\n",
            "Clean ground truth songs\n",
            "+------------------------------------+---+-------------+-------------------------------------+-------------------------------+------------------------------------+-----------+-----------------+------+\n",
            "|track_uri                           |pos|artist_name  |artist_uri                           |track_name                     |album_uri                           |duration_ms|album_name       |pos   |\n",
            "+------------------------------------+---+-------------+-------------------------------------+-------------------------------+------------------------------------+-----------+-----------------+------+\n",
            "|spotify:track:5AKlnLpP3WLwZseNbjquND|6  |Ariana Grande|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Let Me Love You                |spotify:album:3OZgEywV4krCZ814pTJWr7|223853     |Dangerous Woman  |8333  |\n",
            "|spotify:track:6djcQtHtVZHfAKlRNydlIi|24 |Ariana Grande|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Be My Baby                     |spotify:album:2ZnzBwKw4e2SHpGvOTWnj4|217053     |My Everything    |27633 |\n",
            "|spotify:track:3oEekS4xhmFQ88ieCVTZ7H|30 |Jessie J     |spotify:artist:2gsggkzM5R49q6jpPvazou|Bang Bang                      |spotify:album:5AMOKSM1ftb3opIbGT2d4q|199320     |My Everything    |28065 |\n",
            "|spotify:track:4PqIj0WOfPAq4QAvisjgpd|15 |Ariana Grande|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Youll Never Know              |spotify:album:5xSvNPstcxHtR4ap2vvN8A|214280     |Yours Truly      |30628 |\n",
            "|spotify:track:5DsnMBbnSmEmqOQMFTwXRq|27 |Ariana Grande|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Just A Little Bit Of Your Heart|spotify:album:2ZnzBwKw4e2SHpGvOTWnj4|232586     |My Everything    |36513 |\n",
            "|spotify:track:7c86ULTZD9eNdAbJDQLRaC|13 |Ariana Grande|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Daydreamin'                    |spotify:album:5xSvNPstcxHtR4ap2vvN8A|211293     |Yours Truly      |55101 |\n",
            "|spotify:track:3tRFqxTYOjeTmCiVaGDCsq|4  |Ariana Grande|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Be Alright                     |spotify:album:4lVR2fg3DAUQpGVJ6DciHW|179293     |Dangerous Woman  |340926|\n",
            "|spotify:track:45wBTYlOx3FsuFluuuRRQh|26 |Ariana Grande|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Love Me Harder                 |spotify:album:2ZnzBwKw4e2SHpGvOTWnj4|236133     |My Everything    |348129|\n",
            "|spotify:track:09VVVW2VxsmXE5Pyo3T0ah|36 |Ariana Grande|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Not Just On Christmas          |spotify:album:2A1KyqHu1DmLtjXpIMNoQq|123573     |Christmas & Chill|353659|\n",
            "|spotify:track:4QgH3GXHnHuxMJu3RG69Hg|33 |Ariana Grande|spotify:artist:66CXWjxzNUsdJxJ2JdwvnR|Intro                          |spotify:album:2A1KyqHu1DmLtjXpIMNoQq|65960      |Christmas & Chill|373013|\n",
            "+------------------------------------+---+-------------+-------------------------------------+-------------------------------+------------------------------------+-----------+-----------------+------+\n",
            "\n",
            "Prediction df songs (num recommendations: 500)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/13 20:36:18 WARN TaskSetManager: Stage 66 contains a task of very large size (1209 KiB). The maximum recommended task size is 1000 KiB.\n",
            "23/06/13 20:36:19 WARN TaskSetManager: Stage 71 contains a task of very large size (1209 KiB). The maximum recommended task size is 1000 KiB.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+------------+------------------------------------+\n",
            "|pos|confidence  |track_uri                           |\n",
            "+---+------------+------------------------------------+\n",
            "|7  |0.0051272963|spotify:track:48ZUwXrEOhaXLCxvmRYhZv|\n",
            "|19 |0.0037515892|spotify:track:4eQec76xYzMWafPfJEDELl|\n",
            "|22 |4.4842117E-4|spotify:track:0srm8RgwUfBvwdXKvkyDlT|\n",
            "|26 |0.015324642 |spotify:track:6G6u99wgTtoATpqtNmA02F|\n",
            "|29 |0.00205158  |spotify:track:3cwDSDzTiWr5H5xMQhQ6Mx|\n",
            "|34 |0.006128149 |spotify:track:2X9G82BPPSqhE78e5YjekE|\n",
            "|50 |4.309273E-4 |spotify:track:35k31HZI4z9PbBOioaI4dZ|\n",
            "|54 |8.9117774E-4|spotify:track:6iX1f3r7oUJnMbGgQ2gx1j|\n",
            "|57 |0.0011192594|spotify:track:0C1OcBOsuFmFFGkh3FWIGG|\n",
            "|65 |0.0026256384|spotify:track:4bEcoz1OcfMgUbp2ft8ieQ|\n",
            "|77 |2.4645153E-4|spotify:track:4Fvnz1ZJ86IdqDAepWYPAh|\n",
            "|94 |2.4668826E-4|spotify:track:6HEAUuBSW9lCL4clfEOTJ8|\n",
            "|110|2.5660856E-4|spotify:track:65lHwG8JFJs67PnOUhCYPq|\n",
            "|112|5.3823285E-4|spotify:track:1UlyHfT68gEVYwIMIVEX1u|\n",
            "|113|0.0024502387|spotify:track:7EgG37pjxw0Y4GHwjK3CBS|\n",
            "|126|4.112541E-4 |spotify:track:19e8D0Qvau0q8X7JCnYhtF|\n",
            "|130|2.4615446E-4|spotify:track:65wNNrAj5mMOLvLQ2JQhlv|\n",
            "|136|0.001412612 |spotify:track:6lAdV7Btii1FmVOjtvSUxt|\n",
            "|144|5.9100153E-4|spotify:track:54SFFQhDGvPCWhYLtu2bJn|\n",
            "|149|0.0012145697|spotify:track:6xHQ7ogo1QqWT89UGYv1Mf|\n",
            "+---+------------+------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Clean Prediction df songs (num recommendations: 500)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 72:>                                                         (0 + 8) / 8]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+-----------+------------------------------------+\n",
            "|pos   |confidence |track_uri                           |\n",
            "+------+-----------+------------------------------------+\n",
            "|681805|0.1904341  |spotify:track:7AbAfIqrkrWHwSF32eemMV|\n",
            "|23173 |0.1091218  |spotify:track:6DjEa4vziZjdYG0bq2Jxcl|\n",
            "|348871|0.099217884|spotify:track:539wfGOsGcRmT1IBVUfiJV|\n",
            "|338336|0.09756852 |spotify:track:0zMzyHAeMvwq5CRstru1Fp|\n",
            "|30442 |0.0918417  |spotify:track:4z0PnuB07fxtVZZRWsCfxb|\n",
            "|28061 |0.09160706 |spotify:track:2gdEfFFTRU8ylaqteESdk2|\n",
            "|36914 |0.082439065|spotify:track:5JDcQAztvZTIkrWoZihgvC|\n",
            "|367112|0.08186953 |spotify:track:5SECgk6Gf1TVMy2FApJmSO|\n",
            "|376243|0.08050343 |spotify:track:3cqZH3cqvfbV8wVbvHyPbG|\n",
            "|29257 |0.079650715|spotify:track:0SGkqnVQo9KPytSri1H6cF|\n",
            "|355820|0.07798547 |spotify:track:1SN1gifVAKecU85lZggS8k|\n",
            "|366732|0.075138435|spotify:track:66hayvUbTotekKU3H4ta1f|\n",
            "|348084|0.07473964 |spotify:track:6SwRhMLwNqEi6alNPVG00n|\n",
            "|38126 |0.07468223 |spotify:track:4TshxhRTfQqDhQbXmTvY50|\n",
            "|21166 |0.0745314  |spotify:track:2AOQVSqYB0KXryNscZCCOE|\n",
            "|15024 |0.0727116  |spotify:track:4immekPm8Har57BB9DcDSj|\n",
            "|21610 |0.07174019 |spotify:track:1FYf85iyKfzECNWS70QP8i|\n",
            "|29256 |0.07165393 |spotify:track:7dIDDbPxb3t9EmkyGLb1kb|\n",
            "|11706 |0.0711102  |spotify:track:6XLWV4y0TWPzZGY72m6mbA|\n",
            "|366742|0.07104324 |spotify:track:7A0FGrZsLgOUmeNtMTnt4z|\n",
            "+------+-----------+------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.0, 0)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Playlist train songs\")\n",
        "playlist_train_songs.show(truncate=False)\n",
        "print(\"Clean playlist train songs\")\n",
        "clean_playlist_train_songs.show(truncate=False)\n",
        "print(\"Ground truth songs\")\n",
        "ground_truth.show(truncate=False)\n",
        "print(\"Clean ground truth songs\")\n",
        "clean_ground_truth.show(truncate=False)\n",
        "print(f\"Prediction df songs (num recommendations: {n_recommendations})\")\n",
        "prediction_df.show(truncate=False)\n",
        "print(f\"Clean Prediction df songs (num recommendations: {n_recommendations})\")\n",
        "clean_prediction_df.show(truncate=False)\n",
        "prec, gain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iN8Fk_7Jel4-"
      },
      "outputs": [],
      "source": [
        "def average_results(results):\n",
        "  prec_avg = sum(prec for prec, _ in results) / len(results)\n",
        "  gain_avg = sum(gain for _, gain in results) / len(results)\n",
        "  return prec_avg, gain_avg\n",
        "\n",
        "average_results(results)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMMG33ctvkyDDZwCI68FV48",
      "collapsed_sections": [
        "XvQ6e0PgCOZg"
      ],
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "025feace7e5548cebe8d42356ed1963e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cc43c4c34974993ad879ab6789719dc",
            "placeholder": "",
            "style": "IPY_MODEL_3a7a8265d2f84b18b0556518474586cc",
            "value": "Training model:   0%"
          }
        },
        "1ecbd9fd2159484e9fd5f1ad4028717e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "210989b9506346409dcb494dc08a7c28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ecbd9fd2159484e9fd5f1ad4028717e",
            "placeholder": "",
            "style": "IPY_MODEL_c54d6d9cf7614f20b5f000c29c5a5b18",
            "value": " 0/8000.0 [00:00&lt;?, ?it/s]"
          }
        },
        "2e5ed18f6ed644898269df6699939a96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56ff9818b0e24a4ca8fbe94afc45b797",
            "max": 8000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3af36fc968654a27826c33cbfa6a7b62",
            "value": 0
          }
        },
        "3a7a8265d2f84b18b0556518474586cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3af36fc968654a27826c33cbfa6a7b62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4cc43c4c34974993ad879ab6789719dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56ff9818b0e24a4ca8fbe94afc45b797": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "800d36c1bd2f4519ad7215f62fe694b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_025feace7e5548cebe8d42356ed1963e",
              "IPY_MODEL_2e5ed18f6ed644898269df6699939a96",
              "IPY_MODEL_210989b9506346409dcb494dc08a7c28"
            ],
            "layout": "IPY_MODEL_bada53838d434c47bfd5185687d2e133"
          }
        },
        "bada53838d434c47bfd5185687d2e133": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c54d6d9cf7614f20b5f000c29c5a5b18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
