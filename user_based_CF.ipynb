{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DomizianoScarcelli/big-data-project/blob/nn-model/user_based_CF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ySOgYrVKaDjm"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KOojFseRjVnN"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "def is_running_on_colab():\n",
        "    return \"COLAB_GPU\" in os.environ\n",
        "\n",
        "LOCAL = not is_running_on_colab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3wVgRfHYoOs",
        "outputId": "dcb30a00-e042-4c4e-e4f0-95951f55460e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The operation couldn’t be completed. Unable to locate a Java Runtime that supports apt.\n",
            "Please visit http://www.java.com for information on installing Java.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title Download necessary libraries\n",
        "if not LOCAL:\n",
        "    !pip install pyspark -qq\n",
        "    !pip install -U -q PyDrive -qq\n",
        "    !apt install openjdk-8-jdk-headless -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "CGHPv9OqY9MI"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import plotly\n",
        "\n",
        "import pyspark\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql import SparkSession, DataFrame, Row\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType, FloatType, LongType\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.ml.linalg import SparseVector, DenseVector, VectorUDT\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "import gc\n",
        "\n",
        "if not LOCAL:\n",
        "    from google.colab import drive\n",
        "\n",
        "from typing import Tuple\n",
        "from functools import reduce\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JF8LUBZeYiWP"
      },
      "outputs": [],
      "source": [
        "#@title Set up variables\n",
        "if not LOCAL:\n",
        "    JAVA_HOME = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "    GDRIVE_DIR = \"/content/drive\"\n",
        "    GDRIVE_HOME_DIR = GDRIVE_DIR + \"/MyDrive\"\n",
        "    GDRIVE_DATA_DIR = GDRIVE_HOME_DIR + \"/Big Data/datasets\"\n",
        "    DATASET_FILE = os.path.join(GDRIVE_DATA_DIR, \"pyspark_friendly_spotify_playlist_dataset\")\n",
        "    AUDIO_FEATURES_FILE = os.path.join(GDRIVE_DATA_DIR, \"pyspark_track_features\")\n",
        "    LITTLE_SLICE_FILE = os.path.join(GDRIVE_DATA_DIR, \"little_slice\")\n",
        "    SMALL_SLICE_FLIE = os.path.join(GDRIVE_DATA_DIR, \"small_slice\")\n",
        "    LITTLE_SLICE_AUDIO_FEATURES = os.path.join(GDRIVE_DATA_DIR, \"little_slice_audio_features\")\n",
        "    MICRO_SLICE_AUDIO_FEATURES = os.path.join(GDRIVE_DATA_DIR, \"micro_slice_audio_features\")\n",
        "    SPLITTED_SLICE_AUDIO_FEATURES = os.path.join(GDRIVE_DATA_DIR, \"splitted_pyspark_track_features\")\n",
        "    SAVED_DFS_PATH = os.path.join(GDRIVE_DATA_DIR, \"saved_dfs\")\n",
        "    SAVED_MODELS = os.path.join(GDRIVE_DATA_DIR, \"saved_models\")\n",
        "else:\n",
        "    GDRIVE_DATA_DIR = os.path.abspath(\"./data\")\n",
        "    SAVED_DFS_PATH = os.path.join(GDRIVE_DATA_DIR, \"saved_dfs\")\n",
        "    SAVED_MODELS = os.path.join(GDRIVE_DATA_DIR, \"saved_models\")\n",
        "    DATASET_FILE = os.path.join(GDRIVE_DATA_DIR, \"full_dataset\")\n",
        "    SMALL_SLICE_FLIE = os.path.join(GDRIVE_DATA_DIR, \"small_slice\")\n",
        "    JAVA_HOME = \"/opt/homebrew/opt/openjdk\"\n",
        "RANDOM_SEED = 42 # for reproducibility\n",
        "os.environ[\"JAVA_HOME\"] = JAVA_HOME\n",
        "os.environ[\"PYSPARK_PYTHON\"]=\"python\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "4m7VztzdZgm6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "23/06/22 19:35:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
          ]
        }
      ],
      "source": [
        "#@title Create the session\n",
        "conf = SparkConf().\\\n",
        "                set('spark.ui.port', \"4050\").\\\n",
        "                set('spark.executor.memory', '12G').\\\n",
        "                set('spark.driver.memory', '12G').\\\n",
        "                set('spark.driver.maxResultSize', '100G').\\\n",
        "                set(\"spark.executor.extraJavaOptions\", \"-XX:+UseG1GC\").\\\n",
        "                setAppName(\"PySparkTutorial\").\\\n",
        "                setMaster(\"local[*]\")\n",
        "\n",
        "# Create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsX5d-YXZ2Ul",
        "outputId": "5a5dd440-edea-47ea-f469-9a4f043335c5"
      },
      "outputs": [],
      "source": [
        "if not LOCAL:\n",
        "    drive.mount(GDRIVE_DIR, force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlxfJiBSZ6ju",
        "outputId": "bc4c8bba-256b-4b45-d45d-166d9a5460ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<pyspark.sql.session.SparkSession at 0x147f4d3f0>,\n",
              " [('spark.executor.extraJavaOptions',\n",
              "   '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false -XX:+UseG1GC'),\n",
              "  ('spark.app.name', 'PySparkTutorial'),\n",
              "  ('spark.driver.host', '192.168.1.175'),\n",
              "  ('spark.executor.id', 'driver'),\n",
              "  ('spark.driver.extraJavaOptions',\n",
              "   '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false'),\n",
              "  ('spark.ui.port', '4050'),\n",
              "  ('spark.rdd.compress', 'True'),\n",
              "  ('spark.driver.memory', '12G'),\n",
              "  ('spark.driver.port', '59115'),\n",
              "  ('spark.serializer.objectStreamReset', '100'),\n",
              "  ('spark.master', 'local[*]'),\n",
              "  ('spark.submit.pyFiles', ''),\n",
              "  ('spark.driver.maxResultSize', '100G'),\n",
              "  ('spark.app.startTime', '1687455344714'),\n",
              "  ('spark.submit.deployMode', 'client'),\n",
              "  ('spark.app.submitTime', '1687455344633'),\n",
              "  ('spark.executor.memory', '12G'),\n",
              "  ('spark.ui.showConsoleProgress', 'true'),\n",
              "  ('spark.app.id', 'local-1687455345182')])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@title Check if everything is ok\n",
        "spark, sc._conf.getAll()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VJeY9PpvaHUJ"
      },
      "source": [
        "# Data acquisition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "icd2lj-RRvhU"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.linalg import VectorUDT\n",
        "song_schema = StructType([\n",
        "    StructField(\"pos\", IntegerType(), True),\n",
        "    StructField(\"artist_name\", StringType(), True),\n",
        "    StructField(\"track_uri\", StringType(), True),\n",
        "    StructField(\"artist_uri\", StringType(), True),\n",
        "    StructField(\"track_name\", StringType(), True),\n",
        "    StructField(\"album_uri\", StringType(), True),\n",
        "    StructField(\"duration_ms\", LongType(), True),\n",
        "    StructField(\"album_name\", StringType(), True)\n",
        "])\n",
        "\n",
        "playlist_schema = StructType([\n",
        "    StructField(\"name\", StringType(), True),\n",
        "    StructField(\"collaborative\", StringType(), True),\n",
        "    StructField(\"pid\", IntegerType(), True),\n",
        "    StructField(\"modified_at\", IntegerType(), True),\n",
        "    StructField(\"num_tracks\", IntegerType(), True),\n",
        "    StructField(\"num_albums\", IntegerType(), True),\n",
        "    StructField(\"num_followers\", IntegerType(), True),\n",
        "    StructField(\"tracks\", ArrayType(song_schema), True),\n",
        "    StructField(\"num_edits\", IntegerType(), True),\n",
        "    StructField(\"duration_ms\", IntegerType(), True),\n",
        "    StructField(\"num_artists\", IntegerType(), True),\n",
        "])\n",
        "\n",
        "playlist_schema_mapped = StructType([\n",
        "    StructField(\"name\", StringType(), True),\n",
        "    StructField(\"collaborative\", StringType(), True),\n",
        "    StructField(\"pid\", IntegerType(), True),\n",
        "    StructField(\"modified_at\", IntegerType(), True),\n",
        "    StructField(\"num_tracks\", IntegerType(), True),\n",
        "    StructField(\"num_albums\", IntegerType(), True),\n",
        "    StructField(\"num_followers\", IntegerType(), True),\n",
        "    StructField(\"tracks\", VectorUDT(), True),\n",
        "    StructField(\"num_edits\", IntegerType(), True),\n",
        "    StructField(\"duration_ms\", IntegerType(), True),\n",
        "    StructField(\"num_artists\", IntegerType(), True),\n",
        "])\n",
        "\n",
        "audio_features_schema = StructType([\n",
        "    StructField(\"danceability\", FloatType(), True),\n",
        "    StructField(\"energy\", FloatType(), True),\n",
        "    StructField(\"key\", IntegerType(), True),\n",
        "    StructField(\"loudness\", FloatType(), True),\n",
        "    StructField(\"mode\", IntegerType(), True),\n",
        "    StructField(\"speechiness\", FloatType(), True),\n",
        "    StructField(\"acousticness\", FloatType(), True),\n",
        "    StructField(\"instrumentalness\", FloatType(), True),\n",
        "    StructField(\"liveness\", FloatType(), True),\n",
        "    StructField(\"valence\", FloatType(), True),\n",
        "    StructField(\"tempo\", FloatType(), True),\n",
        "    StructField(\"type\", StringType(), True),\n",
        "    StructField(\"id\", StringType(), True),\n",
        "    StructField(\"uri\", StringType(), True),\n",
        "    StructField(\"track_href\", StringType(), True),\n",
        "    StructField(\"analysis_url\", StringType(), True),\n",
        "    StructField(\"duration_ms\", LongType(), True),\n",
        "    StructField(\"time_signature\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BY_szFyLTps4"
      },
      "outputs": [],
      "source": [
        "# playlist_df = spark.read.schema(playlist_schema).json(DATASET_FILE, multiLine=True)\n",
        "slice_df = spark.read.schema(playlist_schema).json(SMALL_SLICE_FLIE, multiLine=True)\n",
        "# slice_df = spark.read.schema(playlist_schema).json(LITTLE_SLICE_FILE, multiLine=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WaSyTUepySNu"
      },
      "source": [
        "# User-Based Collaborative Filtering\n",
        "Note: The users are the playlists, the items are the songs and the ratings are 0 if the song is not in the playlist, 1 otherwise.\n",
        "\n",
        "We have to define a function $sim(u,v)$ that defines the similarity between two users based on their ratings.\n",
        "\n",
        "We represent the ratings $r_u \\in \\mathbb{R}^n$ as the $n$ dimensional vector that represents the ratings of the user $u$, where $n$ is the number of total songs in the dataset.\n",
        "\n",
        "As the similarity function we can use Jaccard similarity.\n",
        "\\begin{equation}\n",
        "sim(u,v) = J(r_u, r_v) = \\frac{|r_u \\cap r_v|}{|r_u \\cup r_v|}\n",
        "\\end{equation}\n",
        "\n",
        "Jaccard similarity ignores rating values, but we don't care here since the ratings are binary. In case of discrete value ratings we can use cosine similarity, or better pearson's correlation.\n",
        "\n",
        "Done that, and defined as ${U^k}$ the neighborhood of $u$ ($k$ most similar users to $u$), we define the set of items rated by $u$'s neighborhood as\n",
        "\n",
        "\\begin{equation}\n",
        "I^k = \\{i \\in I : \\mathbf{r_{u,i}} \\downarrow \\land u \\in U^k\\}\n",
        "\\end{equation}\n",
        "\n",
        "The rating for the item $i$ to the user $u$ will just be $\\mathbf{r_u[i]}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dawV4e6yOCo4"
      },
      "outputs": [],
      "source": [
        "from functools import wraps\n",
        "import time\n",
        "\n",
        "DEBUG = True\n",
        "IGNORE_TIMING = True\n",
        "def timeit(func):\n",
        "    @wraps(func)\n",
        "    def timeit_wrapper(*args, **kwargs):\n",
        "        start_time = time.perf_counter()\n",
        "        result = func(*args, **kwargs)\n",
        "        end_time = time.perf_counter()\n",
        "        total_time = end_time - start_time\n",
        "        if not IGNORE_TIMING:\n",
        "          print(f'Function {func.__name__} Took {total_time:.4f} seconds')\n",
        "        return result\n",
        "    return timeit_wrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Ym9TWjvkGGOa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:35:55 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
          ]
        }
      ],
      "source": [
        "NUM_PLAYLISTS = 100_000\n",
        "SONGS_EMBEDDINGS_PATH = os.path.join(SAVED_DFS_PATH, f\"songs_embeddings-{NUM_PLAYLISTS}.json\")\n",
        "SONGS_INFO_DF = os.path.join(SAVED_DFS_PATH, f\"songs_info_df-{NUM_PLAYLISTS}.json\") #TODO: Little bug this is songs_df, meaning it hasn't got any info, but we don't actually care.\n",
        "RATING_VECTOR_LENGTH_PATH = os.path.join(SAVED_DFS_PATH, f\"songs_vector_length-{NUM_PLAYLISTS}.txt\")\n",
        "with open(RATING_VECTOR_LENGTH_PATH, \"r\") as f:\n",
        "  RATING_VECTOR_LENGTH = int(f.read())\n",
        "\n",
        "songs_embeddings = spark.read.schema(playlist_schema_mapped).json(SONGS_EMBEDDINGS_PATH)\n",
        "song_pos_mapping = spark.read.json(SONGS_INFO_DF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9n1ed0ryz3m",
        "outputId": "134d7eb5-40a2-4c5c-80b8-34c477451d9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+--------------------+\n",
            "|pos|           track_uri|\n",
            "+---+--------------------+\n",
            "|  0|spotify:track:1mr...|\n",
            "|  1|spotify:track:1Uv...|\n",
            "|  2|spotify:track:4WR...|\n",
            "|  3|spotify:track:7B6...|\n",
            "|  4|spotify:track:2Gy...|\n",
            "|  5|spotify:track:7AO...|\n",
            "|  6|spotify:track:48Z...|\n",
            "|  7|spotify:track:1Um...|\n",
            "|  8|spotify:track:7MO...|\n",
            "|  9|spotify:track:27P...|\n",
            "| 10|spotify:track:6lt...|\n",
            "| 11|spotify:track:1yz...|\n",
            "| 12|spotify:track:5Mz...|\n",
            "| 13|spotify:track:3BU...|\n",
            "| 14|spotify:track:4Cl...|\n",
            "| 15|spotify:track:2dN...|\n",
            "| 16|spotify:track:341...|\n",
            "| 17|spotify:track:7ja...|\n",
            "| 18|spotify:track:4eQ...|\n",
            "| 19|spotify:track:6fy...|\n",
            "+---+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-------------+-------------+----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "|         name|collaborative| pid|modified_at|num_tracks|num_albums|num_followers|              tracks|num_edits|duration_ms|num_artists|\n",
            "+-------------+-------------+----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "|       disney|        false|1000| 1457827200|       189|        16|            1|(681805,[126,1903...|        4|   31428282|         65|\n",
            "|Indie Electro|        false|1001| 1417824000|       165|        18|            2|(681805,[17322,18...|        2|   38241566|          8|\n",
            "|  jack & jack|        false|1002| 1465430400|        17|        14|            1|(681805,[4591,952...|        3|    3549358|          3|\n",
            "|        vibes|        false|1003| 1498435200|       225|       195|            2|(681805,[392,431,...|       91|   51242585|        157|\n",
            "|        Indie|        false|1004| 1498608000|       165|       118|            1|(681805,[196,425,...|       74|   42601098|         92|\n",
            "|      college|        false|1005| 1504310400|        28|        26|            1|(681805,[899,6937...|        2|    5870710|         25|\n",
            "|    Summer 15|        false|1006| 1471996800|        80|        74|            2|(681805,[1221,351...|       40|   19652753|         67|\n",
            "|    New music|        false|1007| 1509148800|        58|        48|            1|(681805,[1070,207...|       20|   13158862|         38|\n",
            "|          Now|        false|1008| 1505692800|        84|        82|            3|(681805,[1709,371...|       36|   18432208|         79|\n",
            "|         Jams|        false|1009| 1507680000|        41|        36|            1|(681805,[82584,83...|       25|    9413467|         31|\n",
            "|    Party Mix|        false|1010| 1464393600|        74|        72|            2|(681805,[124,397,...|       11|   17853470|         63|\n",
            "|         LOCO|        false|1011| 1491868800|        97|        90|           18|(681805,[753,6951...|       27|   20635206|         82|\n",
            "|   Bruno Mars|        false|1012| 1506211200|        18|         7|            1|(681805,[1226,441...|        3|    3974946|          3|\n",
            "|       Breezy|        false|1013| 1490140800|        67|        55|            1|(681805,[836,3685...|       42|   14724585|         45|\n",
            "|      Fall 16|        false|1014| 1496793600|        83|        64|            3|(681805,[533,900,...|       27|   21004989|         49|\n",
            "|          SLO|        false|1015| 1498262400|        53|        32|            1|(681805,[5466,109...|        3|   12136870|         19|\n",
            "|       BANGAZ|        false|1016| 1508716800|       198|       141|            1|(681805,[65,575,7...|      104|   43843897|         89|\n",
            "|  Piano Music|        false|1017| 1401148800|        29|        21|            1|(681805,[2246,146...|        5|    6992643|         12|\n",
            "|  Beach Music|        false|1018| 1492387200|       130|       106|           14|(681805,[2564,328...|       27|   30811124|         70|\n",
            "|    Slow jamz|        false|1019| 1505779200|        43|        42|            1|(681805,[2081,238...|       15|   11198025|         32|\n",
            "+-------------+-------------+----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "song_pos_mapping.show(), songs_embeddings.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "X5iG9Mus6VWy"
      },
      "source": [
        "Preprocessing the dataframe in order to associate to each track_uri an integer, that will represent the position of the track in the rating_vector. This is useful in order to avoid doing a lot of joins when generating the rating_vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "MFwQWIZ1Bddv"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "track_uri_to_id = song_pos_mapping.select('track_uri', 'pos').rdd.collectAsMap()\n",
        "def map_track_df_to_pos(playlist_df: DataFrame) -> DataFrame:\n",
        "    \"\"\"\n",
        "    Returns a DataFrames containing the playlists, but the tracks are represented as a binary sparse vector.\n",
        "    \"\"\"\n",
        "\n",
        "    @F.udf(returnType=VectorUDT())\n",
        "    def extract_vector(tracks):\n",
        "      pos_list = set()\n",
        "\n",
        "      def reduce_fn(pos_list, row):\n",
        "          pos_list.add(track_uri_to_id.get(row.track_uri))\n",
        "          return pos_list\n",
        "      \n",
        "      pos_list = reduce(reduce_fn, tracks, pos_list)\n",
        "      \n",
        "      return SparseVector(RATING_VECTOR_LENGTH, sorted(list(pos_list)), [1 for _ in pos_list])\n",
        "\n",
        "    # Apply the mapping UDF on the \"tracks\" column of the slice_df dataframe\n",
        "    mapped_df = playlist_df.withColumn('tracks', extract_vector(F.col('tracks')))\n",
        "\n",
        "    return mapped_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hWyQZJ5JrDjR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The size of the track_uri -> position mapping dictionary is 20.971608 MB\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(\"The size of the track_uri -> position mapping dictionary is {} MB\".format(sys.getsizeof(track_uri_to_id) / 1_000_000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "rB2LIcCJ0t-K"
      },
      "outputs": [],
      "source": [
        "# def row_to_sparse_vector(item: dict) -> SparseVector:\n",
        "#     \"\"\"\n",
        "#     Because of json serialization, the SparseVector is converted into a Row(indices=..., values=...),\n",
        "#     this function converts it back to a pyspark.SparseVector with length RATING_VECTOR_LENGHT+1 as default.\n",
        "#     \"\"\"\n",
        "#     return SparseVector(RATING_VECTOR_LENGTH+1, item.indices, item.values)\n",
        "\n",
        "# @udf(returnType=VectorUDT())\n",
        "# def parse_sparse_vector(row):\n",
        "#   return row_to_sparse_vector(row)\n",
        "\n",
        "# #TODO: Uncomment this and remove the other calls to row_to_spare_vector\n",
        "# # mapped_slice_df = mapped_slice_df.withColumnRenamed(\"rating_vector\", \"temp\")\\\n",
        "#   # .withColumn(\"rating_vector\", parse_sparse_vector(col(\"temp\")))\\\n",
        "#   # .drop(\"temp\").cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "5Nhc0hwgDQ6X"
      },
      "outputs": [],
      "source": [
        "def jaccard_similarity(vector_1: SparseVector, vector_2: SparseVector) -> float:\n",
        "  \"\"\"\n",
        "  Computes the Jaccard Similarity between two sparse binary vectors\n",
        "  \"\"\"\n",
        "  # Convert SparseVectors to sets\n",
        "  set1 = set(vector_1.indices)\n",
        "  set2 = set(vector_2.indices)\n",
        "\n",
        "  # Calculate the intersection and union of the sets\n",
        "  intersection = len(set1.intersection(set2))\n",
        "  union = len(set1.union(set2))\n",
        "\n",
        "  # Calculate the similarity\n",
        "  similarity = intersection / union\n",
        "\n",
        "  return similarity"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dWMpoMHrpxxf"
      },
      "source": [
        "Creating a function that gets in input the playlist to continue, and returns a Dataframe that indicates its similarity with each other playlist in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "SGjEbkYTAI3h"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 6:============================================>              (6 + 2) / 8]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+-------------+-----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+----------+\n",
            "|           name|collaborative|  pid|modified_at|num_tracks|num_albums|num_followers|       rating_vector|num_edits|duration_ms|num_artists|similarity|\n",
            "+---------------+-------------+-----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+----------+\n",
            "|         disney|        false| 1000| 1457827200|       189|        16|            1|(681805,[126,1903...|        4|   31428282|         65|       1.0|\n",
            "|         Disney|        false|34420| 1430784000|       179|        15|            1|(681805,[254,1903...|        3|   25533248|         54|0.22635135|\n",
            "|        Disney✨|        false|12990| 1450915200|       113|        32|            1|(681805,[1790,190...|        3|   20665774|         64|0.18775511|\n",
            "|         Disney|        false| 3323| 1391817600|       133|        20|            1|(681805,[4132,494...|        6|   23208277|         64|0.16911764|\n",
            "|         DISNEY|        false|44565| 1506470400|       179|        23|            1|(681805,[83,4442,...|        5|   26129019|         70|0.16666667|\n",
            "|  Disney Movies|        false|23038| 1399852800|       170|        16|            6|(681805,[1903,349...|        2|   25356294|         50|0.16393442|\n",
            "|Disney Princess|        false|65458| 1496793600|       159|        25|            1|(681805,[83,126,2...|        3|   26615932|         71|0.16271186|\n",
            "|         Disney|        false|50071| 1486080000|       154|        55|            1|(681805,[916,1790...|       16|   28494250|         95|0.15862069|\n",
            "|         disney|        false| 9718| 1467849600|        74|        28|            1|(681805,[126,4286...|        6|   14431883|         53|   0.15625|\n",
            "|        Disney |        false|45621| 1469404800|       191|        60|            1|(681805,[125,126,...|       12|   35313420|        100|0.15189873|\n",
            "|         DISNEY|        false|84889| 1410480000|       241|        23|            1|(681805,[254,1903...|        2|   38597440|         79|0.14516129|\n",
            "|         Disney|        false|22490| 1396396800|       245|        20|            1|(681805,[254,1903...|        3|   37871643|         66|0.14506173|\n",
            "|         DISNEY|        false|36245| 1479772800|        58|        24|            1|(681805,[4940,494...|        4|   10831497|         39|0.14285715|\n",
            "|         Disney|        false|33505| 1453680000|        95|        34|            1|(681805,[4940,668...|        8|   16193877|         69|0.13360325|\n",
            "|      disney!!!|        false|57499| 1423526400|       228|        35|            1|(681805,[254,1790...|        2|   40446966|         82| 0.1278409|\n",
            "|         Disney|        false|10604| 1419811200|       124|        13|            1|(681805,[3436,349...|        2|   20226973|         39|0.12773722|\n",
            "|        Disney |        false|21144| 1488153600|       112|        38|            1|(681805,[83,4442,...|        5|   17514563|         87|0.12643678|\n",
            "|         Disney|        false|27458| 1411084800|        56|        13|            1|(681805,[4940,860...|        5|    8923982|         41|0.12616822|\n",
            "|         Disney|         true|69884| 1490918400|        49|        15|            3|(681805,[2438,860...|        9|    9143547|         34|     0.125|\n",
            "|      Disney <3|        false|18810| 1404864000|       215|        25|            1|(681805,[254,1549...|        4|   36929082|         59|0.12112676|\n",
            "+---------------+-------------+-----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "from typing import Callable\n",
        "@timeit\n",
        "def create_similarity_df(input_vector: DataFrame, rating_vectors_df: DataFrame, similarityFunction: Callable) -> DataFrame:  \n",
        "  input_vector_cached = input_vector.cache()\n",
        "  input_vector = input_vector.first()[0]\n",
        "  \n",
        "  @F.udf(returnType=FloatType())\n",
        "  def compute_similarity(vector1):\n",
        "    return jaccard_similarity(vector1, input_vector)\n",
        "\n",
        "  rv_df_input = rating_vectors_df\n",
        "  result_df = rv_df_input.withColumn(\"similarity\", compute_similarity(rv_df_input.rating_vector))\n",
        "\n",
        "  input_vector_cached.unpersist()\n",
        "  \n",
        "  return result_df\n",
        "\n",
        "if DEBUG:\n",
        "  rv_df = songs_embeddings.withColumnRenamed(\"tracks\", \"rating_vector\")\n",
        "  # Just to show, we take the first playlist as the playlist to be continued \n",
        "  first_playlist_vector = rv_df.limit(1).select(\"rating_vector\").withColumnRenamed(\"rating_vector\",\"input_vector\")\n",
        "  result_df = create_similarity_df(first_playlist_vector, rv_df, jaccard_similarity)\n",
        "  result_df.cache()\n",
        "  result_df.orderBy(F.col(\"similarity\").desc()).show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "12CY_fuNFXKr"
      },
      "source": [
        "Curse of dimensionality! We can see that each playlist is very dissimilar from each other playlist.\n",
        "\n",
        "If we filter the playlists that have a strictly positive similarity with the input playlist, and order them by descending similarity, we can see that the name (that we assume is very informative for the content of the playlist) is very similar, meaning that the algorithm seems to work!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NrPRMP-rINkc"
      },
      "outputs": [],
      "source": [
        "# result_df.filter(\"similarity > 0\").orderBy(col(\"similarity\").desc()).show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ppy5-Y19swvG"
      },
      "source": [
        "Now, in order to suggest some songs to continuate the input playlist, let's take the $k$ top most similar playlists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "wNoSOnIqCLm8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+-------------+-----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+----------+\n",
            "|           name|collaborative|  pid|modified_at|num_tracks|num_albums|num_followers|       rating_vector|num_edits|duration_ms|num_artists|similarity|\n",
            "+---------------+-------------+-----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+----------+\n",
            "|         Disney|        false|34420| 1430784000|       179|        15|            1|(681805,[254,1903...|        3|   25533248|         54|0.22635135|\n",
            "|        Disney✨|        false|12990| 1450915200|       113|        32|            1|(681805,[1790,190...|        3|   20665774|         64|0.18775511|\n",
            "|         Disney|        false| 3323| 1391817600|       133|        20|            1|(681805,[4132,494...|        6|   23208277|         64|0.16911764|\n",
            "|         DISNEY|        false|44565| 1506470400|       179|        23|            1|(681805,[83,4442,...|        5|   26129019|         70|0.16666667|\n",
            "|  Disney Movies|        false|23038| 1399852800|       170|        16|            6|(681805,[1903,349...|        2|   25356294|         50|0.16393442|\n",
            "|Disney Princess|        false|65458| 1496793600|       159|        25|            1|(681805,[83,126,2...|        3|   26615932|         71|0.16271186|\n",
            "|         Disney|        false|50071| 1486080000|       154|        55|            1|(681805,[916,1790...|       16|   28494250|         95|0.15862069|\n",
            "|         disney|        false| 9718| 1467849600|        74|        28|            1|(681805,[126,4286...|        6|   14431883|         53|   0.15625|\n",
            "|        Disney |        false|45621| 1469404800|       191|        60|            1|(681805,[125,126,...|       12|   35313420|        100|0.15189873|\n",
            "|         DISNEY|        false|84889| 1410480000|       241|        23|            1|(681805,[254,1903...|        2|   38597440|         79|0.14516129|\n",
            "|         Disney|        false|22490| 1396396800|       245|        20|            1|(681805,[254,1903...|        3|   37871643|         66|0.14506173|\n",
            "|         DISNEY|        false|36245| 1479772800|        58|        24|            1|(681805,[4940,494...|        4|   10831497|         39|0.14285715|\n",
            "|         Disney|        false|33505| 1453680000|        95|        34|            1|(681805,[4940,668...|        8|   16193877|         69|0.13360325|\n",
            "|      disney!!!|        false|57499| 1423526400|       228|        35|            1|(681805,[254,1790...|        2|   40446966|         82| 0.1278409|\n",
            "|         Disney|        false|10604| 1419811200|       124|        13|            1|(681805,[3436,349...|        2|   20226973|         39|0.12773722|\n",
            "|        Disney |        false|21144| 1488153600|       112|        38|            1|(681805,[83,4442,...|        5|   17514563|         87|0.12643678|\n",
            "|         Disney|        false|27458| 1411084800|        56|        13|            1|(681805,[4940,860...|        5|    8923982|         41|0.12616822|\n",
            "|         Disney|         true|69884| 1490918400|        49|        15|            3|(681805,[2438,860...|        9|    9143547|         34|     0.125|\n",
            "|      Disney <3|        false|18810| 1404864000|       215|        25|            1|(681805,[254,1549...|        4|   36929082|         59|0.12112676|\n",
            "|    disney love|        false|57883| 1470700800|       167|        48|            1|(681805,[1549,179...|       10|   28566741|        112| 0.1178344|\n",
            "+---------------+-------------+-----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "@timeit\n",
        "def get_top_k_results(playlist_pid: int, similarity_df: DataFrame, k: int = 20) -> DataFrame:\n",
        "  return similarity_df.filter((F.col(\"similarity\") > 0) & (F.col(\"pid\") != playlist_pid)).orderBy(F.col(\"similarity\").desc()).limit(k)\n",
        "\n",
        "if DEBUG:\n",
        "  first_playlist_pid = rv_df.limit(1).select(\"pid\").first().pid\n",
        "  top_k_results = get_top_k_results(first_playlist_pid, result_df)\n",
        "  top_k_results.cache()\n",
        "  top_k_results.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nGUtRgGutIgZ"
      },
      "source": [
        "We want to obtain a single embedding for all the $K$ top most similar playlists, that will be the rating vector. We can then pick the indices of the $n$ top greatest values form this vector, and those will be the $n$ songs that we will reccomend.\n",
        "\n",
        "In order to aggregate the $k$ embeddings into a single one, I decided to take an average, weighted by the similarity value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "nDEnlGrCcOHp"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 12:>                                                         (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|              summed|\n",
            "+--------------------+\n",
            "|(681805,[83,125,2...|\n",
            "+--------------------+\n",
            "\n",
            "28.124406099319458\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "@timeit\n",
        "def get_input_rating_vector(similarity_df: DataFrame) -> SparseVector:\n",
        "  return similarity_df.limit(1).select(\"input_vector\").collect()[0].input_vector\n",
        "\n",
        "@timeit\n",
        "def accumulate_top_k_results(top_k_results: DataFrame, input_vector: np.ndarray) -> DataFrame:\n",
        "\n",
        "  @F.udf(returnType=VectorUDT())\n",
        "  def sum_vector(sparse_vectors, similarities):\n",
        "    similarities = np.array(similarities)\n",
        "    sparse_vectors = np.array(sparse_vectors)\n",
        "    acc = np.dot(sparse_vectors.T, similarities) #Compute the sum(vector * similarity) for each vector and similarity\n",
        "    acc /= similarities.sum() #Normalize the vector\n",
        "    acc -= (input_vector * acc) #If a song is present in the input playlist, don't consider it\n",
        "    return SparseVector(acc.size, np.nonzero(acc)[0], acc[np.nonzero(acc)])\n",
        "\n",
        "  return top_k_results.agg(sum_vector(F.collect_list('rating_vector'), F.collect_list(\"similarity\")).alias('summed'))\n",
        "\n",
        "if DEBUG:\n",
        "  t1 = time.time()\n",
        "  input_vector = first_playlist_vector.first()[0]\n",
        "  accumulated_vector_df = accumulate_top_k_results(top_k_results, input_vector)\n",
        "  accumulated_vector_df.cache()\n",
        "  accumulated_vector_df.show()\n",
        "  t2 = time.time()\n",
        "  print(t2-t1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "keTpUBIXTdHg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+----------+\n",
            "|   pos|confidence|\n",
            "+------+----------+\n",
            "|505626|0.86660594|\n",
            "|338046| 0.8451381|\n",
            "|256245| 0.8245531|\n",
            "|669595|0.81081593|\n",
            "|174330|0.78816617|\n",
            "|592258| 0.7713628|\n",
            "|589100| 0.7507684|\n",
            "|170221|0.73229903|\n",
            "| 87563| 0.7185418|\n",
            "|585110|0.71125495|\n",
            "+------+----------+\n",
            "\n",
            "0.3676290512084961\n"
          ]
        }
      ],
      "source": [
        "@F.udf(returnType=ArrayType(\n",
        "    StructType([\n",
        "      StructField(\"pos\", IntegerType(), False),\n",
        "      StructField(\"confidence\", FloatType(), False)\n",
        "])))\n",
        "def get_top_n_values(vector: SparseVector, n: int=10):\n",
        "  sorted_elements = vector.toArray().tolist()\n",
        "  top_n_indices = sorted(range(len(sorted_elements)), key=lambda i: sorted_elements[i], reverse=True)[:n]\n",
        "  return [(index, sorted_elements[index]) for index in top_n_indices]\n",
        "\n",
        "if DEBUG:\n",
        "  t1 = time.time()\n",
        "  top_n_reccomendations = accumulated_vector_df.withColumn(\"top_n_recommendations\", get_top_n_values(F.col(\"summed\"))).select(F.explode(\"top_n_recommendations\")).select(\"col.*\")\n",
        "  top_n_reccomendations.show()\n",
        "  t2 = time.time()\n",
        "  print(t2-t1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ZJOyep5RUMGV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+----------+--------------------+\n",
            "|   pos|confidence|           track_uri|\n",
            "+------+----------+--------------------+\n",
            "| 87563| 0.7185418|spotify:track:0qc...|\n",
            "|170221|0.73229903|spotify:track:6P3...|\n",
            "|174330|0.78816617|spotify:track:0qx...|\n",
            "|256245| 0.8245531|spotify:track:28U...|\n",
            "|338046| 0.8451381|spotify:track:5k3...|\n",
            "|505626|0.86660594|spotify:track:1OY...|\n",
            "|585110|0.71125495|spotify:track:2yi...|\n",
            "|589100| 0.7507684|spotify:track:70b...|\n",
            "|592258| 0.7713628|spotify:track:2AI...|\n",
            "|669595|0.81081593|spotify:track:0HU...|\n",
            "+------+----------+--------------------+\n",
            "\n",
            "1.0036489963531494\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "#TODO: For now this works, but it's very slow, and since this has to be executed online,\n",
        "# consider to directly embed the song information inside the dataframe when computing the songs\n",
        "# to recommend.\n",
        "@timeit\n",
        "def recommendation_song_info(recommendation: DataFrame, songs_info_df: DataFrame) -> DataFrame:\n",
        "  return recommendation.join(songs_info_df, \"pos\")\n",
        "\n",
        "if DEBUG:\n",
        "  t1 = time.time()\n",
        "  songs_info = recommendation_song_info(top_n_reccomendations, song_pos_mapping)\n",
        "  songs_info.show()\n",
        "  t2 = time.time()\n",
        "  print(t2-t1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CFmlqOAttu32"
      },
      "source": [
        "### Putting it all togheter\n",
        "We now define a single function that will get a playlist in input and will reccomend $n$ songs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "jfiQn5_rt827"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating rating vectors: 0.3389158248901367\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:36:45 WARN CacheManager: Asked to cache already cached data.\n",
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing similarity_df: 2.3518710136413574\n",
            "Getting top_k_results: 2.7671151161193848\n",
            "Getting the playlist's input vector: 1.2081599235534668\n",
            "Getting the top n indices: 0.06534123420715332\n",
            "Getting the reccomended_songs_info: 0.020317792892456055\n"
          ]
        }
      ],
      "source": [
        "#TODO: this now takes a playlist and extracts its PID, if a playlist is built from scratch the PID shouldn't be defined\n",
        "# A solution would be to pass the playlist row with the PID = Nan and then have a condition when extracting the PID. If Nan, ignore it\n",
        "@timeit\n",
        "def user_based_recommendation(playlist: DataFrame, \n",
        "                              mapped_slice_df: DataFrame, \n",
        "                              similarity_function: Callable, \n",
        "                              n:int = 50,\n",
        "                              k: int = 20) -> DataFrame:\n",
        "                              \n",
        "  rv_df = mapped_slice_df.withColumnRenamed(\"tracks\", \"rating_vector\").cache() #TODO: Parse the rv_df before and then remove this\n",
        "  #TODO: Try not to use this map_track_df_to_pos\n",
        "  playlist_vector = map_track_df_to_pos(playlist).select(\"tracks\").withColumnRenamed(\"tracks\", \"input_vector\").cache()\n",
        "  similarity_df = create_similarity_df(playlist_vector, rv_df, jaccard_similarity).cache()\n",
        "  top_k_results = get_top_k_results(playlist.first().pid, similarity_df, k=k).cache()\n",
        "  input_vector = playlist_vector.select(\"input_vector\").first()[0].toArray()\n",
        "  accumulated_vector_df = accumulate_top_k_results(top_k_results, input_vector).cache()\n",
        "  top_n_indices = accumulated_vector_df\\\n",
        "                  .withColumn(\"top_n_recommendations\", get_top_n_values(F.col(\"summed\")))\\\n",
        "                  .select(F.explode(\"top_n_recommendations\"))\\\n",
        "                  .select(\"col.*\").cache()\n",
        "  #TODO: songs_df because it's faster, but it doesn't get all the info.\n",
        "  recommended_songs_info = recommendation_song_info(top_n_indices, song_pos_mapping).cache() \n",
        "\n",
        "  playlist_vector.unpersist()\n",
        "  similarity_df.unpersist()\n",
        "  top_k_results.unpersist()\n",
        "  accumulated_vector_df.unpersist()\n",
        "  top_n_indices.unpersist()\n",
        "  return recommended_songs_info\n",
        "  \n",
        "\n",
        "if DEBUG:\n",
        "  #Collect and createDataFrame because operations on limit(1) take as long as the entire slice_df, don't know why\n",
        "  playlist = spark.createDataFrame(slice_df.filter(\"pid == 1010\").limit(1).collect())\n",
        "  final_recommendation = user_based_recommendation(playlist, songs_embeddings, jaccard_similarity, n=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+----------+--------------------+\n",
            "|   pos|confidence|           track_uri|\n",
            "+------+----------+--------------------+\n",
            "|   402|0.37936306|spotify:track:78W...|\n",
            "|255794|0.44066477|spotify:track:1Je...|\n",
            "|333588|0.45380837|spotify:track:3zB...|\n",
            "|416552|0.44611415|spotify:track:2Pp...|\n",
            "|417324|0.35038823|spotify:track:0XU...|\n",
            "|424672|0.44969997|spotify:track:5dN...|\n",
            "|497574|0.34576124|spotify:track:6uQ...|\n",
            "|500339| 0.4509231|spotify:track:5Rs...|\n",
            "|591490|0.45051354|spotify:track:6cb...|\n",
            "|669578| 0.4977322|spotify:track:4o6...|\n",
            "+------+----------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "final_recommendation.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eM7ErDxxt69B"
      },
      "source": [
        "## Performance Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "GaY6U3hajPVM"
      },
      "outputs": [],
      "source": [
        "TRAIN_DF_PATH = os.path.join(SAVED_DFS_PATH, f\"train_df-{NUM_PLAYLISTS}.json\")\n",
        "TEST_DF_PATH = os.path.join(SAVED_DFS_PATH, f\"test_df-{NUM_PLAYLISTS}.json\")\n",
        "train_df = spark.read.schema(playlist_schema).json(TRAIN_DF_PATH)\n",
        "test_df = spark.read.schema(playlist_schema).json(TEST_DF_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8ISUytekZvo",
        "outputId": "6e632731-a846-49ab-97a6-860f11aae64b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(100000, 100000)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# train_df.count(), test_df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-vEt0SPkqu_",
        "outputId": "413c6285-201b-4edd-ef87-2e3ed37104b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+-------------+----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "|         name|collaborative| pid|modified_at|num_tracks|num_albums|num_followers|              tracks|num_edits|duration_ms|num_artists|\n",
            "+-------------+-------------+----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "|       disney|        false|1000| 1457827200|       189|        16|            1|[{31, Daughters o...|        4|   31428282|         65|\n",
            "|Indie Electro|        false|1001| 1417824000|       165|        18|            2|[{117, Boards of ...|        2|   38241566|          8|\n",
            "|  jack & jack|        false|1002| 1465430400|        17|        14|            1|[{14, Jack & Jack...|        3|    3549358|          3|\n",
            "|        vibes|        false|1003| 1498435200|       225|       195|            2|[{119, PREP, spot...|       91|   51242585|        157|\n",
            "|        Indie|        false|1004| 1498608000|       165|       118|            1|[{117, LCD Sounds...|       74|   42601098|         92|\n",
            "|      college|        false|1005| 1504310400|        28|        26|            1|[{22, Kid Ink, sp...|        2|    5870710|         25|\n",
            "|    Summer 15|        false|1006| 1471996800|        80|        74|            2|[{9, Kygo, spotif...|       40|   19652753|         67|\n",
            "|    New music|        false|1007| 1509148800|        58|        48|            1|[{17, Kodak Black...|       20|   13158862|         38|\n",
            "|          Now|        false|1008| 1505692800|        84|        82|            3|[{30, Mullally, s...|       36|   18432208|         79|\n",
            "|         Jams|        false|1009| 1507680000|        41|        36|            1|[{12, Alabama Sha...|       25|    9413467|         31|\n",
            "|    Party Mix|        false|1010| 1464393600|        74|        72|            2|[{39, Stevie Wond...|       11|   17853470|         63|\n",
            "|         LOCO|        false|1011| 1491868800|        97|        90|           18|[{33, Fat Joe, sp...|       27|   20635206|         82|\n",
            "|   Bruno Mars|        false|1012| 1506211200|        18|         7|            1|[{13, Bruno Mars,...|        3|    3974946|          3|\n",
            "|       Breezy|        false|1013| 1490140800|        67|        55|            1|[{7, Jon Bellion,...|       42|   14724585|         45|\n",
            "|      Fall 16|        false|1014| 1496793600|        83|        64|            3|[{61, Kings of Le...|       27|   21004989|         49|\n",
            "|          SLO|        false|1015| 1498262400|        53|        32|            1|[{34, Todd Snider...|        3|   12136870|         19|\n",
            "|       BANGAZ|        false|1016| 1508716800|       198|       141|            1|[{185, Russ, spot...|      104|   43843897|         89|\n",
            "|  Piano Music|        false|1017| 1401148800|        29|        21|            1|[{26, Jennifer Th...|        5|    6992643|         12|\n",
            "|  Beach Music|        false|1018| 1492387200|       130|       106|           14|[{24, Zion & Lenn...|       27|   30811124|         70|\n",
            "|    Slow jamz|        false|1019| 1505779200|        43|        42|            1|[{27, Bone Thugs-...|       15|   11198025|         32|\n",
            "+-------------+-------------+----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-------------+-------------+----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "|         name|collaborative| pid|modified_at|num_tracks|num_albums|num_followers|              tracks|num_edits|duration_ms|num_artists|\n",
            "+-------------+-------------+----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "|       disney|        false|1000| 1457827200|       189|        16|            1|[{184, Various Ar...|        4|   31428282|         65|\n",
            "|Indie Electro|        false|1001| 1417824000|       165|        18|            2|[{135, Boards of ...|        2|   38241566|          8|\n",
            "|  jack & jack|        false|1002| 1465430400|        17|        14|            1|[{0, Jack & Jack,...|        3|    3549358|          3|\n",
            "|        vibes|        false|1003| 1498435200|       225|       195|            2|[{9, Marc E. Bass...|       91|   51242585|        157|\n",
            "|        Indie|        false|1004| 1498608000|       165|       118|            1|[{135, Fleet Foxe...|       74|   42601098|         92|\n",
            "|      college|        false|1005| 1504310400|        28|        26|            1|[{9, Kesha, spoti...|        2|    5870710|         25|\n",
            "|    Summer 15|        false|1006| 1471996800|        80|        74|            2|[{30, Jeremih, sp...|       40|   19652753|         67|\n",
            "|    New music|        false|1007| 1509148800|        58|        48|            1|[{0, Post Malone,...|       20|   13158862|         38|\n",
            "|          Now|        false|1008| 1505692800|        84|        82|            3|[{73, PredZ, spot...|       36|   18432208|         79|\n",
            "|         Jams|        false|1009| 1507680000|        41|        36|            1|[{24, Foster The ...|       25|    9413467|         31|\n",
            "|    Party Mix|        false|1010| 1464393600|        74|        72|            2|[{4, The Killers,...|       11|   17853470|         63|\n",
            "|         LOCO|        false|1011| 1491868800|        97|        90|           18|[{62, Boostee, sp...|       27|   20635206|         82|\n",
            "|   Bruno Mars|        false|1012| 1506211200|        18|         7|            1|[{0, Bruno Mars, ...|        3|    3974946|          3|\n",
            "|       Breezy|        false|1013| 1490140800|        67|        55|            1|[{36, Troye Sivan...|       42|   14724585|         45|\n",
            "|      Fall 16|        false|1014| 1496793600|        83|        64|            3|[{30, The Arcs, s...|       27|   21004989|         49|\n",
            "|          SLO|        false|1015| 1498262400|        53|        32|            1|[{19, Bruce Sprin...|        3|   12136870|         19|\n",
            "|       BANGAZ|        false|1016| 1508716800|       198|       141|            1|[{65, Young Thug,...|      104|   43843897|         89|\n",
            "|  Piano Music|        false|1017| 1401148800|        29|        21|            1|[{27, Jennifer Th...|        5|    6992643|         12|\n",
            "|  Beach Music|        false|1018| 1492387200|       130|       106|           14|[{55, Héctor \"El ...|       27|   30811124|         70|\n",
            "|    Slow jamz|        false|1019| 1505779200|        43|        42|            1|[{37, R. Kelly, s...|       15|   11198025|         32|\n",
            "+-------------+-------------+----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# train_df.show(), test_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "86dFBXK20uqu"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "@timeit\n",
        "def precision_at_k(recommendations, ground_truth, num_of_recommendations) -> float:\n",
        "    \"\"\"\n",
        "    Calculates precision at k for the recommendations.\n",
        "    \"\"\"\n",
        "    recommended_relevant_tracks = recommendations.join(ground_truth, \"track_uri\").cache()\n",
        "    reccomended_relevant_tracks_count = recommended_relevant_tracks.count() #this can be top_n_results.join in order to be more performant\n",
        "    recommended_relevant_tracks.unpersist()\n",
        "    precision = reccomended_relevant_tracks_count / float(num_of_recommendations)\n",
        "\n",
        "    return precision\n",
        "\n",
        "\n",
        "import math\n",
        "def normalized_discounted_cumulative_gain(recommendations: DataFrame, ground_truth: DataFrame, num_of_recommendations: int) -> float:\n",
        "  recommendations = recommendations.orderBy(F.col(\"confidence\").desc())\n",
        "  recommendations_list = recommendations.collect()\n",
        "  cumulative_gain = 0\n",
        "\n",
        "  intersection = recommendations.join(ground_truth, \"track_uri\").count()\n",
        "  if intersection == 0: return 0\n",
        "\n",
        "  ideal_cumulative_gain = 1 + np.array([(1 / math.log(i, 2)) for i in range(2, 2+intersection)]).sum() #TODO: replace this with sum([])\n",
        "  for index, row in enumerate(recommendations_list):\n",
        "    i = index + 1\n",
        "    is_rel = ground_truth.filter(F.col(\"track_uri\").isin(row.track_uri)).count() > 0\n",
        "    rel = 1 if is_rel else 0\n",
        "    if i == 1:\n",
        "      cumulative_gain += rel\n",
        "    else:\n",
        "      cumulative_gain += (rel / math.log(i, 2))\n",
        "  return cumulative_gain / ideal_cumulative_gain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "J8kbN-2Emdmz"
      },
      "outputs": [],
      "source": [
        "@timeit\n",
        "def evaluate(pid: int) -> Tuple[DataFrame, float]:\n",
        "    playlist_train = train_df.filter(f\"pid == {pid}\").cache()\n",
        "    playlist_test = test_df.filter(f\"pid == {pid}\").cache()\n",
        "    ground_truth = playlist_test.select(F.explode(\"tracks\")).select(\"col.*\").cache()\n",
        "    #TODO: This can be remove by inserting the number of songs when creating the train and test df\n",
        "    num_of_recommendations = ground_truth.count()\n",
        "    recommendations = user_based_recommendation(playlist_train, \n",
        "                                                songs_embeddings, \n",
        "                                                jaccard_similarity, \n",
        "                                                n=num_of_recommendations,\n",
        "                                                k = 10).cache()\n",
        "    precision = precision_at_k(recommendations, ground_truth, num_of_recommendations)\n",
        "    gain = normalized_discounted_cumulative_gain(recommendations, ground_truth, num_of_recommendations)\n",
        "\n",
        "    playlist_train.unpersist()\n",
        "    playlist_test.unpersist()\n",
        "    ground_truth.unpersist()\n",
        "    return playlist_train, playlist_test, ground_truth, recommendations, precision, gain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLluNZXYIFk7",
        "outputId": "89f57767-8f7c-4a0c-b214-d6b5a83c36b3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:37:25 WARN CacheManager: Asked to cache already cached data.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating rating vectors: 0.4294600486755371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:37:25 WARN CacheManager: Asked to cache already cached data.\n",
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing similarity_df: 3.1668317317962646\n",
            "Getting top_k_results: 3.326906681060791\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting the playlist's input vector: 2.7075142860412598\n",
            "Getting the top n indices: 0.130018949508667\n",
            "Getting the reccomended_songs_info: 0.0507967472076416\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:37:32 WARN CacheManager: Asked to cache already cached data.\n",
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total time: 28.260274171829224\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.14814814814814814, 0.49528491839179634)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train, test, gt, rec, prec, gain = evaluate(47264)\n",
        "prec, gain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Kz6ghaOixXU4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------+-------------+-----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "|          name|collaborative|  pid|modified_at|num_tracks|num_albums|num_followers|              tracks|num_edits|duration_ms|num_artists|\n",
            "+--------------+-------------+-----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "|all the way up|        false|47264| 1484784000|       106|        91|            8|[{73, Kevin Gates...|       45|   23079971|         71|\n",
            "+--------------+-------------+-----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "\n",
            "+--------------+-------------+-----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "|          name|collaborative|  pid|modified_at|num_tracks|num_albums|num_followers|              tracks|num_edits|duration_ms|num_artists|\n",
            "+--------------+-------------+-----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "|all the way up|        false|47264| 1484784000|       106|        91|            8|[{100, Selena Gom...|       45|   23079971|         71|\n",
            "+--------------+-------------+-----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "\n",
            "+------+----------+--------------------+\n",
            "|   pos|confidence|           track_uri|\n",
            "+------+----------+--------------------+\n",
            "| 86708|0.59157133|spotify:track:2Qb...|\n",
            "|166911| 0.5107924|spotify:track:1vv...|\n",
            "|171801| 0.6026541|spotify:track:1Tt...|\n",
            "|172181|0.51527154|spotify:track:343...|\n",
            "|331536| 0.7074116|spotify:track:5aA...|\n",
            "|415741|0.50389534|spotify:track:7yC...|\n",
            "|417723| 0.5064138|spotify:track:7yy...|\n",
            "|418490| 0.6003173|spotify:track:0Qs...|\n",
            "|504717|0.60213315|spotify:track:4Hf...|\n",
            "|592619| 0.5064138|spotify:track:5hT...|\n",
            "+------+----------+--------------------+\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(None, None, None, 0.14814814814814814)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.show(), test.show(), rec.show(), prec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "CEJCTq-eqJyk"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "337510f0f3a34b2d8bedd114ab832875",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Performing evaluation:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:45:04 WARN CacheManager: Asked to cache already cached data.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating rating vectors: 0.5889122486114502\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:45:04 WARN CacheManager: Asked to cache already cached data.\n",
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing similarity_df: 1.9946949481964111\n",
            "Getting top_k_results: 2.081190824508667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting the playlist's input vector: 1.7408912181854248\n",
            "Getting the top n indices: 0.14092803001403809\n",
            "Getting the reccomended_songs_info: 0.01810479164123535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:45:08 WARN CacheManager: Asked to cache already cached data.\n",
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total time: 22.711556911468506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:45:27 WARN CacheManager: Asked to cache already cached data.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating rating vectors: 0.5471527576446533\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:45:27 WARN CacheManager: Asked to cache already cached data.\n",
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing similarity_df: 1.2961370944976807\n",
            "Getting top_k_results: 1.3294332027435303\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting the playlist's input vector: 1.0208487510681152\n",
            "Getting the top n indices: 0.05796313285827637\n",
            "Getting the reccomended_songs_info: 0.010725021362304688\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:45:30 WARN CacheManager: Asked to cache already cached data.\n",
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total time: 19.990849018096924\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:45:47 WARN CacheManager: Asked to cache already cached data.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating rating vectors: 0.37842369079589844\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:45:48 WARN CacheManager: Asked to cache already cached data.\n",
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing similarity_df: 1.2348601818084717\n",
            "Getting top_k_results: 1.2761881351470947\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting the playlist's input vector: 1.0355291366577148\n",
            "Getting the top n indices: 0.06665396690368652\n",
            "Getting the reccomended_songs_info: 0.019361019134521484\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:45:50 WARN CacheManager: Asked to cache already cached data.\n",
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total time: 23.85125207901001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:46:12 WARN CacheManager: Asked to cache already cached data.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating rating vectors: 0.5056109428405762\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:46:12 WARN CacheManager: Asked to cache already cached data.\n",
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing similarity_df: 4.174385070800781\n",
            "Getting top_k_results: 4.268749952316284\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting the playlist's input vector: 3.195374011993408\n",
            "Getting the top n indices: 0.19579100608825684\n",
            "Getting the reccomended_songs_info: 0.03510904312133789\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:46:20 WARN CacheManager: Asked to cache already cached data.\n",
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total time: 28.603249073028564\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:46:42 WARN CacheManager: Asked to cache already cached data.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating rating vectors: 0.49161386489868164\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:46:42 WARN CacheManager: Asked to cache already cached data.\n",
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing similarity_df: 4.09291410446167\n",
            "Getting top_k_results: 4.203598976135254\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting the playlist's input vector: 3.019865036010742\n",
            "Getting the top n indices: 0.24603486061096191\n",
            "Getting the reccomended_songs_info: 0.025109052658081055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:46:50 WARN CacheManager: Asked to cache already cached data.\n",
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total time: 25.962573051452637\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:47:08 WARN CacheManager: Asked to cache already cached data.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating rating vectors: 0.38521599769592285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:47:08 WARN CacheManager: Asked to cache already cached data.\n",
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing similarity_df: 3.154144048690796\n",
            "Getting top_k_results: 3.22196102142334\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting the playlist's input vector: 2.4859459400177\n",
            "Getting the top n indices: 0.10286116600036621\n",
            "Getting the reccomended_songs_info: 0.016600847244262695\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:47:14 WARN CacheManager: Asked to cache already cached data.\n",
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total time: 24.216420650482178\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:47:33 WARN CacheManager: Asked to cache already cached data.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating rating vectors: 0.4311859607696533\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:47:33 WARN CacheManager: Asked to cache already cached data.\n",
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing similarity_df: 4.868103981018066\n",
            "Getting top_k_results: 4.940645933151245\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:47:40 WARN CacheManager: Asked to cache already cached data.        \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting the playlist's input vector: 2.320175886154175\n",
            "Getting the top n indices: 0.05518221855163574\n",
            "Getting the reccomended_songs_info: 0.011857032775878906\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total time: 27.15517282485962\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:48:00 WARN CacheManager: Asked to cache already cached data.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating rating vectors: 0.4046962261199951\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:48:01 WARN CacheManager: Asked to cache already cached data.\n",
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing similarity_df: 3.424952983856201\n",
            "Getting top_k_results: 3.4794199466705322\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting the playlist's input vector: 2.6219921112060547\n",
            "Getting the top n indices: 0.1208488941192627\n",
            "Getting the reccomended_songs_info: 0.01769280433654785\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/22 19:48:07 WARN CacheManager: Asked to cache already cached data.\n",
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total time: 26.437735319137573\n"
          ]
        }
      ],
      "source": [
        "EVALUATION_RESULTS_PATH = os.path.join(GDRIVE_DATA_DIR, \"UB_evaluation_results_FINAL\")\n",
        "def perform_evaluation():\n",
        "  SAMPLING_FRACTION = 0.01\n",
        "  sampled_playlists = train_df.sample(False, SAMPLING_FRACTION, seed=42).cache()\n",
        "\n",
        "  results = []\n",
        "  for index, row in enumerate(tqdm(sampled_playlists.collect(), desc=\"Performing evaluation\")):\n",
        "      CHECKPOINT_RESULTS = os.path.join(GDRIVE_DATA_DIR, f\"UB_evaluation_results_check_{index}\")\n",
        "      pid = row['pid']\n",
        "      train, test, gt, rec, prec, gain = evaluate(pid)\n",
        "      results.append((prec, gain))\n",
        "      if index % 10 == 0:\n",
        "         with open(CHECKPOINT_RESULTS, \"w\") as f:\n",
        "            json.dump(results, f)\n",
        "  with open(EVALUATION_RESULTS_PATH, \"w\") as f:\n",
        "    json.dump(results, f)\n",
        "  \n",
        "  sampled_playlists.unpersist()\n",
        "  return results\n",
        "\n",
        "\n",
        "results = perform_evaluation()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYvIrTvqfrzZ",
        "outputId": "1fe047e4-1352-434f-efc1-7d77293c6277"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.14186958874458874, 0.37676438321859024)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "avg_prec = np.array(results).mean()\n",
        "avg_prec, avg_gain = 0, 0\n",
        "for prec, gain in results:\n",
        "  avg_prec += prec\n",
        "  avg_gain += gain \n",
        "tot = len(results)\n",
        "avg_prec /= tot\n",
        "avg_gain /= tot\n",
        "avg_prec, avg_gain"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SqlejJ_MFrB9"
      },
      "source": [
        "# Fighting against the curse of dimensionality: Matrix Factorization"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gnioMF6_KGfr"
      },
      "source": [
        "We want to define $\\mathbf{x}_u \\in \\mathbb{R}^d$ $d$-dimensional vector that represents the user $u$, and $\\mathbf{w}_i \\in \\mathbb{R}^d$ vector that represent the item $i$.\n",
        "\n",
        "We then can estimate the rating of user $u$ for the item $i$ by computing\n",
        "\\begin{equation}\n",
        "\\hat{r}_{u, i}=\\mathbf{x}_u^T \\cdot \\mathbf{w}_i=\\sum_{j=1}^d x_{u, j} w_{j, i}\n",
        "\\end{equation}\n",
        "Or, in matrix notation,\n",
        "\n",
        "\\begin{equation}\n",
        "\\underbrace{R}_{m \\times n} =\n",
        "\\underbrace{X}_{m \\times d}\n",
        "\\underbrace{W^T}_{d \\times n}\n",
        "\\end{equation}\n",
        "\n",
        "### How to learn $X$ and $W$\n",
        "The matrix $R$ is partially known and filled with the observations inside the dataset $\\mathcal{D}$. In order to learn the latent factor representations $X$ and $W$, we minimize the following loss function:\n",
        "\\begin{equation}\n",
        "L(X, W)=\\sum_{(u, i) \\in \\mathcal{D}}\\underbrace{\\left(r_{u, i}-\\mathbf{x}_u^T \\cdot \\mathbf{w}_i\\right)^2}_{\\text{squared error term}}+\\underbrace{\\lambda\\left(\\sum_{u \\in \\mathcal{D}}\\left\\|\\mathbf{x}_u\\right\\|^2+\\sum_{i \\in \\mathcal{D}}\\left\\|\\mathbf{w}_i\\right\\|^2\\right)}_{\\text{regularization term}}\n",
        "\\end{equation}\n",
        "\n",
        "We can then minimize the loss using Stochastic Gradient Descent or Alternating Least Squares."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "el7BsOEsjSgN"
      },
      "source": [
        "# Matrix Factorization\n",
        "Generate a matrix Y where each column represent a playlist and each row represent a song, the (i,j) entry will be 1 if the playlist contains the song, 0 otherwise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KsENF4IfRks"
      },
      "outputs": [],
      "source": [
        "# Throw error in order to not execute the following code\n",
        "raise ValueError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1PEWA1Xjbb2"
      },
      "outputs": [],
      "source": [
        "import pyspark.sql.functions as f\n",
        "from pyspark.sql.functions import explode\n",
        "spark.conf.set(\"spark.sql.pivotMaxValues\", 1000000)\n",
        "\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.functions import expr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCEit6ZXgClg"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import explode\n",
        "import random\n",
        "tracks_df = slice_df.select(\"pid\", explode(\"tracks\").alias(\"track\")).select(\"pid\", \"track.track_uri\")\n",
        "tracks_df = tracks_df.withColumn(\"rating\", lit(1))\n",
        "# tracks_df = tracks_df.withColumn(\"rating\", (rand() * 10 + 1).cast(\"integer\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzl4_KPigJyN"
      },
      "outputs": [],
      "source": [
        "tracks_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrNo-NacpGXC"
      },
      "outputs": [],
      "source": [
        "# # Explode the tracks array column into multiple rows\n",
        "# # tracks_df = slice_df.select(\"pid\", explode(\"tracks\").alias(\"track\"))\n",
        "# # tracks_df = slice_df.select(\"pid\", \"tracks\", \"tracks\")\n",
        "# tracks_df = slice_df.select(\"pid\", explode(\"tracks\").alias(\"track\")).select(\"pid\", \"track.track_uri\", \"track.pos\")\n",
        "\n",
        "# # Select relevant columns and add a rating column with value 1\n",
        "# playlist_track_df = tracks_df.withColumn(\"rating\", lit(1))\n",
        "\n",
        "# # Get distinct track_uri values and join with playlist_track_df\n",
        "# all_tracks_df = slice_df.select(explode(\"tracks\").alias(\"track\")).select(\"track.track_uri\").distinct()\n",
        "# all_playlists_df = slice_df.select(\"pid\").distinct()\n",
        "\n",
        "# all_against_all = all_tracks_df.join(all_playlists_df).distinct()\n",
        "\n",
        "# from pyspark.sql.functions import when, col\n",
        "\n",
        "# # playlist_track_rating_df = playlist_track_df.join(all_against_all, [\"pid\", \"track_uri\"], \"left_outer\") \\\n",
        "# #     .withColumn(\"rating\", when(col(\"pos\").isNull(), 0).otherwise(1))\n",
        "\n",
        "# playlist_track_rating_df = all_against_all.join(playlist_track_df, [\"pid\", \"track_uri\"], \"left_outer\") \\\n",
        "#     .withColumn(\"rating\", when(col(\"pos\").isNull(), 0).otherwise(1)) \\\n",
        "#     .drop(\"pos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_g71QpbzP9G"
      },
      "outputs": [],
      "source": [
        "playlist_track_rating_df = tracks_df.withColumn(\"song_id\", dense_rank().over(Window.orderBy(\"track_uri\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFR59iIwsuAv"
      },
      "outputs": [],
      "source": [
        "playlist_track_rating_df.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0E86sNXYxTJP"
      },
      "outputs": [],
      "source": [
        "als = ALS(userCol=\"pid\", itemCol=\"song_id\", ratingCol=\"rating\", nonnegative=True, coldStartStrategy=\"drop\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKxgkuM0GsVf"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "import random\n",
        "\n",
        "def train_test_split(df: DataFrame, split_ratio: float, seed: Optional[int] = None) -> Tuple[DataFrame, DataFrame]:\n",
        "  random.seed(seed)\n",
        "  distinct_pids = df.select(\"pid\").distinct().rdd.map(lambda x: x[0]).collect()\n",
        "  random.shuffle(distinct_pids)\n",
        "  split_index = int(len(distinct_pids) * split_ratio)\n",
        "  train_pids = distinct_pids[:split_index]\n",
        "  test_pids = distinct_pids[split_index:]\n",
        "  train_df = df.filter(col(\"pid\").isin(train_pids))\n",
        "  test_df = df.filter(col(\"pid\").isin(test_pids))\n",
        "  return train_df, test_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pf82Hstmxb7i"
      },
      "outputs": [],
      "source": [
        "training, test = playlist_track_rating_df.randomSplit([0.8, 0.2], seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5r0g7uPzH19c"
      },
      "outputs": [],
      "source": [
        "model = als.fit(training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_S3oNC7AIFXY"
      },
      "outputs": [],
      "source": [
        "predictions = model.transform(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwciStIaibF-"
      },
      "outputs": [],
      "source": [
        "predictions.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_FWXza9ycMU"
      },
      "outputs": [],
      "source": [
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
        "                                predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJfWDUMSh8Nd"
      },
      "outputs": [],
      "source": [
        "predictions.filter(col(\"prediction\") != \"NaN\").count(), predictions.filter(col(\"prediction\") == \"NaN\").count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47oQcRQdm-qy"
      },
      "outputs": [],
      "source": [
        "rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2eoCHXqLNU8"
      },
      "outputs": [],
      "source": [
        "subset = playlist_track_rating_df.select(\"pid\").distinct().limit(1)\n",
        "subUserRecs = model.recommendForUserSubset(subset, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tya3FyOxLn0S"
      },
      "outputs": [],
      "source": [
        "subset.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5lfCDhiLZjo"
      },
      "outputs": [],
      "source": [
        "subUserRecs.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyvBEVF8MP30"
      },
      "outputs": [],
      "source": [
        "def song_name_from_id(song_id: int, reverse_lookup: DataFrame) -> str:\n",
        "  return \n",
        "  \n",
        "def interpretRecommendation(recommended_result: DataFrame) -> str:\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMvzQsXnykMX"
      },
      "outputs": [],
      "source": [
        "userRecs = model.recommendForAllUsers(1).orderBy(\"recommendations\")\n",
        "userRecs.show(truncate=False)\n",
        "userRecs.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKrGgg35mjmS"
      },
      "outputs": [],
      "source": [
        "slice_df.filter(col(\"pid\") == 1710).select(explode(\"tracks.track_name\")).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mF1ERfgmyFU"
      },
      "outputs": [],
      "source": [
        "track_uris = playlist_track_rating_df.filter(col(\"song_id\") == 588).select(\"track_uri\")\n",
        "track_uris.first()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "VJeY9PpvaHUJ",
        "SqlejJ_MFrB9",
        "el7BsOEsjSgN"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
