{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DomizianoScarcelli/big-data-project/blob/nn-model/user_based_CF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KOojFseRjVnN"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we configure the environment. Since I alternated from Google Colab to Local development, I define a LOCAL variable that allows me to know in which environment I am. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "def is_running_on_colab():\n",
        "    return \"COLAB_GPU\" in os.environ\n",
        "\n",
        "LOCAL = not is_running_on_colab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3wVgRfHYoOs",
        "outputId": "dcb30a00-e042-4c4e-e4f0-95951f55460e"
      },
      "outputs": [],
      "source": [
        "#@title Download necessary libraries\n",
        "if not LOCAL:\n",
        "    !pip install pyspark -qq\n",
        "    !pip install -U -q PyDrive -qq\n",
        "    !apt install openjdk-8-jdk-headless -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "id": "CGHPv9OqY9MI"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "import numpy as np\n",
        "import json\n",
        "import time\n",
        "import math\n",
        "import sys\n",
        "\n",
        "\n",
        "import pyspark\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql import SparkSession, DataFrame\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType, FloatType, LongType\n",
        "from pyspark import SparkConf\n",
        "from pyspark.ml.linalg import SparseVector, VectorUDT\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "if not LOCAL:\n",
        "    from google.colab import drive\n",
        "\n",
        "from typing import Tuple, Callable, List\n",
        "from functools import reduce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JF8LUBZeYiWP"
      },
      "outputs": [],
      "source": [
        "#@title Set up variables\n",
        "if not LOCAL:\n",
        "    JAVA_HOME = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "    GDRIVE_DIR = \"/content/drive\"\n",
        "    GDRIVE_HOME_DIR = GDRIVE_DIR + \"/MyDrive\"\n",
        "    GDRIVE_DATA_DIR = GDRIVE_HOME_DIR + \"/Big Data/datasets\"\n",
        "    DATASET_FILE = os.path.join(GDRIVE_DATA_DIR, \"pyspark_friendly_spotify_playlist_dataset\")\n",
        "    AUDIO_FEATURES_FILE = os.path.join(GDRIVE_DATA_DIR, \"pyspark_track_features\")\n",
        "    LITTLE_SLICE_FILE = os.path.join(GDRIVE_DATA_DIR, \"little_slice\")\n",
        "    SMALL_SLICE_FLIE = os.path.join(GDRIVE_DATA_DIR, \"small_slice\")\n",
        "    LITTLE_SLICE_AUDIO_FEATURES = os.path.join(GDRIVE_DATA_DIR, \"little_slice_audio_features\")\n",
        "    MICRO_SLICE_AUDIO_FEATURES = os.path.join(GDRIVE_DATA_DIR, \"micro_slice_audio_features\")\n",
        "    SPLITTED_SLICE_AUDIO_FEATURES = os.path.join(GDRIVE_DATA_DIR, \"splitted_pyspark_track_features\")\n",
        "    SAVED_DFS_PATH = os.path.join(GDRIVE_DATA_DIR, \"saved_dfs\")\n",
        "    SAVED_MODELS = os.path.join(GDRIVE_DATA_DIR, \"saved_models\")\n",
        "    EVALUATION_FOLDER = os.path.jon(GDRIVE_DATA_DIR, \"evaluation\", \"user_base_evaluation\")\n",
        "else:\n",
        "    GDRIVE_DATA_DIR = os.path.abspath(\"./data\")\n",
        "    SAVED_DFS_PATH = os.path.join(GDRIVE_DATA_DIR, \"saved_dfs\")\n",
        "    SAVED_MODELS = os.path.join(GDRIVE_DATA_DIR, \"saved_models\")\n",
        "    DATASET_FILE = os.path.join(GDRIVE_DATA_DIR, \"full_dataset\")\n",
        "    SMALL_SLICE_FLIE = os.path.join(GDRIVE_DATA_DIR, \"small_slice\")\n",
        "    EVALUATION_FOLDER = os.path.join(os.path.abspath(\"./evaluation\"), \"user_base_evaluation\")\n",
        "\n",
        "    JAVA_HOME = \"/opt/homebrew/opt/openjdk\"\n",
        "RANDOM_SEED = 42 # for reproducibility\n",
        "os.environ[\"JAVA_HOME\"] = JAVA_HOME\n",
        "os.environ[\"PYSPARK_PYTHON\"]=\"python\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "id": "4m7VztzdZgm6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/30 19:30:23 WARN Utils: Your hostname, MacBook-Air-di-Domiziano.local resolves to a loopback address: 127.0.0.1; using 192.168.1.175 instead (on interface en0)\n",
            "23/06/30 19:30:23 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "23/06/30 19:30:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "23/06/30 19:30:24 WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting port 4051.\n",
            "23/06/30 19:30:24 WARN Utils: Service 'SparkUI' could not bind on port 4051. Attempting port 4052.\n",
            "23/06/30 19:30:24 WARN Utils: Service 'SparkUI' could not bind on port 4052. Attempting port 4053.\n"
          ]
        }
      ],
      "source": [
        "#@title Create the session\n",
        "conf = SparkConf().\\\n",
        "                set('spark.ui.port', \"4050\").\\\n",
        "                set('spark.executor.memory', '12G').\\\n",
        "                set('spark.driver.memory', '12G').\\\n",
        "                set('spark.driver.maxResultSize', '100G').\\\n",
        "                set(\"spark.executor.extraJavaOptions\", \"-XX:+UseG1GC\").\\\n",
        "                setAppName(\"PySparkTutorial\").\\\n",
        "                setMaster(\"local[*]\")\n",
        "\n",
        "# Create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsX5d-YXZ2Ul",
        "outputId": "5a5dd440-edea-47ea-f469-9a4f043335c5"
      },
      "outputs": [],
      "source": [
        "if not LOCAL:\n",
        "    drive.mount(GDRIVE_DIR, force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlxfJiBSZ6ju",
        "outputId": "bc4c8bba-256b-4b45-d45d-166d9a5460ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<pyspark.sql.session.SparkSession at 0x107968670>,\n",
              " [('spark.executor.extraJavaOptions',\n",
              "   '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false -XX:+UseG1GC'),\n",
              "  ('spark.app.name', 'PySparkTutorial'),\n",
              "  ('spark.driver.host', '192.168.1.175'),\n",
              "  ('spark.app.id', 'local-1688146224475'),\n",
              "  ('spark.executor.id', 'driver'),\n",
              "  ('spark.driver.extraJavaOptions',\n",
              "   '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false'),\n",
              "  ('spark.ui.port', '4050'),\n",
              "  ('spark.driver.port', '51199'),\n",
              "  ('spark.rdd.compress', 'True'),\n",
              "  ('spark.driver.memory', '12G'),\n",
              "  ('spark.serializer.objectStreamReset', '100'),\n",
              "  ('spark.master', 'local[*]'),\n",
              "  ('spark.submit.pyFiles', ''),\n",
              "  ('spark.driver.maxResultSize', '100G'),\n",
              "  ('spark.submit.deployMode', 'client'),\n",
              "  ('spark.app.submitTime', '1688146223789'),\n",
              "  ('spark.executor.memory', '12G'),\n",
              "  ('spark.ui.showConsoleProgress', 'true'),\n",
              "  ('spark.app.startTime', '1688146223889')])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@title Check if everything is ok\n",
        "spark, sc._conf.getAll()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VJeY9PpvaHUJ"
      },
      "source": [
        "# Load DataFrame"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the `DataFrame` schemas and load the primary `DataFrame`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "icd2lj-RRvhU"
      },
      "outputs": [],
      "source": [
        "song_schema = StructType([\n",
        "    StructField(\"pos\", IntegerType(), True),\n",
        "    StructField(\"artist_name\", StringType(), True),\n",
        "    StructField(\"track_uri\", StringType(), True),\n",
        "    StructField(\"artist_uri\", StringType(), True),\n",
        "    StructField(\"track_name\", StringType(), True),\n",
        "    StructField(\"album_uri\", StringType(), True),\n",
        "    StructField(\"duration_ms\", LongType(), True),\n",
        "    StructField(\"album_name\", StringType(), True)\n",
        "])\n",
        "\n",
        "playlist_schema = StructType([\n",
        "    StructField(\"name\", StringType(), True),\n",
        "    StructField(\"collaborative\", StringType(), True),\n",
        "    StructField(\"pid\", IntegerType(), True),\n",
        "    StructField(\"modified_at\", IntegerType(), True),\n",
        "    StructField(\"num_tracks\", IntegerType(), True),\n",
        "    StructField(\"num_albums\", IntegerType(), True),\n",
        "    StructField(\"num_followers\", IntegerType(), True),\n",
        "    StructField(\"tracks\", ArrayType(song_schema), True),\n",
        "    StructField(\"num_edits\", IntegerType(), True),\n",
        "    StructField(\"duration_ms\", IntegerType(), True),\n",
        "    StructField(\"num_artists\", IntegerType(), True),\n",
        "])\n",
        "\n",
        "playlist_schema_mapped = StructType([\n",
        "    StructField(\"name\", StringType(), True),\n",
        "    StructField(\"collaborative\", StringType(), True),\n",
        "    StructField(\"pid\", IntegerType(), True),\n",
        "    StructField(\"modified_at\", IntegerType(), True),\n",
        "    StructField(\"num_tracks\", IntegerType(), True),\n",
        "    StructField(\"num_albums\", IntegerType(), True),\n",
        "    StructField(\"num_followers\", IntegerType(), True),\n",
        "    StructField(\"tracks\", VectorUDT(), True),\n",
        "    StructField(\"num_edits\", IntegerType(), True),\n",
        "    StructField(\"duration_ms\", IntegerType(), True),\n",
        "    StructField(\"num_artists\", IntegerType(), True),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BY_szFyLTps4"
      },
      "outputs": [],
      "source": [
        "slice_df = spark.read.schema(playlist_schema).json(SMALL_SLICE_FLIE, multiLine=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WaSyTUepySNu"
      },
      "source": [
        "# User-Based Collaborative Filtering\n",
        "Note: The users are the playlists, the items are the songs and the ratings are 0 if the song is not in the playlist, 1 otherwise.\n",
        "\n",
        "We have to define a function $sim(u,v)$ that defines the similarity between two users based on their ratings.\n",
        "\n",
        "We represent the ratings $r_u \\in \\mathbb{R}^n$ as the $n$ dimensional vector that represents the ratings of the user $u$, where $n$ is the number of total songs in the dataset.\n",
        "\n",
        "As the similarity function we can use Jaccard similarity.\n",
        "\\begin{equation}\n",
        "sim(u,v) = J(r_u, r_v) = \\frac{|r_u \\cap r_v|}{|r_u \\cup r_v|}\n",
        "\\end{equation}\n",
        "\n",
        "Jaccard similarity ignores rating values, but we don't care here since the ratings are binary. In case of discrete value ratings we can use cosine similarity, or better pearson's correlation.\n",
        "\n",
        "Done that, and defined as ${U^k}$ the neighborhood of $u$ ($k$ most similar users to $u$), we define the set of items rated by $u$'s neighborhood as\n",
        "\n",
        "\\begin{equation}\n",
        "I^k = \\{i \\in I : \\mathbf{r_{u,i}} \\downarrow \\land u \\in U^k\\}\n",
        "\\end{equation}\n",
        "\n",
        "The rating for the item $i$ to the user $u$ will just be $\\mathbf{r_u[i]}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dawV4e6yOCo4"
      },
      "outputs": [],
      "source": [
        "DEBUG = True #If True, execute code that helps to debug the code"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's load the song embedding encodings, and the `DataFrame` that maps each song to a position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Ym9TWjvkGGOa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/30 19:30:36 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
          ]
        }
      ],
      "source": [
        "NUM_PLAYLISTS = 100_000\n",
        "SONGS_EMBEDDINGS_PATH = os.path.join(SAVED_DFS_PATH, f\"songs_embeddings-{NUM_PLAYLISTS}.json\")\n",
        "SONGS_INFO_DF = os.path.join(SAVED_DFS_PATH, f\"songs_info_df-{NUM_PLAYLISTS}.json\") #TODO: Little bug this is songs_df, meaning it hasn't got any info, but we don't actually care.\n",
        "RATING_VECTOR_LENGTH_PATH = os.path.join(SAVED_DFS_PATH, f\"songs_vector_length-{NUM_PLAYLISTS}.txt\")\n",
        "with open(RATING_VECTOR_LENGTH_PATH, \"r\") as f:\n",
        "  RATING_VECTOR_LENGTH = int(f.read())\n",
        "\n",
        "songs_embeddings = spark.read.schema(playlist_schema_mapped).json(SONGS_EMBEDDINGS_PATH)\n",
        "song_pos_mapping = spark.read.json(SONGS_INFO_DF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9n1ed0ryz3m",
        "outputId": "134d7eb5-40a2-4c5c-80b8-34c477451d9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+-------------+----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "|         name|collaborative| pid|modified_at|num_tracks|num_albums|num_followers|              tracks|num_edits|duration_ms|num_artists|\n",
            "+-------------+-------------+----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "|       disney|        false|1000| 1457827200|       189|        16|            1|(681805,[126,1903...|        4|   31428282|         65|\n",
            "|Indie Electro|        false|1001| 1417824000|       165|        18|            2|(681805,[17322,18...|        2|   38241566|          8|\n",
            "|  jack & jack|        false|1002| 1465430400|        17|        14|            1|(681805,[4591,952...|        3|    3549358|          3|\n",
            "|        vibes|        false|1003| 1498435200|       225|       195|            2|(681805,[392,431,...|       91|   51242585|        157|\n",
            "|        Indie|        false|1004| 1498608000|       165|       118|            1|(681805,[196,425,...|       74|   42601098|         92|\n",
            "|      college|        false|1005| 1504310400|        28|        26|            1|(681805,[899,6937...|        2|    5870710|         25|\n",
            "|    Summer 15|        false|1006| 1471996800|        80|        74|            2|(681805,[1221,351...|       40|   19652753|         67|\n",
            "|    New music|        false|1007| 1509148800|        58|        48|            1|(681805,[1070,207...|       20|   13158862|         38|\n",
            "|          Now|        false|1008| 1505692800|        84|        82|            3|(681805,[1709,371...|       36|   18432208|         79|\n",
            "|         Jams|        false|1009| 1507680000|        41|        36|            1|(681805,[82584,83...|       25|    9413467|         31|\n",
            "|    Party Mix|        false|1010| 1464393600|        74|        72|            2|(681805,[124,397,...|       11|   17853470|         63|\n",
            "|         LOCO|        false|1011| 1491868800|        97|        90|           18|(681805,[753,6951...|       27|   20635206|         82|\n",
            "|   Bruno Mars|        false|1012| 1506211200|        18|         7|            1|(681805,[1226,441...|        3|    3974946|          3|\n",
            "|       Breezy|        false|1013| 1490140800|        67|        55|            1|(681805,[836,3685...|       42|   14724585|         45|\n",
            "|      Fall 16|        false|1014| 1496793600|        83|        64|            3|(681805,[533,900,...|       27|   21004989|         49|\n",
            "|          SLO|        false|1015| 1498262400|        53|        32|            1|(681805,[5466,109...|        3|   12136870|         19|\n",
            "|       BANGAZ|        false|1016| 1508716800|       198|       141|            1|(681805,[65,575,7...|      104|   43843897|         89|\n",
            "|  Piano Music|        false|1017| 1401148800|        29|        21|            1|(681805,[2246,146...|        5|    6992643|         12|\n",
            "|  Beach Music|        false|1018| 1492387200|       130|       106|           14|(681805,[2564,328...|       27|   30811124|         70|\n",
            "|    Slow jamz|        false|1019| 1505779200|        43|        42|            1|(681805,[2081,238...|       15|   11198025|         32|\n",
            "+-------------+-------------+----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "songs_embeddings.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+--------------------+\n",
            "|pos|           track_uri|\n",
            "+---+--------------------+\n",
            "|  0|spotify:track:1mr...|\n",
            "|  1|spotify:track:1Uv...|\n",
            "|  2|spotify:track:4WR...|\n",
            "|  3|spotify:track:7B6...|\n",
            "|  4|spotify:track:2Gy...|\n",
            "|  5|spotify:track:7AO...|\n",
            "|  6|spotify:track:48Z...|\n",
            "|  7|spotify:track:1Um...|\n",
            "|  8|spotify:track:7MO...|\n",
            "|  9|spotify:track:27P...|\n",
            "| 10|spotify:track:6lt...|\n",
            "| 11|spotify:track:1yz...|\n",
            "| 12|spotify:track:5Mz...|\n",
            "| 13|spotify:track:3BU...|\n",
            "| 14|spotify:track:4Cl...|\n",
            "| 15|spotify:track:2dN...|\n",
            "| 16|spotify:track:341...|\n",
            "| 17|spotify:track:7ja...|\n",
            "| 18|spotify:track:4eQ...|\n",
            "| 19|spotify:track:6fy...|\n",
            "+---+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "song_pos_mapping.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "X5iG9Mus6VWy"
      },
      "source": [
        "Preprocessing the dataframe in order to associate to each `track_uri` an integer, that will represent the position of the track in the `rating_vector`. This is the same function that generates the `songs_embeddings`, but I also need it here because I need to convert the input playlist to continuate when doing performance evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MFwQWIZ1Bddv"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "track_uri_to_id = song_pos_mapping.select('track_uri', 'pos').rdd.collectAsMap()\n",
        "def map_track_df_to_pos(playlist_df: DataFrame) -> DataFrame:\n",
        "    \"\"\"\n",
        "    Returns a DataFrames containing the playlists, but the tracks are represented as a binary sparse vector.\n",
        "    \"\"\"\n",
        "\n",
        "    @F.udf(returnType=VectorUDT())\n",
        "    def extract_vector(tracks):\n",
        "      pos_list = set()\n",
        "\n",
        "      def reduce_fn(pos_list, row):\n",
        "          pos_list.add(track_uri_to_id.get(row.track_uri))\n",
        "          return pos_list\n",
        "      \n",
        "      pos_list = reduce(reduce_fn, tracks, pos_list)\n",
        "      \n",
        "      return SparseVector(RATING_VECTOR_LENGTH, sorted(list(pos_list)), [1 for _ in pos_list])\n",
        "\n",
        "    # Apply the mapping UDF on the \"tracks\" column of the slice_df dataframe\n",
        "    mapped_df = playlist_df.withColumn('tracks', extract_vector(F.col('tracks')))\n",
        "\n",
        "    return mapped_df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I could transform the `song_pos_mapping` into a python dictionary, since it requires very little memory (about 20 MB)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "hWyQZJ5JrDjR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The size of the track_uri -> position mapping dictionary is 20.971608 MB\n"
          ]
        }
      ],
      "source": [
        "print(\"The size of the track_uri -> position mapping dictionary is {} MB\".format(sys.getsizeof(track_uri_to_id) / 1_000_000))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's define the similarity function. Since we are dealing with binary vectors, we can use Jaccard Similarity, since we don't need the information about the single values in the vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5Nhc0hwgDQ6X"
      },
      "outputs": [],
      "source": [
        "def jaccard_similarity(vector_1: SparseVector, vector_2: SparseVector) -> float:\n",
        "  \"\"\"\n",
        "  Computes the Jaccard Similarity between two sparse binary vectors\n",
        "  \"\"\"\n",
        "  set1 = set(vector_1.indices)\n",
        "  set2 = set(vector_2.indices)\n",
        "\n",
        "  intersection = len(set1.intersection(set2))\n",
        "  union = len(set1.union(set2))\n",
        "\n",
        "  similarity = intersection / union\n",
        "\n",
        "  return similarity"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dWMpoMHrpxxf"
      },
      "source": [
        "Creating a function that gets in input the playlist to continue, and returns a Dataframe that indicates its similarity with each other playlist in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "SGjEbkYTAI3h"
      },
      "outputs": [],
      "source": [
        "def create_similarity_df(input_vector: DataFrame, rating_vectors_df: DataFrame, similarityFunction: Callable) -> DataFrame:  \n",
        "  \"\"\"\n",
        "  Given a DataFrame with only one row that represents the vector representation of the playlist to continuate, it returns a dataframe containing the similarity between that vector and each\n",
        "  other playlist vector in the dataset.\n",
        "\n",
        "  - input_vector: A DataFrame with only one Row, that is the SparseVector representing the input playlist\n",
        "  - rating_vectors_df: A Dataframe that contains the playlists and their respective vector representation\n",
        "  \"\"\"\n",
        "\n",
        "  input_vector_cached = input_vector.cache()\n",
        "  input_vector = input_vector.first()[0]\n",
        "  \n",
        "  @F.udf(returnType=FloatType())\n",
        "  def compute_similarity(vector1):\n",
        "    return jaccard_similarity(vector1, input_vector)\n",
        "\n",
        "  result_df = rating_vectors_df.withColumn(\"similarity\", compute_similarity(rating_vectors_df.rating_vector))\n",
        "\n",
        "  input_vector_cached.unpersist()\n",
        "  \n",
        "  return result_df\n",
        "\n",
        "if DEBUG:\n",
        "  rv_df = songs_embeddings.withColumnRenamed(\"tracks\", \"rating_vector\")\n",
        "  # Just to show, we take the first playlist as the playlist to be continued \n",
        "  first_playlist_vector = rv_df.limit(1).select(\"rating_vector\").withColumnRenamed(\"rating_vector\",\"input_vector\")\n",
        "  result_df = create_similarity_df(first_playlist_vector, rv_df, jaccard_similarity)\n",
        "  result_df.cache()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "12CY_fuNFXKr"
      },
      "source": [
        "If we filter the playlists that have a strictly positive similarity with the input playlist, and order them by descending similarity, we can see that the name (that we assume is very informative for the content of the playlist) is very similar, meaning that the algorithm seems to work!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "NrPRMP-rINkc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+-------------+-----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+----------+\n",
            "|           name|collaborative|  pid|modified_at|num_tracks|num_albums|num_followers|       rating_vector|num_edits|duration_ms|num_artists|similarity|\n",
            "+---------------+-------------+-----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+----------+\n",
            "|         disney|        false| 1000| 1457827200|       189|        16|            1|(681805,[126,1903...|        4|   31428282|         65|       1.0|\n",
            "|         Disney|        false|34420| 1430784000|       179|        15|            1|(681805,[254,1903...|        3|   25533248|         54|0.22635135|\n",
            "|        Disney✨|        false|12990| 1450915200|       113|        32|            1|(681805,[1790,190...|        3|   20665774|         64|0.18775511|\n",
            "|         Disney|        false| 3323| 1391817600|       133|        20|            1|(681805,[4132,494...|        6|   23208277|         64|0.16911764|\n",
            "|         DISNEY|        false|44565| 1506470400|       179|        23|            1|(681805,[83,4442,...|        5|   26129019|         70|0.16666667|\n",
            "|  Disney Movies|        false|23038| 1399852800|       170|        16|            6|(681805,[1903,349...|        2|   25356294|         50|0.16393442|\n",
            "|Disney Princess|        false|65458| 1496793600|       159|        25|            1|(681805,[83,126,2...|        3|   26615932|         71|0.16271186|\n",
            "|         Disney|        false|50071| 1486080000|       154|        55|            1|(681805,[916,1790...|       16|   28494250|         95|0.15862069|\n",
            "|         disney|        false| 9718| 1467849600|        74|        28|            1|(681805,[126,4286...|        6|   14431883|         53|   0.15625|\n",
            "|        Disney |        false|45621| 1469404800|       191|        60|            1|(681805,[125,126,...|       12|   35313420|        100|0.15189873|\n",
            "|         DISNEY|        false|84889| 1410480000|       241|        23|            1|(681805,[254,1903...|        2|   38597440|         79|0.14516129|\n",
            "|         Disney|        false|22490| 1396396800|       245|        20|            1|(681805,[254,1903...|        3|   37871643|         66|0.14506173|\n",
            "|         DISNEY|        false|36245| 1479772800|        58|        24|            1|(681805,[4940,494...|        4|   10831497|         39|0.14285715|\n",
            "|         Disney|        false|33505| 1453680000|        95|        34|            1|(681805,[4940,668...|        8|   16193877|         69|0.13360325|\n",
            "|      disney!!!|        false|57499| 1423526400|       228|        35|            1|(681805,[254,1790...|        2|   40446966|         82| 0.1278409|\n",
            "|         Disney|        false|10604| 1419811200|       124|        13|            1|(681805,[3436,349...|        2|   20226973|         39|0.12773722|\n",
            "|        Disney |        false|21144| 1488153600|       112|        38|            1|(681805,[83,4442,...|        5|   17514563|         87|0.12643678|\n",
            "|         Disney|        false|27458| 1411084800|        56|        13|            1|(681805,[4940,860...|        5|    8923982|         41|0.12616822|\n",
            "|         Disney|         true|69884| 1490918400|        49|        15|            3|(681805,[2438,860...|        9|    9143547|         34|     0.125|\n",
            "|      Disney <3|        false|18810| 1404864000|       215|        25|            1|(681805,[254,1549...|        4|   36929082|         59|0.12112676|\n",
            "+---------------+-------------+-----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if DEBUG:\n",
        "    result_df.filter(\"similarity > 0\").orderBy(F.col(\"similarity\").desc()).show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ppy5-Y19swvG"
      },
      "source": [
        "Now, in order to suggest some songs to continuate the input playlist, let's take the $k$ top most similar playlists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "wNoSOnIqCLm8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 9:=======>                                                   (1 + 7) / 8]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+-------------+-----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+----------+\n",
            "|           name|collaborative|  pid|modified_at|num_tracks|num_albums|num_followers|       rating_vector|num_edits|duration_ms|num_artists|similarity|\n",
            "+---------------+-------------+-----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+----------+\n",
            "|         Disney|        false|34420| 1430784000|       179|        15|            1|(681805,[254,1903...|        3|   25533248|         54|0.22635135|\n",
            "|        Disney✨|        false|12990| 1450915200|       113|        32|            1|(681805,[1790,190...|        3|   20665774|         64|0.18775511|\n",
            "|         Disney|        false| 3323| 1391817600|       133|        20|            1|(681805,[4132,494...|        6|   23208277|         64|0.16911764|\n",
            "|         DISNEY|        false|44565| 1506470400|       179|        23|            1|(681805,[83,4442,...|        5|   26129019|         70|0.16666667|\n",
            "|  Disney Movies|        false|23038| 1399852800|       170|        16|            6|(681805,[1903,349...|        2|   25356294|         50|0.16393442|\n",
            "|Disney Princess|        false|65458| 1496793600|       159|        25|            1|(681805,[83,126,2...|        3|   26615932|         71|0.16271186|\n",
            "|         Disney|        false|50071| 1486080000|       154|        55|            1|(681805,[916,1790...|       16|   28494250|         95|0.15862069|\n",
            "|         disney|        false| 9718| 1467849600|        74|        28|            1|(681805,[126,4286...|        6|   14431883|         53|   0.15625|\n",
            "|        Disney |        false|45621| 1469404800|       191|        60|            1|(681805,[125,126,...|       12|   35313420|        100|0.15189873|\n",
            "|         DISNEY|        false|84889| 1410480000|       241|        23|            1|(681805,[254,1903...|        2|   38597440|         79|0.14516129|\n",
            "|         Disney|        false|22490| 1396396800|       245|        20|            1|(681805,[254,1903...|        3|   37871643|         66|0.14506173|\n",
            "|         DISNEY|        false|36245| 1479772800|        58|        24|            1|(681805,[4940,494...|        4|   10831497|         39|0.14285715|\n",
            "|         Disney|        false|33505| 1453680000|        95|        34|            1|(681805,[4940,668...|        8|   16193877|         69|0.13360325|\n",
            "|      disney!!!|        false|57499| 1423526400|       228|        35|            1|(681805,[254,1790...|        2|   40446966|         82| 0.1278409|\n",
            "|         Disney|        false|10604| 1419811200|       124|        13|            1|(681805,[3436,349...|        2|   20226973|         39|0.12773722|\n",
            "|        Disney |        false|21144| 1488153600|       112|        38|            1|(681805,[83,4442,...|        5|   17514563|         87|0.12643678|\n",
            "|         Disney|        false|27458| 1411084800|        56|        13|            1|(681805,[4940,860...|        5|    8923982|         41|0.12616822|\n",
            "|         Disney|         true|69884| 1490918400|        49|        15|            3|(681805,[2438,860...|        9|    9143547|         34|     0.125|\n",
            "|      Disney <3|        false|18810| 1404864000|       215|        25|            1|(681805,[254,1549...|        4|   36929082|         59|0.12112676|\n",
            "|    disney love|        false|57883| 1470700800|       167|        48|            1|(681805,[1549,179...|       10|   28566741|        112| 0.1178344|\n",
            "+---------------+-------------+-----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+----------+\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "def get_top_k_results(playlist_pid: int, similarity_df: DataFrame, k: int = 20) -> DataFrame:\n",
        "  \"\"\"\n",
        "  Given the playlist PID and the DataFrames of similarity relative to that playlist, it returns a DataFrame containing the top k most similar playlists.\n",
        "\n",
        "  - playlist_pid: \n",
        "  - similarity_df: \n",
        "  \"\"\"\n",
        "  return similarity_df.filter((F.col(\"similarity\") > 0) & (F.col(\"pid\") != playlist_pid)).orderBy(F.col(\"similarity\").desc()).limit(k)\n",
        "\n",
        "if DEBUG:\n",
        "  first_playlist_pid = rv_df.limit(1).select(\"pid\").first().pid\n",
        "  top_k_results = get_top_k_results(first_playlist_pid, result_df)\n",
        "  top_k_results.cache()\n",
        "  top_k_results.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nGUtRgGutIgZ"
      },
      "source": [
        "We want to obtain a single embedding for all the $K$ top most similar playlists, that will be the rating vector. We can then pick the indices of the $n$ top greatest values form this vector, and those will be the $n$ songs that we will reccomend.\n",
        "\n",
        "In order to aggregate the $k$ embeddings into a single one, I decided to take an average, weighted by the similarity value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "nDEnlGrCcOHp"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 15:>                                                         (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|              summed|\n",
            "+--------------------+\n",
            "|(681805,[83,125,2...|\n",
            "+--------------------+\n",
            "\n",
            "32.64169001579285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "def get_input_rating_vector(similarity_df: DataFrame) -> SparseVector:\n",
        "  \"\"\"\n",
        "  Given DataFrames of similarities ordered by similarity in descending order, it returns the vector representation of the first row, which\n",
        "  is the vector of the input playlist (similarity 1.0)\n",
        "  \"\"\"\n",
        "  return similarity_df.limit(1).select(\"input_vector\").collect()[0].input_vector\n",
        "\n",
        "def accumulate_top_k_results(top_k_results: DataFrame, input_vector: np.ndarray) -> DataFrame:\n",
        "  \"\"\"\n",
        "  Given a DataFrame that represents the top-k most similar playlists to the input playlist, it returns a\n",
        "  DataFrame that contains a single row, representing the aggregation of all the playlists' vectors.\n",
        "  \n",
        "  The aggregation is just the sum of the vectors, weighted by the relative similarity, and normalized by dividing it by the sum of similarities.\n",
        "  \"\"\"\n",
        "\n",
        "  @F.udf(returnType=VectorUDT())\n",
        "  def sum_vector(sparse_vectors, similarities):\n",
        "    similarities = np.array(similarities)\n",
        "    sparse_vectors = np.array(sparse_vectors)\n",
        "    acc = np.dot(sparse_vectors.T, similarities) #Compute the sum(vector * similarity) for each vector and similarity\n",
        "    acc /= similarities.sum() #Normalize the vector\n",
        "    acc -= (input_vector * acc) #If a song is present in the input playlist, don't consider it\n",
        "    return SparseVector(acc.size, np.nonzero(acc)[0], acc[np.nonzero(acc)])\n",
        "\n",
        "  return top_k_results.agg(sum_vector(F.collect_list('rating_vector'), F.collect_list(\"similarity\")).alias('summed'))\n",
        "\n",
        "if DEBUG:\n",
        "  t1 = time.time()\n",
        "  input_vector = first_playlist_vector.first()[0]\n",
        "  accumulated_vector_df = accumulate_top_k_results(top_k_results, input_vector)\n",
        "  accumulated_vector_df.cache()\n",
        "  accumulated_vector_df.show()\n",
        "  t2 = time.time()\n",
        "  print(t2-t1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that I have the aggregated vector, I can just take the top-$n$ indices that corresponds to the higher values, and those would be the indices of the songs that are the most relevant to the input playlist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "keTpUBIXTdHg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+----------+\n",
            "|   pos|confidence|\n",
            "+------+----------+\n",
            "|505626|0.86660594|\n",
            "|338046| 0.8451381|\n",
            "|256245| 0.8245531|\n",
            "|669595|0.81081593|\n",
            "|174330|0.78816617|\n",
            "|592258| 0.7713628|\n",
            "|589100| 0.7507684|\n",
            "|170221|0.73229903|\n",
            "| 87563| 0.7185418|\n",
            "|585110|0.71125495|\n",
            "+------+----------+\n",
            "\n",
            "0.45963597297668457\n"
          ]
        }
      ],
      "source": [
        "@F.udf(returnType=ArrayType(\n",
        "    StructType([\n",
        "      StructField(\"pos\", IntegerType(), False),\n",
        "      StructField(\"confidence\", FloatType(), False)\n",
        "])))\n",
        "def get_top_n_values(vector: SparseVector, n: int) -> List[Tuple[int, float]]:\n",
        "  \"\"\"\n",
        "  Given the aggregated vector, it returns a list of tuples that map the index of the song to the confidence that that song is relevant for the input playlist.\n",
        "  The index are only of the top-n most confident results, and are ordered by confidence.\n",
        "  \"\"\"\n",
        "  sorted_elements = vector.toArray().tolist()\n",
        "  top_n_indices = sorted(range(len(sorted_elements)), key=lambda i: sorted_elements[i], reverse=True)[:n]\n",
        "  return [(index, sorted_elements[index]) for index in top_n_indices]\n",
        "\n",
        "if DEBUG:\n",
        "  t1 = time.time()\n",
        "  top_n_reccomendations = accumulated_vector_df.withColumn(\"top_n_recommendations\", get_top_n_values(F.col(\"summed\"), F.lit(10))).select(F.explode(\"top_n_recommendations\")).select(\"col.*\")\n",
        "  top_n_reccomendations.show()\n",
        "  t2 = time.time()\n",
        "  print(t2-t1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now I can join the indices to the `songs_info_df` DataFrame in order to obtain the `track_uri` of the recommended tracks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ZJOyep5RUMGV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+----------+--------------------+\n",
            "|   pos|confidence|           track_uri|\n",
            "+------+----------+--------------------+\n",
            "| 87563| 0.7185418|spotify:track:0qc...|\n",
            "|170221|0.73229903|spotify:track:6P3...|\n",
            "|174330|0.78816617|spotify:track:0qx...|\n",
            "|256245| 0.8245531|spotify:track:28U...|\n",
            "|338046| 0.8451381|spotify:track:5k3...|\n",
            "|505626|0.86660594|spotify:track:1OY...|\n",
            "|585110|0.71125495|spotify:track:2yi...|\n",
            "|589100| 0.7507684|spotify:track:70b...|\n",
            "|592258| 0.7713628|spotify:track:2AI...|\n",
            "|669595|0.81081593|spotify:track:0HU...|\n",
            "+------+----------+--------------------+\n",
            "\n",
            "1.742967128753662\n"
          ]
        }
      ],
      "source": [
        "def recommendation_song_info(recommendation: DataFrame, songs_info_df: DataFrame) -> DataFrame:\n",
        "  return recommendation.join(songs_info_df, \"pos\")\n",
        "\n",
        "if DEBUG:\n",
        "  t1 = time.time()\n",
        "  songs_info = recommendation_song_info(top_n_reccomendations, song_pos_mapping)\n",
        "  songs_info.show()\n",
        "  t2 = time.time()\n",
        "  print(t2-t1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CFmlqOAttu32"
      },
      "source": [
        "### Putting it all togheter\n",
        "We now define a single function that will get a playlist in input and will reccomend $n$ songs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "jfiQn5_rt827"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/06/30 19:33:23 WARN CacheManager: Asked to cache already cached data.        \n",
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "def user_based_recommendation(playlist: DataFrame, \n",
        "                              mapped_slice_df: DataFrame, \n",
        "                              n:int = 50,\n",
        "                              k: int = 20) -> DataFrame:\n",
        "  \n",
        "  \"\"\"\n",
        "  Given a DataFrame with a single row that represents the input playlist, generate the DataFrame of n recommendations.\n",
        "  \"\"\"\n",
        "                              \n",
        "  rv_df = mapped_slice_df.withColumnRenamed(\"tracks\", \"rating_vector\").cache()\n",
        "  playlist_vector = map_track_df_to_pos(playlist).select(\"tracks\").withColumnRenamed(\"tracks\", \"input_vector\").cache()\n",
        "  similarity_df = create_similarity_df(playlist_vector, rv_df, jaccard_similarity).cache()\n",
        "  top_k_results = get_top_k_results(playlist.first().pid, similarity_df, k=k).cache()\n",
        "  input_vector = playlist_vector.select(\"input_vector\").first()[0].toArray()\n",
        "  accumulated_vector_df = accumulate_top_k_results(top_k_results, input_vector).cache()\n",
        "  top_n_indices = accumulated_vector_df\\\n",
        "                  .withColumn(\"top_n_recommendations\", get_top_n_values(F.col(\"summed\"), F.lit(n)))\\\n",
        "                  .select(F.explode(\"top_n_recommendations\"))\\\n",
        "                  .select(\"col.*\").cache()\n",
        "\n",
        "  recommended_songs_info = recommendation_song_info(top_n_indices, song_pos_mapping).cache() \n",
        "\n",
        "  playlist_vector.unpersist()\n",
        "  similarity_df.unpersist()\n",
        "  top_k_results.unpersist()\n",
        "  accumulated_vector_df.unpersist()\n",
        "  top_n_indices.unpersist()\n",
        "  return recommended_songs_info\n",
        "  \n",
        "\n",
        "if DEBUG:\n",
        "  #Collect and createDataFrame because operations on limit(1) take as long as the entire slice_df, don't know why\n",
        "  playlist = spark.createDataFrame(slice_df.filter(\"pid == 1010\").limit(1).collect())\n",
        "  final_recommendation = user_based_recommendation(playlist, songs_embeddings, n=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+----------+--------------------+\n",
            "|   pos|confidence|           track_uri|\n",
            "+------+----------+--------------------+\n",
            "|669578| 0.4977322|spotify:track:4o6...|\n",
            "|333588|0.45380837|spotify:track:3zB...|\n",
            "|500339| 0.4509231|spotify:track:5Rs...|\n",
            "|591490|0.45051354|spotify:track:6cb...|\n",
            "|424672|0.44969997|spotify:track:5dN...|\n",
            "+------+----------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if DEBUG:\n",
        "    final_recommendation.orderBy(F.col(\"confidence\").desc()).show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eM7ErDxxt69B"
      },
      "source": [
        "## Performance Evaluation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since now we operated on the entire dataset, but for performance evaluation we will generate some recommendations for each playlist in the training set, and then compare the recommended songs with the songs in the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "GaY6U3hajPVM"
      },
      "outputs": [],
      "source": [
        "TRAIN_DF_PATH = os.path.join(SAVED_DFS_PATH, f\"train_df-{NUM_PLAYLISTS}.json\")\n",
        "TEST_DF_PATH = os.path.join(SAVED_DFS_PATH, f\"test_df-{NUM_PLAYLISTS}.json\")\n",
        "train_df = spark.read.schema(playlist_schema).json(TRAIN_DF_PATH)\n",
        "test_df = spark.read.schema(playlist_schema).json(TEST_DF_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-vEt0SPkqu_",
        "outputId": "413c6285-201b-4edd-ef87-2e3ed37104b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+-------------+----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "|         name|collaborative| pid|modified_at|num_tracks|num_albums|num_followers|              tracks|num_edits|duration_ms|num_artists|\n",
            "+-------------+-------------+----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "|       disney|        false|1000| 1457827200|       189|        16|            1|[{31, Daughters o...|        4|   31428282|         65|\n",
            "|Indie Electro|        false|1001| 1417824000|       165|        18|            2|[{117, Boards of ...|        2|   38241566|          8|\n",
            "|  jack & jack|        false|1002| 1465430400|        17|        14|            1|[{14, Jack & Jack...|        3|    3549358|          3|\n",
            "|        vibes|        false|1003| 1498435200|       225|       195|            2|[{119, PREP, spot...|       91|   51242585|        157|\n",
            "|        Indie|        false|1004| 1498608000|       165|       118|            1|[{117, LCD Sounds...|       74|   42601098|         92|\n",
            "|      college|        false|1005| 1504310400|        28|        26|            1|[{22, Kid Ink, sp...|        2|    5870710|         25|\n",
            "|    Summer 15|        false|1006| 1471996800|        80|        74|            2|[{9, Kygo, spotif...|       40|   19652753|         67|\n",
            "|    New music|        false|1007| 1509148800|        58|        48|            1|[{17, Kodak Black...|       20|   13158862|         38|\n",
            "|          Now|        false|1008| 1505692800|        84|        82|            3|[{30, Mullally, s...|       36|   18432208|         79|\n",
            "|         Jams|        false|1009| 1507680000|        41|        36|            1|[{12, Alabama Sha...|       25|    9413467|         31|\n",
            "|    Party Mix|        false|1010| 1464393600|        74|        72|            2|[{39, Stevie Wond...|       11|   17853470|         63|\n",
            "|         LOCO|        false|1011| 1491868800|        97|        90|           18|[{33, Fat Joe, sp...|       27|   20635206|         82|\n",
            "|   Bruno Mars|        false|1012| 1506211200|        18|         7|            1|[{13, Bruno Mars,...|        3|    3974946|          3|\n",
            "|       Breezy|        false|1013| 1490140800|        67|        55|            1|[{7, Jon Bellion,...|       42|   14724585|         45|\n",
            "|      Fall 16|        false|1014| 1496793600|        83|        64|            3|[{61, Kings of Le...|       27|   21004989|         49|\n",
            "|          SLO|        false|1015| 1498262400|        53|        32|            1|[{34, Todd Snider...|        3|   12136870|         19|\n",
            "|       BANGAZ|        false|1016| 1508716800|       198|       141|            1|[{185, Russ, spot...|      104|   43843897|         89|\n",
            "|  Piano Music|        false|1017| 1401148800|        29|        21|            1|[{26, Jennifer Th...|        5|    6992643|         12|\n",
            "|  Beach Music|        false|1018| 1492387200|       130|       106|           14|[{24, Zion & Lenn...|       27|   30811124|         70|\n",
            "|    Slow jamz|        false|1019| 1505779200|        43|        42|            1|[{27, Bone Thugs-...|       15|   11198025|         32|\n",
            "+-------------+-------------+----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-------------+-------------+----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "|         name|collaborative| pid|modified_at|num_tracks|num_albums|num_followers|              tracks|num_edits|duration_ms|num_artists|\n",
            "+-------------+-------------+----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "|       disney|        false|1000| 1457827200|       189|        16|            1|[{184, Various Ar...|        4|   31428282|         65|\n",
            "|Indie Electro|        false|1001| 1417824000|       165|        18|            2|[{135, Boards of ...|        2|   38241566|          8|\n",
            "|  jack & jack|        false|1002| 1465430400|        17|        14|            1|[{0, Jack & Jack,...|        3|    3549358|          3|\n",
            "|        vibes|        false|1003| 1498435200|       225|       195|            2|[{9, Marc E. Bass...|       91|   51242585|        157|\n",
            "|        Indie|        false|1004| 1498608000|       165|       118|            1|[{135, Fleet Foxe...|       74|   42601098|         92|\n",
            "|      college|        false|1005| 1504310400|        28|        26|            1|[{9, Kesha, spoti...|        2|    5870710|         25|\n",
            "|    Summer 15|        false|1006| 1471996800|        80|        74|            2|[{30, Jeremih, sp...|       40|   19652753|         67|\n",
            "|    New music|        false|1007| 1509148800|        58|        48|            1|[{0, Post Malone,...|       20|   13158862|         38|\n",
            "|          Now|        false|1008| 1505692800|        84|        82|            3|[{73, PredZ, spot...|       36|   18432208|         79|\n",
            "|         Jams|        false|1009| 1507680000|        41|        36|            1|[{24, Foster The ...|       25|    9413467|         31|\n",
            "|    Party Mix|        false|1010| 1464393600|        74|        72|            2|[{4, The Killers,...|       11|   17853470|         63|\n",
            "|         LOCO|        false|1011| 1491868800|        97|        90|           18|[{62, Boostee, sp...|       27|   20635206|         82|\n",
            "|   Bruno Mars|        false|1012| 1506211200|        18|         7|            1|[{0, Bruno Mars, ...|        3|    3974946|          3|\n",
            "|       Breezy|        false|1013| 1490140800|        67|        55|            1|[{36, Troye Sivan...|       42|   14724585|         45|\n",
            "|      Fall 16|        false|1014| 1496793600|        83|        64|            3|[{30, The Arcs, s...|       27|   21004989|         49|\n",
            "|          SLO|        false|1015| 1498262400|        53|        32|            1|[{19, Bruce Sprin...|        3|   12136870|         19|\n",
            "|       BANGAZ|        false|1016| 1508716800|       198|       141|            1|[{65, Young Thug,...|      104|   43843897|         89|\n",
            "|  Piano Music|        false|1017| 1401148800|        29|        21|            1|[{27, Jennifer Th...|        5|    6992643|         12|\n",
            "|  Beach Music|        false|1018| 1492387200|       130|       106|           14|[{55, Héctor \"El ...|       27|   30811124|         70|\n",
            "|    Slow jamz|        false|1019| 1505779200|        43|        42|            1|[{37, R. Kelly, s...|       15|   11198025|         32|\n",
            "+-------------+-------------+----+-----------+----------+----------+-------------+--------------------+---------+-----------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_df.show()\n",
        "test_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "86dFBXK20uqu"
      },
      "outputs": [],
      "source": [
        "def r_prec(recommendations: DataFrame, ground_truth: DataFrame, num_of_recommendations: int) -> float:\n",
        "    \"\"\"\n",
        "    Calculates R-Precision for the recommendations.\n",
        "    \"\"\"\n",
        "    recommended_relevant_tracks = recommendations.join(ground_truth, \"track_uri\").cache()\n",
        "    reccomended_relevant_tracks_count = recommended_relevant_tracks.count() #this can be top_n_results.join in order to be more performant\n",
        "    recommended_relevant_tracks.unpersist()\n",
        "    precision = reccomended_relevant_tracks_count / float(num_of_recommendations)\n",
        "\n",
        "    return precision\n",
        "\n",
        "def normalized_discounted_cumulative_gain(recommendations: DataFrame, ground_truth: DataFrame, num_of_recommendations: int) -> float:\n",
        "  \"\"\"\n",
        "  Calculates the Normalized Discounted Cumulative Gain between the DataFrame of recommendations and the DataFrame of ground truth.\n",
        "  \"\"\"\n",
        "  recommendations = recommendations.orderBy(F.col(\"confidence\").desc())\n",
        "  recommendations_list = recommendations.collect()\n",
        "  cumulative_gain = 0\n",
        "\n",
        "  intersection = recommendations.join(ground_truth, \"track_uri\").count()\n",
        "  if intersection == 0: return 0\n",
        "\n",
        "  ideal_cumulative_gain = 1 + np.array([(1 / math.log(i, 2)) for i in range(2, 2+intersection)]).sum()\n",
        "  for index, row in enumerate(recommendations_list):\n",
        "    i = index + 1\n",
        "    is_rel = ground_truth.filter(F.col(\"track_uri\").isin(row.track_uri)).count() > 0\n",
        "    rel = 1 if is_rel else 0\n",
        "    if i == 1:\n",
        "      cumulative_gain += rel\n",
        "    else:\n",
        "      cumulative_gain += (rel / math.log(i, 2))\n",
        "  return cumulative_gain / ideal_cumulative_gain"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's define the function that will perform the evaluation pipeline for a single playlist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "J8kbN-2Emdmz"
      },
      "outputs": [],
      "source": [
        "def evaluate(pid: int) -> Tuple[DataFrame, float]:\n",
        "    \"\"\"\n",
        "    Perform the evaluation for a given playlist.\n",
        "    \"\"\"\n",
        "    playlist_train = train_df.filter(f\"pid == {pid}\").cache()\n",
        "    playlist_test = test_df.filter(f\"pid == {pid}\").cache()\n",
        "    ground_truth = playlist_test.select(F.explode(\"tracks\")).select(\"col.*\").cache()\n",
        "    num_of_recommendations = ground_truth.count()\n",
        "    recommendations = user_based_recommendation(playlist_train, \n",
        "                                                songs_embeddings, \n",
        "                                                n=num_of_recommendations,\n",
        "                                                k = 10).cache()\n",
        "    precision = r_prec(recommendations, ground_truth, num_of_recommendations)\n",
        "    gain = normalized_discounted_cumulative_gain(recommendations, ground_truth, num_of_recommendations)\n",
        "\n",
        "    playlist_train.unpersist()\n",
        "    playlist_test.unpersist()\n",
        "    ground_truth.unpersist()\n",
        "    return playlist_train, playlist_test, ground_truth, recommendations, precision, gain"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can finally perform the evaluation on a set of playlists. I decided to evaluate the algorithm on 1000 playlists. Since each evaluation step takes about 30 seconds (30,000 seconds are about 8 hours), I used checkpointing in order to interrupt the evaluation and restart it from the same point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEJCTq-eqJyk"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "LAST_CHECKPOINT_INDEX = 0\n",
        "EVALUATION_RESULTS_PATH = os.path.join(EVALUATION_FOLDER,  \"UB_evaluation_results_FINAL\")\n",
        "def perform_evaluation():\n",
        "  SAMPLING_FRACTION = 0.01\n",
        "  sampled_playlists = train_df.sample(False, SAMPLING_FRACTION, seed=42).cache()\n",
        "\n",
        "  results = []\n",
        "  for index, row in enumerate(tqdm(sampled_playlists.collect(), desc=\"Performing evaluation\")):\n",
        "      if index <= LAST_CHECKPOINT_INDEX: continue \n",
        "      \n",
        "      CHECKPOINT_RESULTS = os.path.join(EVALUATION_FOLDER, f\"UB_evaluation_results_check_{index}\")\n",
        "      pid = row['pid']\n",
        "      train, test, gt, rec, prec, gain = evaluate(pid)\n",
        "      results.append((prec, gain))\n",
        "      print((prec, gain))\n",
        "      if index % 10 == 0:\n",
        "         with open(CHECKPOINT_RESULTS, \"w\") as f:\n",
        "            json.dump(results, f)\n",
        "  with open(EVALUATION_RESULTS_PATH, \"w\") as f:\n",
        "    json.dump(results, f)\n",
        "  \n",
        "  sampled_playlists.unpersist()\n",
        "  return results\n",
        "\n",
        "\n",
        "results = perform_evaluation()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's load the `results`, average them and see how the model performed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYvIrTvqfrzZ",
        "outputId": "1fe047e4-1352-434f-efc1-7d77293c6277"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.12420997489246202, 0.30409513695246143)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results = []\n",
        "for file in os.listdir(EVALUATION_FOLDER):\n",
        "    if file == \".DS_Store\": continue\n",
        "    with open(os.path.join(EVALUATION_FOLDER, file), \"r\") as f:\n",
        "        file_results = json.load(f)\n",
        "        results.extend(file_results)\n",
        "\n",
        "avg_prec, avg_gain = 0, 0\n",
        "for prec, gain in results:\n",
        "  avg_prec += prec\n",
        "  avg_gain += gain \n",
        "tot = len(results)\n",
        "avg_prec /= tot\n",
        "avg_gain /= tot\n",
        "avg_prec, avg_gain"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the model has a precision of about 0.10 and a NDCG of 0.28, which isn't bad taking into account that state of the art models with 1M playlists for train have 0.2 precision and 0.38 NDCG."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "VJeY9PpvaHUJ",
        "SqlejJ_MFrB9",
        "el7BsOEsjSgN"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
